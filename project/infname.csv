#*On the Possibility of Path Expressions Containing Backward Navigations in Object-Oriented Databases.
#@Nobutaka Suzuki,Minoru Ito,Jun Okui
#t1996
#cCODAS
#index105904

#*HyperView: Generating Virtual Hypermedia in Decentralized Environments.
#@Shin'ichi Konomi,Yahiko Kambayashi
#t1996
#cCODAS
#index105905

#*A Batch Manufacturing Information Management System Based on Multidimensional View Generation and Active Mechanism.
#@Hideyuki Takada,Hiromitsu Shimakawa,Yoshitomo Asano,Morikazu Takegaki
#t1996
#cCODAS
#index105906

#*Flexible Workflow Framework for Supporting Collaborative Works.
#@Takeo Kunishima,Kazumasa Yokota
#t1996
#cCODAS
#index105907

#*Time Management in Dynamic Workflows.
#@Olivera Marjanovic,Maria E. Orlowska
#t1999
#cCODAS
#index105908

#*Towards Integrated Management of Heterogeneous Documents.
#@Takeo Kunishima,Kazumasa Yokota,Bojiang Liu,Tadaaki Miyake
#t1999
#cCODAS
#index105909

#*Meme Media and Databases.
#@Yuzuru Tanaka
#t1996
#cCODAS
#index105910

#*Incremental Maintenance of Materialized Path Query OODB Views.
#@Harumi A. Kuno,Elke A. Rundensteiner
#t1996
#cCODAS
#index105911

#*Aggregation in Federated Databases: The DOK Approach.
#@Zahir Tari
#t1996
#cCODAS
#index105912

#*Indexing, Query Interface and Query Processing for Venus: A Video Database System.
#@Tony C. T. Kuo,Arbee L. P. Chen
#t1996
#cCODAS
#index105913

#*Knowledge Representation, Concept Acquisition and Retrieval of Video Data.
#@Kuniaki Uehara,Meguru Oe,Keita Maehara
#t1996
#cCODAS
#index105914

#*Optimal Bit Lengths of Direction Signatures for Spatial Match Accessing Using Basic Linear Hashing Scheme.
#@Chin-Feng Lee,Chin-Chen Chang
#t1996
#cCODAS
#index105915

#*A Cooperative Real-Time GIS for Traffic Management.
#@P. Valsecchi,Christophe Claramunt,Stefano Spaccapietra
#t1999
#cCODAS
#index105916

#*Effective and Efficient Boundary-based Clustering for Three-Dimensional Geoinformation Studies.
#@Ickjai Lee,Vladimir Estivill-Castro
#t2001
#cCODAS
#index105917
#!Due to their inherent volumetric nature, underground and marine geoinformation studies and even astronomy demand clustering techniques capable of dealing with three-dimensional data. However, most robust and exploratory spatial clustering approaches for GIS only consider two dimensions. We extend robust argument-free two-dimensional boundary-based clustering [8] to three dimensions. The progression to 3D demands manipulation of one argument from users and the encoding of proximity and density information in different proximity graphs. Fortunately, the input argument allows exploration of weaknesses in clusters, and detection of regions for potential merge or split. We also provide an effective heuristic to obtain good initial values for the input argument. This maximizes user friendliness and minimizes exploration time. Experimental results demonstrate that for two popular proximity graphs (Delaunay Tetrahedrization and undirected k-nearest neighbor graph) our approach is robust to the presence of noise and is able to detect high-quality volumetric clusters for complex situations such as non-convex clusters, clusters of different densities and clusters of different sizes. Our experiments also show that, undirected k-nearest neighbor graphs produce consistent high-quality clusters with little sensitivity to values of k. Moreover, this variant of the algorithm only requires subquadratic time.

#*Document Retrieval Based on Subtopic Combination.
#@Masahiro Watanabe,Takaharu Oishi,Masatoshi Yoshikawa,Minoru Nakai,Shunsuke Uemura
#t1999
#cCODAS
#index105918

#*Supporting Voluntary Disconnection in WFMSs.
#@Seung Il Lee,Dongsoo Han,Dongman Lee
#t2001
#cCODAS
#index105919
#!With the network and computing environment improvement in both wireless and wired area, mobile or portable devices like palmtops and notebooks have become prevalent. They are even considered as essential ingredients of business workplace. Thus this mobile business environment should be accommodated in the business automation systems like workflow management systems(WFMSs). Researches have been focused on disconnected operation to provide continuous and safe services for the mobile devices in various fields. However, disconnected operation has not been fully addressed in the area of WFMSs at all. In this paper, we analyze the type and scope of disconnected service in WFMSs through the in-depth analysis of workflow task models. Based on this analysis, we show and discuss four general issues that should be addressed to support disconnected operation in WFMSs. The discussions are mainly focused on voluntary disconnection in the wired environment and issues like task classification, task relevant data handling, application handling, and task state emulation are included.

#*Applying Event-Condition-Action Mechanism in Healthcare; A Computerized Clinical Test-Ordering protocol System (TOPS).
#@Bing Wu,Kudakwashe Dube
#t2001
#cCODAS
#index105920
#!This paper addresses issues of the active database application in the challenging healthcare area: the management and execution of computerised clinical practice guidelines/protocols. The problem of how to efficiently and effectively query and manipulate the computerised clinical protocols/guidelines has posed a major challenge but received little research attention until very recently. By proposing a declarative modeling language (PLAN) with an Event-Condition-Action (ECA) mechanism for clinical test-ordering protocols, and an automatic mapping and management system (TOPS), this paper addresses this issue, in an important medical domain, from a unified approach based on an active rule mechanism. The work presented in this paper is part of an on-going research effort that investigates a new application domain for active databases, and proposes some new requirements towards the enhancements of active DBMS functionalities.

#*Set-Based Access Conflicts Analysis of Concurrent Workflow Definition.
#@Minkyu Lee,Dongsoo Han,Jaeyong Shim
#t2001
#cCODAS
#index105921
#!An error-comprising workflow definition might provoke serious problems to an enterprise especially when it is involved with mission critical business processes. Concurrency of workflow processes is known as one of the major sources causing such an invalid workflow process definition. So the conflicts caused by concurrent workflow processes should be considered deliberately when defining concurrent workflow processes. However it is very difficult to ascertain whether a workflow process is free from conflicts or not without any experimental executions at runtime. Which will be very tedious and time consuming work to process designers. If we can analyze the conflicts immanent in concurrent workflow definition prior to runtime, it will be very helpful to business process designers and many other users of workflow management system. In this paper, we propose a set-based constraint system to analyze possible read-write conflicts and write-write conflicts between activities which reads and writes to the shared variables in a workflow process definition. The system is composed of two phases. In the first phase, it generates set constraints from a structured workflow definition. In the second phase, it finds the minimal solution of the set constraints.

#*Concurrency Control Based on Order Constraints in Advanced Database Systems.
#@Haiyan Xu,Tetsuya Furukawa,Yihua Shi
#t1996
#cCODAS
#index105922

#*Caching and Concurrency Control in Mobile Client/Server Database Systems.
#@SangKeun Lee,Chong-Sun Hwang,Heon-Chang Yu
#t1999
#cCODAS
#index105923

#*Constraints for Information Cooperation in Virtual Enterprise Systems.
#@Xiaochun Yang,Ge Yu,Guoren Wang,Dan Wang,Baoyan Song
#t2001
#cCODAS
#index105924
#!In recent years, research about distributing information sources over network has become increasingly important. Here, we concentrate on the issues of information cooperation among heterogeneous virtual enterprise information sources. When a virtual enterprise was built up, enterprise information will be bound together with some constraints enforcing virtual enterprise logic across several enterprises. This paper explores the needs on the constraints in cooperative virtual enterprise information systems, and presents a cooperative model suitable for constructing a virtual enterprise. This is done through the constraint definition and constraint model developed in a virtual enterprise information integrating system named ViaScope. In order to manage these constraints effectively, the properties of distributed constraints are studied deeply. Further, some novel implementation issues in ViaScope system are provided including the cooperative architecture, constraint evaluation and an active rule based maintenance strategy.

#*The Semi Transaction Model for Cooperative Database Management.
#@Jai-Hyuk Lee,Yoon-Joon Lee,Pyung-Chul Kim
#t1996
#cCODAS
#index105925

#*Evaluation of Dynamic Representation of Roles by Environment Model.
#@Yusuke Yokota,Keiji Sugiyama,Hiroyuki Tarumi,Yahiko Kambayashi
#t1999
#cCODAS
#index105926

#*FAIRY: Personalized Information Dissemination System Based on How-Net.
#@Zhang Lei,Xiaoyong Du,Shan Wang
#t2001
#cCODAS
#index105927

#*Parallel Join Algorithms based on Parallel B+-trees.
#@Jianzhong Li,Wen-jun Sun,Yingshu Li
#t2001
#cCODAS
#index105928
#!Within the last several years, a number of parallel algorithms for the join operation have been proposed. However, almost all of the algorithms did not take advantage of the underlying parallel storage structures or data declustering methods of the operand relations. This paper introduces the concept of parallel storage structure or declustering aware parallel join algorithm. Two classes of parallel join algorithms, which take advantage of the underlying parallel B-tree index, are proposed and analyzed. One class is based on the rage-partition strategy. The other is based on the hash-partition strategy. The parallel execution times of the algorithms are linearly proportional to max{N/P, M/P}, where N and M are the numbers of tuples of the operand relations and P is the number of processing nodes. The proposed parallel join algorithms are compared with well known parallel join algorithms in practice. Theoretical and experimental results show that the proposed algorithms are more efficient than others in case of at least one operand relation having a parallel B-tree index on the join attributes.

#*Inter-agent Communication in Dynamic Distributed Information Systems.
#@Kazutoshi Yokoyama,Satoshi Hakomori,Ushio Inoue
#t1996
#cCODAS
#index105929

#*Export Database Derivation and Query Processing for Object-Oriented Wrappers.
#@Ee-Peng Lim,Hon-Kuan Lee
#t1996
#cCODAS
#index105930

#*Enriched Relationship Processing in Object-Relational Database Management Systems.
#@Nan Zhang,Norbert Ritter,Theo Härder
#t2001
#cCODAS
#index105931
#!In this paper, we bring together two important topics of current database research: enhancing the data model by refined relationship semantics and exploiting ORDBMS extensibility to equip the system with new functionality. Regarding the first topic, we introduce a framework to capture diverse semantic characteristics of application-specific relationships. Then, in order to integrate the conceptual extensions with the data model provided by SQL:1999, the second topic comes into play. Our efforts to realize semantically rich relationships by employing current ORDB technology clearly point up the benefits as well as the shortcomings of its extensibility facilities. Unfortunately, deficiencies still prevail in the OR-infrastructure, since the features specific to the extensions cannot sufficiently be taken into account by DBMS-internal processing such as query optimization, and there are very limited mechanisms of adequately supporting the required properties, e. g., by adjusted index and storage structures as well as suitable operational units of processing.

#*An Automated Integration Approach for Semi-Structured and Structured Data.
#@Seung Jin Lim,Yiu-Kai Ng
#t2001
#cCODAS
#index105932
#!As data access beyond traditional intranet boundary is popular on the Internet these days, the demand for an integrated and uniform method for accessing Web data sources that are different in structures and semantics is increasing. This demand is partly driven by users who want to access more diverse information, such as up-to-date information on stock market, entertainment, news, and science. The demand is also partly driven by information providers who provide information service to customers on the Web. In this paper, we present an approach to integrate semi-structured data sources and structured data sources by using an automated structure resolution approach. The structure resolution approach can easily be adopted to i) integrate existing relations in the relational database model into semi-structured data sources, and ii) merge sets of semi-structured data that have different structures with no human intervention. The integration of multiple data sources by using our approach results in the unified view (UV) of the data sources, which is presented in an XML DTD format. UV can be used for query optimization on heterogeneous data sources.

#*Cooperative Content Analysis Agents for Online Multimedia Indexing and Filtering.
#@Wensheng Zhou,Asha Vellaikal,Son K. Dao
#t2001
#cCODAS
#index105933

#*Interaction Adaptivity in Cooperative Agent for Emergent Process Management.
#@Aizhong Lin,John K. Debenham
#t2001
#cCODAS
#index105934

#*On the Optimization of Complex Spatial Queries.
#@Xiaofang Zhou,Yanchun Zhang,Xuemin Lin,Chengfei Liu
#t1999
#cCODAS
#index105935

#*Issues in an Entity-Relationship Based Federated Database System.
#@Tok Wang Ling,Mong-Li Lee
#t1996
#cCODAS
#index105936

#*An Ontology of Metadata for a Data Warehouse Represented in Description Logics.
#@Julieanne van Zyl,Dan Corbett,Millist W. Vincent
#t1999
#cCODAS
#index105937

#*Distributed Indexing and Querying of Unstructured Workgroup Data Using Cooperative Information Agents.
#@Craig Linn
#t1999
#cCODAS
#index105938

#*An Overview of the ROL Language.
#@Mengchi Liu
#t1996
#cCODAS
#index105939

#*Issues on Query Processing in Distributed and Interoperable Information Systems.
#@Ling Liu,Calton Pu
#t1996
#cCODAS
#index105940

#*Incremental Evaluation of Nest and Unnest Operators in Nested Relations.
#@Jixue Liu,Millist W. Vincent,Mukesh K. Mohania
#t1999
#cCODAS
#index105941

#*On Translation of Complex Value Calculus Queries with Arithmatic Operators.
#@Hong-Cheu Liu,Jeffrey Xu Yu,Chaiyaporn Chirathamjaree
#t1996
#cCODAS
#index105942

#*New Technologies (Multimedia - Hypertext - Hypermedia) Potential Use in Developing Countries.
#@Lamine Abdat,Belhadri Messabih
#t1994
#cCODATA
#index105943

#*Issues in the Transborder Flow of Scientific Data.
#@Shelton Alexander,Paul F. Uhlir
#t1994
#cCODATA
#index105944

#*MmtDB: The Metazoa Mitochonrial DNA Variants Specialized Database.
#@Marcella Attimonelli,D. Calo,A. Depascali,M. Porzio,F. Tanzariello,M. Vitale,Cecilia Saccone
#t1994
#cCODATA
#index105945

#*UNESCO Policy on Data Exchange: Grave Disparities in Scientific Data Access.
#@Adnan Badran
#t1994
#cCODATA
#index105946

#*Bioinformatics in the United States: Recent Trends from a Microbiological Perspective.
#@Lois D. Blaine
#t1994
#cCODATA
#index105947

#*ICSU Policy on Access to Data and Information.
#@Michael A. Chinnery
#t1994
#cCODATA
#index105948

#*Internet-Web and ST Data Management: Harmonization and New Horizons.
#@Jacques-Emile Dubois,Belhadri Messabih
#t1994
#cCODATA
#index105949

#*A Workbench for Bibliographic or Factual Data Handling.
#@Jacques Ducloy,Jean-Charles Lamirel,Emmanuel Nauer
#t1994
#cCODATA
#index105950

#*Numerical Databases - Can We Afford Them?
#@Ekkehard Fluck,Henry V. Kehiaian
#t1994
#cCODATA
#index105951

#*Barriers to International Technology Transfer.
#@Abdoulaye Gaye
#t1994
#cCODATA
#index105952

#*Information Highways: Internet and Web Services.
#@Nahum D. Gershon,William Ruh,Brian Dickens,Joshua LeVasseur
#t1994
#cCODATA
#index105953

#*A Few Facets of the Kaleidoscope of Scientific Information.
#@André Heck
#t1994
#cCODATA
#index105954

#*Integrated Information Management for Physics.
#@Eberhard R. Hilf,Bernd Diekmann,Heinrich Stamerjohanns,Jacob Curdes
#t1994
#cCODATA
#index105955

#*Protein Superfamily Database (Prosup).
#@Katsuhisa Horimoto,Kunio Oshima,Akira Tsugita,Jinya Otsuka
#t1994
#cCODATA
#index105956

#*Critical Factors for the Use of Public Databases.
#@Arild Jansen,Pål Sørgaard
#t1994
#cCODATA
#index105957

#*Structuring and Visualizing Hyperspace with Hyper-G.
#@Frank Kappe
#t1994
#cCODATA
#index105958

#*Onnline Electronic Publishing: Developing Infrastructure for the Electronic Reader.
#@Barbara E. Kirsop,Andy Edwards,Sidnei Souza
#t1994
#cCODATA
#index105959

#*Concerted Use of Multiple Databases for Taxonomic Insights.
#@Ashok S. Kolaskar,Prashant S. Naik
#t1994
#cCODATA
#index105960

#*The NASA Astrophysics Data System: A Heterogeneous Distributed Data Environment.
#@Michael J. Kurtz,Günther Eichhorn,Stephen S. Murray,Carolyn Stern-Grant,Alberto Accomazzi
#t1994
#cCODATA
#index105961

#*Bioinformatics - Pulling the European Strings Together.
#@M. L. Harrie Lalieu
#t1994
#cCODATA
#index105962

#*Epitope Data Bank.
#@Lunjiang Ling,Junko Shimura,Hideaki Sugawara,Akira Tsugita
#t1994
#cCODATA
#index105963

#*Teaching Biology by Video Images Assisted by Computer: Embryological Labroratories.
#@Valdiodio Ndiaye
#t1994
#cCODATA
#index105964

#*Integrated Ground-Based and Remotely Sensed Data to Support Global Studies of Environmental Change.
#@Richard J. Olson,Robert S. Turner,Charles T. Garten Jr.
#t1994
#cCODATA
#index105965

#*Guidelines of a European Meteorological Services Policy on Data Exchange.
#@Bartolomé Orfila
#t1994
#cCODATA
#index105966

#*Legal and Economic Aspects of Data Production and Transfer.
#@George Papapavlou
#t1994
#cCODATA
#index105967

#*Computer Networks with Episodic Links and the Use of Portable Computers.
#@Jean-Charles Profizi
#t1994
#cCODATA
#index105968

#*Dynamic Management of Cooperative Applications for Mobile Systems.
#@Pierre-Guillaume Raverdy,Phillipe Darche,Bertil Folliot
#t1994
#cCODATA
#index105969

#*Networking Africa's Scientific and Technical Information Resources.
#@Steve F. Rossouw
#t1994
#cCODATA
#index105970

#*Bioinformatics in East Asia.
#@Akira Tsugita
#t1994
#cCODATA
#index105971

#*The World-Wide Web: A Global Source of Data and Information.
#@Joel Winstead,Nahum D. Gershon
#t1994
#cCODATA
#index105972

#*The Development of a Scientific Research data Network System in China.
#@Zhihong Xu
#t1994
#cCODATA
#index105973

#*The State of Chinese Materials Databases.
#@Zhihong Xu
#t1994
#cCODATA
#index105974

#*Content-Based Information Retrival: New Tools for Textual Data, New Problems for Image Data.
#@Fionn Murtagh
#t1994
#cCODATA
#index105975

#*Communication synthesis and HW/SW integration for embedded system design.
#@Guy Gogniat,Michel Auguin,Luc Bianco,Alain Pegatoquet
#t1998
#cCODES
#index105976
#%106091
#%283380
#%450586

#*Codesign-extended applications.
#@Brian Grattan,Greg Stitt,Frank Vahid
#t2002
#cCODES
#index105977
#%106035
#%203172
#%203447
#%203232
#%141986
#%1056831
#%282252
#%106130
#%132357
#%106238
#%1081164
#%106329
#!We challenge the widespread assumption that an embedded system's functionality can be captured in a single specification and then partitioned among software and custom hardware processors. The specification of some functions in software is very different from the specification of the same function in hardware - too different to conceive of automatically deriving one from the other. We illustrate this concept using a digital camera example. We introduce the idea of codesign-extended applications to deal with the situation, wherein critical functions are written in multiple versions, and integrated such that simple compiler/synthesis flags instantiate a particular version along with the necessary control and communication behavior. By capturing a specification as a codesign-extended application, a designer enables smooth migration among platforms with increasing amounts of on-chip configurable logic.

#*An example of applying the codesign method MOOSE.
#@Peter Green,Paul Rushton,Ronnie Beggs
#t1994
#cCODES
#index105978
#%807024
#%777230
#%191
#%362134
#%522913
#!An extended example of the application of a new method for the Object Oriented codesign of embedded systems (MOOSE) is presented. The example concerns on intelligent video system which is currently being developed using MOOSE. The paper highlights the notable features of the method (including executablity and the commitment process) with reference to the design of the video system, and presents tentative conclusions regarding the method's suitablity for embedded system codesign.

#*Extending the SystemC synthesis subset by object-oriented features.
#@Eike Grimpe,Frank Oppenheimer
#t2003
#cCODES+ISSS
#index105979
#%450546
#%808229
#%142965
#!In this article we present an approach to object-oriented hardware design and synthesis based on SystemC. We will give an introduction to an extended SystemC synthesis subset which we propose, and, in particular, its object-oriented features. We will also briefly outline our basic synthesis concepts for object-oriented hardware specifications. Finally we will present some examples for the application of the extended synthesis subset, which are directly processable by a first synthesis tool prototype which we have developed for this purpose.

#*Memory size estimation for multimedia applications.
#@Peter Grun,Florin Balasa,Nikil D. Dutt
#t1998
#cCODES
#index105980
#%50074
#%116
#%1135094
#%1135020
#%134162
#%450680
#%132822
#%450628
#%282663

#*Instruction set selection for ASIP design.
#@Michael Gschwind
#t1999
#cCODES
#index105981
#%805564
#%1135386
#%132209
#%193907
#%132439
#%858227
#%142925

#*A framework for interactive analysis of timing constraints in embedded systems.
#@R. K. Gupta
#t1996
#cCODES
#index105982
#%1084324
#!An important goal of embedded system co-synthesis is to realize system designs under constraints on timing performance. We present applicable constraints and the notion of satisfiability of a given set of constraints. We describe a two-level system model that is useful for carrying out constraint analysis in presence of the timing and execution uncertainty inherent in embedded systems. We conclude by presenting a framework to determine constraint satisfiability and to interactively debug constraint violations. Examples are presented to show the utility of our approach.

#*Compiler-directed customization of ASIP cores.
#@T. Vinod Kumar Gupta,Roberto E. Ko,Rajeev Barua
#t2002
#cCODES
#index105983
#%418734
#%132193
#%193952
#%645137
#%106118
#%858227
#%2346
#%133850
#!This paper presents an automatic method to customize embedded application-specific instruction processors (ASIPs) based on compiler analysis. ASIPs, also known as embedded soft cores, allow certain hardware parameters in the processor to be customized for a specific application domain. They offer low design cost as they use pre-designed and verified components. Our design goal is choosing parameter values for fastest runtime within a given silicon area budget for a particular application set. Present-day technologies for choosing parameter values rely on exhaustive simulation of the application set on all possible combinations of parameter values -- a time-consuming and non-scalable procedure. We propose a compiler-based method that automatically derives the optimal values of parameters without simulating any configuration. Further, we expand the space of parameters that can be changed from the limited set today, and evaluate the importance of each. Results show that for our benchmarks, the runtimes for different configurations are predicted with an average error of 2.5%. In the two area constrained customization problem we evaluate, our method is able to recommend the same configuration that is recommended by brute force exhaustive simulation.

#*Constrained software generation for hardware-software systems.
#@Rajesh K. Gupta,Giovanni De Micheli
#t1994
#cCODES
#index105984
#%86944
#%858044
#%858325
#%858582
#%858146
#%600814
#%1084908
#%77
#%2353
#%1129460
#!Mixed systems are composed of interacting hardware components such as general-purpose processors, application-specific circuits and software components that executes on the general purpose hardware. The software component consists of application-specific routines that must deliver the required system functionality and a runtime environment. Further, the software is required to deliver functionality under constraints on timing and memory storage available. In this paper, we consider methods to achieve software generation under imposed constraints and demonstrate the utility of our approach by examples.

#*The analysis and design of architecture systems for speech recognition on modern handheld-computing devices.
#@Andreas Hagen,Daniel A. Connors,Bryan L. Pellom
#t2003
#cCODES+ISSS
#index105985
#%418565
#!Growing demand for high performance in embedded systems is creating new opportunities to use speech recognition systems traditionally executed only on high performance systems. In several ways, the needs of embedded computing differ from those of more traditional general-purpose systems. Embedded systems have more stringent constraints on cost and power consumption that lead to design bottlenecks for many computationally-intensive applications. This paper characterizes the speech recognition process on hand-held mobile devices and evaluates the use of modern architecture features and compiler techniques for performing real-time speech recognition. We evaluate the University of Colorado Sonic speech recognition software on the IMPACT architectural simulator and compiler framework. Experimental results show that by using a strategic set of compiler optimization, a 500MHz processor with moderate levels of instruction-level parallelism and cache resources can meet the real-time computing and power constraints of an advanced speech recognition application.

#*Rappit: framework for synthesis of host-assisted scripting engines for adaptive embedded systems.
#@Jiwon Hahn,Qiang Xie,Pai H. Chou
#t2005
#cCODES+ISSS
#index105986
#%16495
#%281938
#%539469
#%461749
#%807625
#%506893
#%296758
#!Scripting is a powerful, high-level, cross-platform, dynamic, easy way of composing software modules as black boxes. Unfortunately, the high runtime overhead has prevented scripting from being widely adopted in embedded applications. This work proposes to overcome these obstacles by synthesizing light-weight, host-assisted scripting engines for embedded systems. The result is dramatically shortened development cycle due to the much higher-level abstraction, interactive access and dynamic reconfigurability, robust in-field software upgradability, and compact code size. This framework has been successfully applied to ultra low-power sensor nodes with under 10KB of program memory to high-performance platforms with fast Ethernet.

#*Memory accesses management during high level synthesis.
#@Gwenolé Corre,Eric Senn,Pierre Bomel,Nathalie Julien,Eric Martin
#t2004
#cCODES+ISSS
#index105987
#!We introduce a new approach to take into account the memory architecture and the memory mapping in behavioral synthesis. We formalize the memory mapping as a set of constraints for the synthesis, and defined a Memory Constraint Graph and an accessibility criterion to be used in the scheduling step. We present a new strategy for implementing signals (ageing vectors). We formalize the maturing process and explain how it may generate memory conflicts over several iterations of the algorithm. The final Compatibility Graph indicates the set of valid mappings for every signal. Several experiments are performed with our HLS tool GAUT. Our scheduling algorithm exhibits a relatively low complexity that permits to tackle complex designs in a reasonable time.

#*Processor frequency setting for energy minimization of streaming multimedia application.
#@Andrea Acquaviva,Luca Benini,Bruno Riccò
#t2001
#cCODES
#index105988
#%133920
#%436942
#%436796
#%436574
#%141346
#%646055
#!In this paper, we describe a software-controlled approach for adaptively minimizing energy in embedded systems for realtime multimedia processing. Energy is optimized by clock speed setting: the software controller dynamically adjusts processor clock speed to the frame rate requirements of the incoming multimedia stream. The speed-setting policy is based on a system model that correlates clock speed with best-case, average-case and worst-case sustainable frame rate, accounting for data-dependency in multimedia streams. Experiments on an MP3 decoding application show that computational energy can be drastically reduced with respect to fixed-frequency operation.

#*Comparing the size of .NET applications with native code.
#@Roberto Costa,Erven Rohou
#t2005
#cCODES+ISSS
#index105989
#%106215
#%465214
#%2346
#!Byte-code based languages are slowly becoming adopted in embedded domains because of improved security and portability. Another potential reason for their adoption is the reputation for smaller code size than native. This is critical in contexts in which a small memory footprint is crucial to reduce production costs. This paper compares the code size of applications compiled for .NET framework with the same natively compiled for various processors. The paper shows that the assumption of an impressive code size reduction is not reachable and it suggests that the adoption of such languages in embedded contexts be justified by additional arguments. The paper also studies the reasons for this and it compares with the compression ratios achievable for various applications through alternative techniques.

#*RS-FDRA: a register sensitive software pipelining algorithm for embedded VLIW processors.
#@Cagdas Akturan,Margarida F. Jacome
#t2001
#cCODES
#index105990
#%106164
#%234133
#%499151
#%1124579
#%450464
#%542636
#%499212
#%132288
#!The paper proposes a novel software-pipelining algorithm, Register Sensitive Force Directed Retiming Algorithm (RS-FDRA), suitable for optimizing compilers targeting embedded VLIW processors. The key difference between RS-FDRA and previous approaches is that our algorithm can handle code size constraints along with latency and resource constraints. This capability enables the exploration of pareto &ldquo;optimal&rdquo; points with respect to code size and performance. RS-FDRA can also minimize the increase in &ldquo;register pressure&rdquo; typically incurred by software pipelining. This ability is critical since, the need to insert spill code may result in significant performance degradation. Extensive experimental results are presented demonstrating that the extended set of optimization goals and constraints supported by RS-FDRA enables a thorough compiler-assisted exploration of trade-offs among performance, code size, and register requirements, for time critical segments of embedded software components.

#*Approach to the Synthesis of HW and SW in Codesign.
#@Vincenza Carchiolo,Michele Malgeri,Giuseppe Mangioni
#t1997
#cCODES
#index105991
#%450666
#%555101
#%793483
#%132209
#%106348
#!The main aim of codesign is to be able to design a whole system without excessive preliminary constraints on the mapping or partitioning of the hardware and software parts. At present, given the availability of CAD tools and hardware devices, the sector which seems to offer most prospects of codesign methodology application is that of embedded systems. This paper presents a codesign approach based on the formal technique called TTL. It shows how the synthesis of both the HW and SW modules described by TTL into RTL or C respectively can be performed thanks to a semantic based translation.

#*Fast performance prediction for periodic task systems.
#@Xiaobo Sharon Hu,Gang Quan
#t2000
#cCODES
#index105992
#%1078402
#%564265
#%858146
#%565092
#%1128264
#%133756
#%1128420
#%564592
#%996974
#%1081894
#!During design exploration, many implementations of the same system specification may need to be evaluated. In this paper, we present an approach to construct sufficient and necessary conditions for a given system specifications. These conditions can be employed in the design exploration process to rapidly determine if an implementation of the system satisfies the timing constraints. We prove that our conditions always outperform the existing respective conditions. Experimental results are also provided to compare our approach with known scheduling results.

#*System-level partitioning with uncertainty.
#@Jones Albuquerque,Claudionor José Nunes Coelho Jr.,Carlos Frederico Cavalcanti,Diógenes Cecilio da Silva Jr.,Antônio Otávio Fernandes
#t1999
#cCODES
#index105993
#%1500634
#%131250
#%857989
#%106135
#%1071068
#%806955
#%1129218

#*Multilanguage design of heterogeneous systems.
#@Philippe Coste,F. Hessel,P. LeMarrec,Zoltan Sugar,M. Romdhani,Rodolph Suescun,Nacer-Eddine Zergainoh,Ahmed Amine Jerraya
#t1999
#cCODES
#index105994
#%106328
#%24887
#%1056831
#%450621
#%106201
#%106218
#%106222
#%282905
#%193781
#%133702
#%858582
#%134401
#%106380

#*A Flexible Model for Evaluating the Behavior of Hardware/Software Systems.
#@Alberto Allara,S. Filipponi,Fabio Salice,William Fornaciari,Donatella Sciuto
#t1997
#cCODES
#index105995
#%193938
#%2595
#!Hardware-software co-design in becoming a "must" for many embedded applications requiring to tradeoff a number of constraints such as size, cost, performance, real-time requirements, design flexibility, etc. . Even if, according to purpose of the digital system, the range of possible architectures is rather wide, for our field of interest (telecom embedded systems) the target architecture can be roughly described as composed of a microprocessor surrounded by some hardware modules connected through buses. The aim of this paper is to present a model (and the related CAD environment) supporting the simultaneous analysis of functionality, timing performance (in terms of execution time of hw and sw modules and bus use), and execution profile of the system specification assuming the given target architecture. The goal of the proposed approach has been to define a simulation algorithm able to consider the partition of each section of the specification and the consequent bus traffic at the system level, in order to enable the designer to efficiently debug and evaluate the specification while considering the timing issues of a mixed hw-sw architecture very close to the final one. The paper gives also the flavor of the CAD environment built around the presented simulation strategy.

#*First results with eBlocks: embedded systems building blocks.
#@Susan Cotterell,Frank Vahid,Walid A. Najjar,Harry Hsieh
#t2003
#cCODES+ISSS
#index105996
#%891765
#%808414
#%1008445
#%956289
#!We describe our first efforts to develop a set of off-the-shelf hardware components that ordinary people could connect to build a simple but useful class of embedded systems. The class of systems, which we call monitor/control systems, is composed primarily of sensors - light, motion, sound, contact, and other types - and output devices - light-emitting diodes, beeping speakers, or even electric relays that control electric appliances like lamps. For example, one monitor/control system would detect if a house's garage door was open at night, and would blink an LED inside the house to alert the homeowner of this normally undesirable situation. Today, configuring even the most basic monitor/control system requires knowledge of electronics and programming. We seek to create a set of building blocks, which we call eBlocks, that would enable someone with no knowledge of electronics or programming to be able to build simple but useful monitor/control systems. We are creating eBlocks largely by incorporating intelligence into previously dumb sensors and output devices, and by developing a set of standards and methods that enable eBlocks to work together seamlessly when connected. eBlocks have only recently become possible due to the extremely low cost, low power, and small size of embedded microprocessors. We describe our first results of creating a basic class of eBlocks, Boolean eBlocks, that from a user's perspective transmit or receive only "yes" or "no" signals. We discuss the internal eBlock design, eBlock system design issues and decisions, and several eBlock-based systems designed by ourselves and by undergraduate students.

#*Deriving hard real-time embedded systems implementations directly from SDL specifications.
#@José M. Álvarez,Manuel Díaz,Luis Llopis,Ernesto Pimentel,José M. Troya
#t2001
#cCODES
#index105997
#%1053103
#!Object-Oriented methodologies together with Formal Description Techniques (FDT) are a promising way to deal with the increasing complexity of hard real-time embedded systems. However, FDTs do not take into account non-functional aspects as real-time constraints. Based on a new real-time execution model for FDT SDL proposed in previous works, a way to derive implementations of hard real-time embedded systems directly from SDL specifications is presented. In order to get it we propose a middleware that supports this model to organize the execution of the tasks generated from SDL system specification. Additionally, a worst case real-time analysis, including the middleware overhead, is presented. Finally, an example to generate the implementation from the SDL specification and a performance study is developed.

#*Future challenges in embedded systems.
#@Andrea Cuomo
#t2004
#cCODES+ISSS
#index105998
#!Embedded Systems will play a key role to drive the technological evolution in the next 20 years. Their evolution will further accelerate with the diffusion of the novel technologies that will deeply change our scenario, among which we can mention nanotechnologies, bioelectronics, and photonics. The central role of embedded systems in the economy will grow stronger and stronger: the starting point is the convergence between storage, security, video, audio, mobility and connectivity.Systems are converging and ICs are more and more converging with systems: this poses a number of challenges for designers and technologists. A key issue is the definition of the right methodologies to translate system knowledge and competences into complex embedded systems, taking into account many system requirements and constraints.The key factor to win this challenge is to build the right culture. This means to be able to build the right environment to exploit existing design, architectural and technological solutions, and to favor the transfer of knowledge from one application field into another.

#*Heuristic tradeoffs between latency and energy consumption in register assignment.
#@R. Anand,Margarida F. Jacome,Gustavo de Veciana
#t2000
#cCODES
#index105999
#%132301
#%450613
#%132822
#%499500
#!One of the challenging tasks in code generation for embedded systems is register allocation and assignment, wherein one decides on the placement and lifetimes of variables in registers. When there are more live variables than registers, some variables need to be spilled to memory and restored later. In this paper we propose a policy that minimizes the number of spills &mdash; which is critical for portable embedded systems since it leads to a decrease in energy consumption. We argue however, that schedules with a minimal number of spills do not necessarily have minimum latency. Accordingly, we propose a class of policies that explore tradeoffs between assignments leading to schedules with low latency versus those leading to low energy consumption and show how to tune them to particular datapath characteristics. Based on experimental results we propose a criterion to select a register assignment policy that for 99% of the cases we considered minimizes both latency and energy consumption associated with spills to memory.

#*Industry best practices in embedded software.
#@Raul Camposano,Mark Underseth,Faraydon Karim
#t2003
#cCODES+ISSS
#index106000
#!Software is a growing part of the embedded systems industry in a range of applications. This session features presenters from automotive, wireless, and medical devices companies to share their experiences in developing software for todays cutting edge applications.

#*HDL code restructuring using timed decision tables.
#@Jian Li,Rajesh K. Gupta
#t1998
#cCODES
#index106001
#%949671
#%132226
#%282460
#%858144
#%77

#*A methodology for control-dominated systems codesign.
#@Stefano Antoniazzi,Alessandro Balboni,William Fornaciari,Donatella Sciuto
#t1994
#cCODES
#index106002
#%858362
#%858044
#%858325
#%858146
#%134304
#%362134
#!This paper presents a methodology and a supporting framework for the design of systems composed of hardware and software modules. The aim is to define an approach, tailored for control-oriented applications, to manage system cospecification, high-level partitioning, hw/sw tradeoffs and cosynthesis. The main goals are always to improve design time and costs by supporting a flexible architectural exploration and to achieve a smooth integration within standard industrial design environments.Our research effort focuses on fulfilling the goal of linking high-level specifications to efficient and cost-effective hw/sw implementations, by investigating techniques such as synchronous cospecification styles, direct machine code generation as well as exploiting the capability of commercial VHDL synthesizers.

#*Configuration-level hardware/software partitioning for real-time embedded systems.
#@Joseph G. D'Ambrosio,Xiaobo Sharon Hu
#t1994
#cCODES
#index106003
#%132333
#%858044
#%858582
#%858146
#!In this paper, we present an approach to hardware/software partitioning for real-time embedded systems. The abstraction level we have adopted is referred to as the configuration level, where hardware is modeled as resources with no detailed functionality and software is modeled as tasks utilizing the resources. Through configuration-level analysis, cost and performance tradeoffs can be studied early in the design process and a large design space can be explored. Feasibility factor is introduced to measure the possibility of a real-time system being feasible, and is used as both a constraint and an attribute during the optimization process. Optimal partitioning is achieved through the use of an existing computer-aided design tool.

#*Designing domain-specific processors.
#@Marnix Arnold,Henk Corporaal
#t2001
#cCODES
#index106004
#%106006
#%499444
#%282591
#%132439
#%193907
#%419107
#%1082479
#%1123225
#!We present a semi-automated method for the detection and exploitation of application domain specific instruction set extensions for embedded (VLIW) processors. It consists of three steps: the first step detects frequently occurring operation patterns, in the second step, the patterns are grouped and implemented in a number of Special Function Units (SFUs) and the third step incorporates the custom operations into the code generation process. Experiments show that the SFUs generated and exploited with our methodology can result in architectures that perform up to 30% better than architectures of the same cost without SFUs.

#*System level memory optimization for hardware-software co-design.
#@Koen Danckaert,Francky Catthoor,Hugo De Man
#t1997
#cCODES
#index106005
#%86927
#%450666
#%196277
#%858044
#%858146
#%858145
#!Application studies in the areas of image and video processing systems indicate that between 50 and 80% of the area cost in (application-specific) architectures for real-time multi-dimensional signal processing (RMSP) is due to data storage and transfer of array signals. This is true for both single- and multi-processor realizations, both customized and (embedded) programmable targets. This paper has two main contributions. First, to reduce this dominant cost, we propose to address the system-level storage organization for the multi-dimensional (M-D) signals as a first step in the overall methodology to map these applications, before the HW/SW-partitioning decision. Secondly, we will demonstrate the usefulness of this novel approach based on a realistic test-vehicle, namely a quad-tree based image coding application.

#*Automatic detection of recurring operation patterns.
#@Marnix Arnold,Henk Corporaal
#t1999
#cCODES
#index106006
#%769531
#%77
#%805564
#%132803
#%282591
#%1082479

#*A strongly polynomial-time algorithm for over-constraint resolution: efficient debugging of timing constraint violations.
#@Ali Dasdan
#t2002
#cCODES
#index106007
#%446377
#%186029
#%131778
#%2020
#%930967
#%106129
#%133005
#%1117866
#%565367
#%133809
#%234211
#%1135055
#!A system of binary linear constraints or difference constraints (SDC) contains a set of variables that are constrained by a set of unary or binary linear inequalities. In such diverse applications as scheduling, interface timing verification, real-time systems, multimedia systems, layout compaction, and constraint satisfaction, SDCs have successfully been used to model systems of both temporal and spatial constraints. Formally, SDCs are modeled by weighted, directed (constraint) graphs. The consistency of an SDC means that there is at least one instantiation of its variables that satisfies all its constraints. It is well known that the absence of positive cycles in a graph implies the consistency of the corresponding SDC, so the consistency can be decided in strongly polynomial time. If a SDC is found to be inconsistent, it has to be repaired to make it consistent. This task is equivalent to removing positive cycles from the corresponding graph. All the previous algorithms for this task take time proportional to the number of positive cycles in the graph, which can grow exponentially. In this paper, we propose a strongly polynomial-time algorithm, i.e., an algorithm whose time complexity is polynomial in the size of the graph. Our algorithm takes in a graph and returns a list of edges and the changes in their weights to remove all the positive cycles from the graph. We experimentally quantify the length of the edge list and the running time of the algorithm on large benchmark graphs. We show that both are very small, so our algorithm is practical.

#*Enhancing security through hardware-assisted run-time validation of program data properties.
#@Divya Arora,Anand Raghunathan,Srivaths Ravi,Niraj K. Jha
#t2005
#cCODES+ISSS
#index106008
#%546557
#%542393
#%636117
#%636869
#%202209
#%53756
#%141315
#%133639
#%485806
#%601338
#!The growing number of information security breaches in electronic and computing systems calls for new design paradigms that consider security as a primary design objective. This is particularly relevant in the embedded domain, where the security solution should be customized to the needs of the target system, while considering other design objectives such as cost, performance, and power. Due to the increasing complexity and shrinking design cycles of embedded software, most embedded systems present a host of software vulnerabilities that can be exploited by security attacks. Many attacks are initiated by causing a violation in the properties of data ( e.g., integrity, privacy, access control rules, etc.) associated with a "trusted" program that is executing on the system, leading to a range of undesirable effects.In this work, we develop a general framework that provides security assurance against a wide class of security attacks. Our work is based on the observation that a program's permissible behaviorwith respect to data accesses can be characterized by certain properties. We present a hardware/software approach wherein such properties can be encoded as data attributes and enforced as security policies during program execution. These policies may be application-specific (e.g., access control for certain data structures), compiler-generated (e.g., enforcing that variables are accessed only within their scope), or universally applicable to all programs (e.g., disallowing writes to unallocated memory). We show how an embedded system architecture can support such policies by (i) enhancing the memory hierarchy to represent the attributes of each datum as security tags that are linked to it through its lifetime, and (ii) adding a configurable hardware checker that interprets the semantics of the tags and enforces the desired security policies. We evaluated the effectiveness of the proposed architecture in enforcing various security policies for several embedded benchmarks. Our experiments in the context of the Simplescalar framework demonstrate that the proposed solution ensures run-time validation of program data properties with minimal execution time overheads.

#*Hardware/software co-design of an ATM network interface card: a case study.
#@Jean-Marc Daveau,Gilberto Fernandes Marchioro,Ahmed Amine Jerraya
#t1998
#cCODES
#index106009
#%1491969
#%106217
#%450647
#%806605
#%450680
#%858067
#%858582
#%106346

#*Parameterised system design based on genetic algorithms.
#@Giuseppe Ascia,Vincenzo Catania,Maurizio Palesi
#t2001
#cCODES
#index106010
#%106110
#%282163
#%106326
#%450542
#%1135158
#%858028
#%52285
#!A recent reduction in the time to market has led to the development of a new approach to IP-based design in which a highly parametric pre-designed system-on-a-chip is configured according to the application it will have to execute. The greatest problems in this area regard exploration of the range of possible system configurations in search of the optimal configuration for a given system. There are, in fact, a number of parameters involved (bus sizes, cache configurations, software algorithms, etc.), each of which has a great impact on design constraints such as area, power and performance. An exhaustive analysis of all possible configurations is thus computationally unfeasible. In this paper we propose using genetic algorithms to determine the optimal configuration for a highly parametric system. The approach is applied to the search for the optimal configuration (in terms of area, power and mean access time) of a memory hierarchy involved in a given application.

#*Software/hardware Co-Design in the MuSE environment.
#@Matthias Deegener,Sorin A. Huss
#t1994
#cCODES
#index106011
#%86939
#%169983
#%469119
#%2595
#!The research project MuSE provides an integrated software environment for the development of complex technical systems. MuSE supports the system engineer by its tools for the specification, simulation and validation of the system's behavior. MuSE also provides the structured archiving of all documents in a hypermedia database. This paper will focus on the specification and validation of the system's behavior, especially on the concepts and tools for Software/Hardware Co-Design and Co-Simulation in the MuSE environment.

#*Multi-objective mapping for mesh-based NoC architectures.
#@Giuseppe Ascia,Vincenzo Catania,Maurizio Palesi
#t2004
#cCODES+ISSS
#index106012
#!In this paper we present an approach to multi-objective exploration of the mapping space of a mesh-based network-on-chip architecture. Based on evolutionary computing techniques, the approach is an efficient and accurate way to obtain the Pareto mappings that optimize performance and power consumption. Integration of the approach in an exploration framework with a kernel based on an event-driven trace-based simulator makes it possible to take account of important dynamic effects that have a great impact on mapping. Validation on both synthesized traffic and real applications (an MPEG-2 encoder/decoder system) confirms theefficiency, accuracy and scalability of the approach.

#*Timed executable system specification of an ADSL modem using a C++ based design environment: a case study.
#@Dirk Desmet,Michiel Esvelt,Prabhat Avasare,Diederik Verkest,Hugo De Man
#t1999
#cCODES
#index106013
#%132380
#%133805

#*An integer linear programming approach for identifying instruction-set extensions.
#@Kubilay Atasu,Günhan Dündar,Can C. Özturan
#t2005
#cCODES+ISSS
#index106014
#%141414
#%77474
#%214265
#%498980
#%566376
#!This paper presents an Integer Linear Programming (ILP) approach to the instruction-set extension identification problem. An algorithm that iteratively generates and solves a set of ILP problems in order to generate a set of templates is proposed. A selection algorithm that ranks the generated templates based on isomorphism testing and potential evaluation is described. A Trimaran based framework is used to evaluate the quality of the instructions generated by the technique. Speed-up results of up to 7.5 are observed.

#*On-chip communication design: roadblocks and avenues.
#@Luca P. Carloni,Alberto L. Sangiovanni-Vincentelli
#t2003
#cCODES+ISSS
#index106015
#%131871
#%281958
#%281800
#%418427
#%142416
#%419484
#%1008371
#%807357
#!The semiconductor industry is experiencing a paradigm shift from "computation-bound design" to "communication-bound design": the number of transistors that can be reached in a clock cycle, and not those that can be integrated on a chip, will drive the design process. Interconnect latency will have a major impact on the design of on-chip communication architectures, which increasingly rely on wire pipelining to go beyond the capabilities of traditional wire buffering. The insertion of stateful repeaters on long wires, instead of simply stateless repeaters, carries major consequences for the synchronous design methodology. This is the foundation of the design ows for the majority of commercial chips today, but, if left unchanged, will lead to an exacerbation of the timing closure problem for tomorrows design ows. New methodologies that regard the chip as a distributed system are necessary. Latency-insensitive design is a step in this direction.

#*Design technology challenges for system and chip level designs in very deep submicron technologies.
#@James Lin
#t2003
#cCODES+ISSS
#index106016
#!With very deep submicron process technologies, previously ignorable phenomena now have great impact on the robustness of IC designs. At the same time, the smaller feature sizes also enable an exponential increase in number of functions (or transistor count) available on chip. Complexity in process technology and design is widening the Design Technology gap, which, if not addressed properly, will threaten the continuation of process scaling and the industry's ability to benefit from it. The complexity of process and design technology, its impact on new designs, new products development and future solutions will be discussed in this presentation. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player

#*Towards a multi-formalism framework for architectural synthesis: the ASAR project.
#@Michel Auguin,Mohamed Belhadj,Judith Benzakki,C. Carrière,Guy Durrieu,Thierry Gautier,Michel Israël,Paul Le Guernic,Michel Lemaître,E. Martin,P. Quinton,Laurence Rideau,François Rousseau,Olivier Sentieys
#t1994
#cCODES
#index106017
#%806605
#%808572
#%858044
#%858146
#%1165956
#%578677
#!This paper describes a research project - named ASAR - grouping together six french research teams, oriented towards architectural and system synthesis. A main concern of this project is hardware/software codesign and user interface management.

#*A power estimation methodology for systemC transaction level models.
#@Nagu R. Dhanwada,Ing-Chao Lin,Vijaykrishnan Narayanan
#t2005
#cCODES+ISSS
#index106018
#%131436
#%133632
#%450585
#%141552
#%283469
#%106063
#!Majority of existing works on system level power estimation have focused on the processor, while there are very few that address power consumption of peripherals in a SoC. With the presence of complex cores in current day embedded system-on-chip devices, the problem of complete system level power estimation is gaining significance. Transaction level models for SoCs are gaining increasing attention with emerging architectural modeling standards like SystemC. In this paper we present a methodology for performing system power estimation for different scenarios or applications being executed on these transaction level models. We describe techniques and a setup for transaction level power characterization, and an approach to augment SystemC transaction level models to perform transaction level power estimation. We also present experimental results to validate the accuracy and speed of our approach.

#*Automatic exploration of VLIW processor architectures from a designer's experience based specification.
#@Michel Auguin,Fernand Boéri,C. Carrière
#t1994
#cCODES
#index106019
#%808572
#%378394
#%378478
#%858044
#%858146
#%131526
#%77
#%360147
#!This paper presents a new synthesis approach for dedicated systems. The aim of our synthesis scheme is to achieve an automatic exploration of VLIW processor architectures from a pure C description of the input system. The innovation consists in the fact that unit allocation must manage the fact that a function may be realized either by dedicated functional units or by a set of lower-level efficiently controlled functional units. For example, execution of a square root function can be accomplished by two ways: either by a dedicated functional unit or by an oriented software implementation of Newton's iterations. The aim is to find the best global trade-off between all the candidate architectures. In order to illustrate this synthesis scheme, we give an example issued from a sonar application.

#*TGFF: task graphs for free.
#@Robert P. Dick,David L. Rhodes,Wayne Wolf
#t1998
#cCODES
#index106020
#%283380
#%282057
#%131937

#*Architecture Synthesis and Partitioning of Real-Time Systems: A Comparison of Three Heuristic Search Strategies.
#@Jakob Axelsson
#t1997
#cCODES
#index106021
#%1275328
#%858044
#%450556
#%1053256
#!This paper studies the problem of automatically selecting a suitable system architecture for implementing a real-time application. Given a library of hardware components, it is shown how an architecture can be synthesized with the goal of fulfilling the real-time constraints stated in the system's specification. In case the selected architecture contains several processing units, the specification is partitioned by assigning tasks to these. The use of three heuristic search techniques is investigated: genetic algorithms, simulated annealing, and tabu search; and it is described how these can be adapted to the architecture synthesis problem. It is concluded that tabu search is the most promising technique, but that simulated annealing is also applicable.

#*Transaction level modeling: flows and use models.
#@Adam Donlin
#t2004
#cCODES+ISSS
#index106022
#!Transaction-level models (TLMs) address the problems of designing increasingly complex systems by raising the level of design abstraction above RTL. However, TLM terminology is presently a subject of contentious debate and a coherent set of TLM use-models have not been proposed. In this paper we propose a variety of TLM use-models that reveal paths through the TLM abstraction levels for various types of system. We begin by stating the abstraction levels that comprise ýtransaction-levelý and identify roles and responsibilities that apply within the use-models. We then take each use-model and discuss the type of system it applies to, the TLM abstraction levels it supports, and the design activites applied at those levels. We also consider the distribution of modeling effort between the various design rôles and apply that to descriptions of various use-model design flows.

#*Large exploration for HW/SW partitioning of multirate and aperiodic real-time systems.
#@Abdenour Azzedine,Jean-Philippe Diguet,Jean-Luc Pillippe
#t2002
#cCODES
#index106023
#%131933
#%106188
#%132715
#%131357
#%106107
#%106032
#%565076
#%106238
#%141753
#%141834
#%858146
#%562649
#%106120
#%450609
#!This paper addresses the domain of fine and coarse grain HW / SW codesign for Real-Time System On-Chip. We propose a new method for the real-time scheduling and the HW / SW partitioning of multi-rate or aperiodic tasks. The large design space exploration is based on parallelism/delay trade-off curves.

#*Driving agenda for systems research.
#@Nik Dutt,Janos Sztipanovits,Masaki Hirata
#t2003
#cCODES+ISSS
#index106024
#!This panel will bring together members who are responsible for leading research directions in embedded systems, Systems-on-Chip (SOCs), and the attendant software and hardware, through their roles in funding research, coordinating industrial consortia, chairing professional societies, and building a community of systems researchers. The panelists will share their views on research challenges in systems, opportunities for research funding, and the role of academics, tool vendors, industry, and consortia in solving challenges for the design and development of next generation embedded systems.

#*STARS of MPEG decoder: a case study in worst-case analysis of discrete-event systems.
#@Felice Balarin
#t2001
#cCODES
#index106025
#%281635
#%132734
#%106027
#%141375
#%106352
#%546049
#!STARS (STatic Analysis of Reactive Systems) is a methodology for worst-case analysis of discrete systems. Theoretical foundations of STARS have been laid down [1, 2, 3], but no implementation has been presented so far. We introduce an implementation of STARS as an extension of YAPI, a programming interface used to model signal processing applications as process networks [7]. We apply STARS to a YAPI model of an MPEG decoder. We show that worst-case bounds computed by STARS are quite close to simulated values (within 15%). We also show that additional effort by the designer required to build STARS models is very small compared to effort of building the YAPI simulation model, and that the run times of STARS are negligible compared to the simulation run times.

#*Exploring design space of parallel realizations: MPEG-2 decoder case study.
#@Basant Kumar Dwivedi,Jan Hoogerbrugge,Paul Stravers,M. Balakrishnan
#t2001
#cCODES
#index106026
#%132734
#%106352
#%502762
#%408213
#%833088
#%9794
#!Many applications lend them to parallelism at different levels of granularity. We first identify the key issues involved in creating a parallel model of an application. These are done with a view to estimate performance and explore the &ldquo;parallel&rdquo; design space to select a suitable design point. The framework presented provides an opportunity to perform this exploration both in the target architecture independent and target architecture dependent manner. An MPEG-2 decoder model in YAPI has been presented which has more parallelism and improved performance. This modal has further been mapped onto SpaceCAKE architecture to study its architectural parameters. Detailed results obtained with YAPI simulation (target architecture independent) and TSS simulation (after process-processor binding) on MPEG-2 decoder application establish the effectiveness of our approach.

#*Worst-case analysis of discrete systems based on conditional abstractions.
#@Felice Balarin
#t1999
#cCODES
#index106027
#%267208
#%483566
#%131357
#%79650

#*New architectures for smart cards: the OCEAN approach.
#@Olivier Caron,Vincent Cordonnier,Philippe Durif,Georges Grimonprez
#t1994
#cCODES
#index106028
#%1275616
#!There are today many and important reasons for giving future smart card generation new processors. This requirement is the result of more sophisticated applications that have to respect specific constraints such as response time and memory capacities.In a smart card, hardware and software and closely interdependent because the code is stored in a rom at the production level. Thus, both hardware and software must be realized in an unique design process.OCEAN project (Outils de Conception et d'Evaluation d'Architectures Nouvelles) has been proposed to respond to that constraint. It bring the possibility to obtain a global evaluation of the chip and its embedded software. The project comprise the OCEAN Hardware description language, a specific C compiler to produce the application, a generic translator and an evaluation tool.OCEAN is a part of the ESPRIT CASCADE project.

#*Hardware-software cosynthesis of multi-mode multi-task embedded systems with real-time constraints.
#@Hyunok Oh,Soonhoi Ha
#t2002
#cCODES
#index106029
#%106150
#%133895
#%106032
#%196018
#%282409
#!An embedded system is called multi-mode when it supports multiple applications by dynamically reconfiguring the system functionality. This paper proposes a hardware-software cosynthesis technique for multi-mode multi-task embedded systems with real-time constraints. The cosynthesis problem involves three subproblems: selection of appropriate processing elements, mapping and scheduling of function modules to the selected processing elements, and schedule analysis. The proposed cosynthesis framework defines an iteration loop of three steps that solve the subproblems separately. One of the key benefits of such a modular approach is extensibility and adaptability. Moreover, unlike the previous approaches, the proposed technique considers task sharing between modes and hardware sharing between tasks at the same time. We demonstrate the usefulness of the proposed technique with a realistic multimode embedded system that supports three modes of operation with 5 different tasks.

#*Automatic Generation of a Real-Time Operating System for Embedded Systems.
#@Felice Balarin,Massimiliano Chiodo,Attila Jurecska,Luciano Lavagno,Bassam Tabbara,Alberto L. Sangiovanni-Vincentelli
#t1997
#cCODES
#index106030
#%106128
#%450666
#!Embedded systems are typically implemented as a set of communicating components some of which are implemented in hardware and some of which are implemented in software. Usually many software components share a processor. A real-time operating system (RTOS) is used to enable sharing and provide a communication mechanism between components. Commercial RTOSs are available for many popular micro-controllers. Using them provides significant reduction in design time and often leads to better structured and more maintainable systems. However, since they have to be quite general, they are not efficient enough for many applications, either in memory usage or in run times. Thus, it is often the case that RTOSs are hand coded by an expert for a particular application. This approach is obviously slow, expensive and error-prone.In this paper we propose an alternative where a RTOS is automatically generated based on a high-level description of the system. RTOSs created in our approach offer an ease of use comparable to commercial RTOSs, and yet since they are generated for a specific example, they can be optimized based on the same information used to optimize hand-written code. We have implemented our approach within POLIS, a system for HW/SW co-design of embedded system. To evaluate the POLIS-generated RTOS we have developed a prototyping environment which we use to compare POLIS against a commercial operating system.

#*Tracking object life cycle for leakage energy optimization.
#@Guangyu Chen,Narayanan Vijaykrishnan,Mahmut T. Kandemir,Mary Jane Irwin,Mario Wolczko
#t2003
#cCODES+ISSS
#index106031
#%499251
#%521990
#%522902
#%252752
#%418760
#%9893
#%499027
#%419005
#!The focus of this work is on utilizing the state of objects during their lifespan in optimizing the leakage energy consumed in the data caches when executing embedded Java applications. Our analysis reveals that a major portion of the leakage energy is actually wasted in retaining the objects beyond their last use. In order to eliminate this wastage, we investigate three approaches that use the garbage collector, escape analysis and last use analysis for reducing leakage energy. Finally, we track the access gap between successive object accesses to reduce leakage energy of live objects. A combination of these schemes is shown to provide 21% data cache leakage energy reduction in our default configuration.

#*A hardware-software cosynthesis technique based on heterogeneous multiprocessor scheduling.
#@Hyunok Oh,Soonhoi Ha
#t1999
#cCODES
#index106032
#%106150
#%131937
#%196018

#*Concurrent execution semantics and sequential simulation algorithms for the metropolis meta-model.
#@Felice Balarin,Luciano Lavagno,Claudio Passerone,Alberto L. Sangiovanni-Vincentelli,Yosinori Watanabe,Guang Yang
#t2002
#cCODES
#index106033
#%132734
#%546225
#%282365
#!This paper presents the simulation techniques that are available in Metropolis, an inter-disciplinary research project that develops a design methodology, supported by a comprehensive design environment and tool set, for embedded systems. System behavior is non-deterministic in general, especially in the beginning of the design process, when several key decision, such as the mapping on an implementation platform, have not yet been made, and thus the traces obtainable by simulation are not unique even under the same input sequence. One may want to visit as many traces as possible for regression tests at the final stage of designs, or may just need one valid trace for a quick validation of the design at an early stage. Our techniques can adapt to these different objectives easily. They are also platform-independent in that simulation using different languages, such as SystemC 2.0, Java, and C++ with a thread library, are possible. This feature is important for co-simulation between designs captured in Metropolis and those that have been already designed in other languages.

#*Automatic synthesis of system on chip multiprocessor architectures for process networks.
#@Basant Kumar Dwivedi,Anshul Kumar,M. Balakrishnan
#t2004
#cCODES+ISSS
#index106034
#!In this paper, we present an approach for automatic synthesis of System on Chip (SoC) multiprocessor architectures for applications expressed as process networks. Our approach is targeted towards design space exploration (DSE) and thus the speed of synthesis is of critical interest. The focus here is on the problem of resource allocation and binding with a view to optimize cost under performance constraints. Our approach exploits adjacency relation of processes and uses a dynamic programming based algorithm to synthesize the architecture including interconnection network. We have done a number of experiments on real as well as randomly generated process networks. The results have been compared with an optimal MILP formulation. They conclusively show that this approach is fast as well as effective and can be employed for DSE.

#*Partitioning and Exploration Strategies in the TOSCA Co-Design Flow.
#@Alessandro Balboni,William Fornaciari,Donatella Sciuto
#t1996
#cCODES
#index106035
#%858044
#%285739
#!The TOSCA environment for hardware/software co-design of control dominated systems implemented on a single chip includes a novel approach to the system exploration phase for the evaluation of alternative architectures. The paper presents the metrics and the partitioning algorithm defined for the identification of the best hardware and software bindings and modularization, given the design constraints and goals. The system exploration phase is implemented as an iterative process directed by the user, based on the formal internal design representation adopted in TOSCA. The application of the metrics is then shown on a simple example to illustrate the approach.

#*A Multi-Level Transformation Approach to HW/SW Codesign: A Case Study.
#@Tommy King-Yin Cheung,Graham R. Hellestrand,Prasert Kanthamanon
#t1996
#cCODES
#index106036
#%769674
#%484298
#%858067
#%214036
#%379653
#!This reported work applies a transformational synthesis approach to hardware/software codesign. In this approach, the process of algorithm design is coupled early on with hardware design to allow for a complete design space exploration. Both the specification and the transformation mechanisms are encoded in a functional notation, called form, which facilitates algorithmic derivation, structural transformation and verification. In the algorithmic derivation phase, possible computational schedules for a given application function are generated from a partial specification of the target architecture. At the hardware level, structural transformations are applied to explore possible datapath designs, where different designs yield different performance and cost. Other design metrics such as interface buffer size, software code size and data size etc. are also included to determine analytically a hardware/ software partition.

#*Extended quasi-static scheduling for formal synthesis and code generation of embedded software.
#@Feng-Shi Su,Pao-Ann Hsiung
#t2002
#cCODES
#index106037
#%564969
#%106156
#%1275169
#%106154
#%141477
#%132938
#%1123734
#%133848
#!With the computerization of most daily-life amenities such as home appliances, the software in a real-time embedded system now accounts for as much as 70% of a system design. On one hand, this increase in software has made embedded systems more accessible and easy to use, while on the other hand, it has also necessitated further research on how complex embedded software can be designed automatically and correctly. Enhancing recent advances in this research, we propose an Extended Quasi-Static Scheduling (EQSS) method for formally synthesizing and automatically generating code for embedded software, using the Complex-Choice Petri Nets (CCPN) model. Our method improves on previous work in three ways: (1) by removing model restrictions to cover a much wider range of applications, (2) by proposing an extended algorithm to schedule the more unrestricted model, and (3) by implementing a code generator that can produce multi-threaded embedded software programs. The requirements of an embedded software are specified by a set of CCPN, which is scheduled using EQSS such that the schedules satisfy limited embedded memory requirements and task precedence constraints. Finally, a POSIX-based multi-threaded embedded software program is generated in the C programming language. Through an example, we illustrate the feasibility and advantages of the proposed EQSS method.

#*HW/SW partitioning and code generation of embedded control applications on a reconfigurable architecture platform.
#@Massimo Baleani,Frank Gennari,Yunjian Jiang,Yatish Patel,Robert K. Brayton,Alberto L. Sangiovanni-Vincentelli
#t2002
#cCODES
#index106038
#%805564
#%805889
#%142031
#%203232
#%282381
#%106178
#%282463
#%132927
#%286681
#%77594
#%133804
#%77636
#!This paper studies the use of a reconfigurable architecture platform for embedded control applications aimed at improving real time performance. The hw/sw codesign methodology from POLIS is used. It starts from high-level specifications, optimizes an intermediate model of computation (Extended Finite State Machines) and derives both hardware and software, based on performance constraints. We study a particular architecture platform, which consists of a general purpose processor core, augmented with a reconfigurable function unit and data-path to improve run time performance. A new mapping flow and algorithms to partition hardware and software are proposed to generate implementations that best utilize this architecture. Encouraging preliminary results are shown for automotive electronic control examples.

#*Software acceleration using programmable logic: is it worth the effort?
#@Martyn Edwards
#t1997
#cCODES
#index106039
#%805564
#%106074
#%858044
#%858146
#%193943
#%106319
#!A commonly accepted technique in hardware/software co-design is to implement as many system functions as possible in software and to move performance critical functions into special-purpose external hardware in order to either satisfy timing constraints or reduce the overall execution time of a program - this is known as "software acceleration". This paper investigates the limits to the performance enhancements obtainable using software acceleration techniques. A practical target architecture, based on the use of programmable logic, is used to illustrate the problems associated with software acceleration. It is shown that normally little benefit can be obtained by applying software acceleration methods to general-purpose applications. Whereas software acceleration can profitably be used in a limited number of special-purpose applications, a designer would probably be better off developing ASIP components, based on heterogeneous multiprocessor architectures.

#*Hybrid global/local search strategies for dynamic voltage scaling in embedded multiprocessors.
#@Neal K. Bambha,Shuvra S. Bhattacharyya,Jürgen Teich,Eckart Zitzler
#t2001
#cCODES
#index106040
#%436519
#%131677
#%132619
#%436665
#%450488
#%286042
#%286624
#%437039
#%1125767
#%310947
#!In this paper, we explore a hybrid global/local search optimization framework for dynamic voltage scaling in embedded multiprocessor systems. The problem is to find, for a multiprocessor system in which the processors are capable of dynamically varying their core voltages, the optimum voltage levels for all the tasks in order to minimize the average power consumption under a given performance constraint. An effective local search approach for static voltage scaling based on the concept of a period graph has been demonstrated in [1]. To make use of it in an optimization problem, the period graph must be integrated into a global search algorithm. Simulated heating, a general optimization framework developed in [19], is an efficient method for precisely this purpose of integrating local search into global search algorithms. However, little is known about the management of computational (compile-time) resources between global search and local search in hybrid algorithms, such as those coordinated by simulated heating. In this paper, we explore various hybrid search management strategies for power optimization under the framework of simulated heating. We demonstrate that careful search management leads to significant power consumption improvement over add-hoc global search / local search integration, and explore alternative approaches to performing hybrid search management for dynamic voltage scaling.

#*Compiling Esterel into sequential code.
#@Stephen A. Edwards
#t1999
#cCODES
#index106041
#%1491968
#%949671
#%1056494
#%131782
#%141477
#!Embedded real-time software systems often need fine-grained parallelism and precise control over time, things typical real-time operating systems do not provide. The Esterel language has both, but Existing compilers produce slow code for large programs. This paper presents the first Esterel compiler able to produce small, fast code for large programs. It can produce code half the size and up to a hundred times faster than code from existing compilers. Esterel's semantics allow the compiler to statically schedule concurrency and synthesize code that efficiently and predictably simulates context switches. The main contribution is an algorithm that synthesizes an efficient sequential program from the concurrent control-flow graph used as an intermediate representation. These techniques could be applied to any language with fine-grained parallelism.

#*Software performance estimation strategies in a system-level design tool.
#@Jwahar R. Bammi,Wido Kruijtzer,Luciano Lavagno,Edwin A. Harcourt,Mihai T. Lazarescu
#t2000
#cCODES
#index106042
#%77
#%282088
#%133072
#%134030
#%134441
#!High-level cost and performance estimation, coupled with a fast hardware/software co-simulation framework, is a key enabler to a fast embedded system design cycle. Unfortunately, the problem of deriving such estimates without a detailed implementation available is difficult.In this paper we describe two approaches to solve software cost and performance estimation problem, and how they are used in an embedded system design environment. A source-based approach uses compilation onto a virtual instruction set, and allows one to quickly obtain estimates without the need for a compiler for the target processor. An object-based approach translates the assembler generated by the target compiler to &ldquo;assembler-level,&rdquo; functionally equivalent t C. In both cases the code is annotated with timing and other execution related information (e.g., estimated memory accesses) and is used as a precise, yet fast, software simulation model. We contrast the precision and speed of these two techniques comparing them with those obtainable by a state-of-the-art cycle-based processor model.

#*Domain-specific interface generation from dataflow specifications.
#@Michael Eisenring,Jürgen Teich
#t1998
#cCODES
#index106043
#%106328
#%1500099
#%106316
#%281938
#%134163
#%1166018
#%245247
#%106222

#*Scratchpad memory: design alternative for cache on-chip memory in embedded systems.
#@Rajeshwari Banakar,Stefan Steinke,Bo-Sik Lee,M. Balakrishnan,Peter Marwedel
#t2002
#cCODES
#index106044
#%858178
#%131423
#%499268
#%142137
#!In this paper we address the problem of on-chip memory selection for computationally intensive applications, by proposing scratch pad memory as an alternative to cache. Area and energy for different scratch pad and cache sizes are computed using the CACTI tool while performance was evaluated using the trace results of the simulator. The target processor chosen for evaluation was AT91M40400. The results clearly establish scratehpad memory as a low power alternative in most situations with an average energy reducation of 40%. Further the average area-time reduction for the seratchpad memory was 46% of the cache memory.

#*VHDL system-level specification and partitioning in a hardware/software co-synthesis environment.
#@Petru Eles,Zebo Peng,Alexa Doboli
#t1994
#cCODES
#index106045
#%806605
#%808572
#%193982
#%807024
#%805564
#%858044
#%858582
#%858146
#!This paper deals with the problems of system-level specification and partitioning in hardware/software co-design. It first discusses the implication of using VHDL as an implementation-independent specification language. A message passing communication mechanism is proposed to relax the strict synchronization imposed by the simulation-based semantics of VHDL. A partitioning technique is then described which is used to partition the VHDL specification into a hardware part and a software part. The partitioning is carried out during the compilation process of VHDL into a design representation which identifies the hardware/software boundary, while capturing hardware and software in a uniform way to allow efficient co-synthesis of both parts. The VHDL compiler and the partitioning algorithm function as the front end of a hardware/software co-synthesis environment which is built on the design representation.

#*Efficient search space exploration for HW-SW partitioning.
#@Sudarshan Banerjee,Nikil D. Dutt
#t2004
#cCODES+ISSS
#index106046
#!Hardware/software (HW-SW) partitioning is a key problem in the codesign of embedded systems, studied extensively in the past. One major open challenge for traditional partitioning approaches ¿ as we move to more complex and heterogeneous SOCs ¿ is the lack of efficient exploration of the large space of possible HW/SW configurations,coupled with the inability to efficiently scale up with larger problem sizes. In this paper, we make two contributions for HW-SW partitioning of applications represented as procedural callgraphs: 1) we prove that during partitioning, the execution time metric for moving a vertex needs to be updated only for the immediate neighbours of the vertex, rather than for all ancestors along paths to the root vertex; consequently, we observe faster run-times for move-based partitioning algorithms such as Simulated Annealing (SA), allowing call graphs with thousands of vertices to be processed in less than a second, and 2) we devise a new cost function for SA that allows frequent discovery of better partitioning solutions by searching spaces overlooked by traditional SA cost functions. We present experimental results on a very large design space, where several thousand configurations are explored in minutes as compared to several hours or days using a traditional SA formulation. Furthermore, our approach is frequently able to locate better design points with over 10 % improvement in application execution time compared to the solutions generated by a Kernighan-Lin partitioning algorithm starting with an all-SW partitioning.

#*A generic tool set for application specific processor architectures.
#@Frank A. Engel,Johannes Nührenberg,Gerhard Fettweis
#t2000
#cCODES
#index106047
#%106238
#!Retargetability allows an easy adoption of a simulator on different processor architectures without a time consuming redesign of all tools. This is evident for an efficient HW/SW codesign.In this paper we describe a tool set for fast and easy simulation of processor architectures based on a retargetable simulator core. This approach helps to reduce the development time for designing and validating System-on-a-chip (SoC) applications based on a processor core. The use of ANSIC avoids an expensive development of a modeling language.Our main focus in this paper is on conceptual decisions we made and on the structure of the tool set.

#*Towards provably correct hardware/software partitioning using occam.
#@Edna Barros,Augusto Sampaio
#t1994
#cCODES
#index106048
#%740943
#%2595
#%1094254
#!In this paper we present some ideas towards an approach to provably correct hardware/software partitioning. We use occam as the source programming language and perform the partitioning by applying a series of algebraic transformations on the source program. The result is still an occam program; its structure reflects the hardware and software components, and how they interact to achieve the overall goal. A simple case study is developed to illustrate the partitioning and to show how the transformations can be proved to preserve an algebraic semantics of occam.

#*A multiobjective optimization model for exploring multiprocessor mappings of process networks.
#@Cagkan Erbas,Selin C. Erbas,Andy D. Pimentel
#t2003
#cCODES+ISSS
#index106049
#%106221
#%106316
#%134077
#%807775
#%566949
#!In the Sesame framework, we develop a modeling and simulation environment for the efficient design space exploration of heterogeneous embedded systems. Since Sesame recognizes separate application and architecture models within a single system simulation, it needs an explicit mapping step to relate these models for co-simulation. So far in Sesame, the mapping decision has been assumed to be made by an experienced designer, intuitively. However, this assumption is increasingly becoming inappropriate for the following reasons: already the realistic systems are far too complex for making intuitive decisions at an early design stage where the design space is very large. Likely, these systems will even get more complex in the near future. Besides, there exist multiple criteria to consider, like processing times, power consumption and cost of the architecture, which make the decision problem even harder.In this paper, the mapping decision problem is formulated as a multiobjective combinatorial optimization problem. For a solution approach, an optimization software tool, implementing an evolutionary algorithm from the literature, has been developed to achieve a set of best alternative mapping decisions under multiple criteria. In a case study, we have used our optimization tool to obtain a set of mapping decisions, some of which were further evaluated by the Sesame simulation framework.

#*A statechart based HW/SW codesign system.
#@I. D. Bates,E. Graeme Chester,D. J. Kinniment
#t1999
#cCODES
#index106050
#%1056831
#%1056494

#*Modeling industrial embedded systems with UML.
#@João M. Fernandes,Ricardo Jorge Machado,Henrique D. Santos
#t2000
#cCODES
#index106051
#%979731
#%684744
#%2617
#%1056831
#!The main purpose of this paper is to present how the Unified Modeling Language (UML) can be used for modeling industrial embedded systems. By using a car radios production line as a running example, the paper demonstrates the modeling process that can be followed during the analysis phase of complex control applications. In order to guarantee the continuity mapping of the models, the authors propose some guidelines to transform the use case diagrams into a single object diagram, which is one of the main diagrams for the next development phases.

#*Flexible design of SPARC cores: a quantitative study.
#@Tomás Bautista,Antonio Núñez
#t1999
#cCODES
#index106052

#*SystemC: a homogenous environment to test embedded systems.
#@Alessandro Fin,Franco Fummi,Maurizio Martignano,Mirko Signoretto
#t2001
#cCODES
#index106053
#%1501545
#%141864
#%1134998
#%132061
#!The SystemC language is becoming a new standard in the EDA field and many designers are starting to use it to model complex systems. SystemC has been mainly adopted to define abstract models of hardware/software components, since they can be easily integrated for rapid prototyping. However, it can also be used to describe modules at a higher level of detail, e.g., RT-level hardware descriptions and assembly software modules. Thus, it would be possible to imagine a SystemC-based design flow, where the system description is translated from one abstraction level to the following one by always using SystemC representations. The adoption of a SystemC-based design flow would be particularly efficient for testing purpose as shown in this paper. In fact, it allows the definition of a homogeneous testing procedure, applicable to all design phases, based on the same error model and on the same test generation strategy. Moreover, test patterns are indifferently applied to hardware and software components, thus making the proposed testing methodology particularly suitable for embedded systems. Test patterns are generated on the SystemC description modeling the system at one abstraction level, then, they are used to validate the translation of the system to a lower abstraction level. New test patterns are then generated for the lower abstraction level to improve the quality of the test set and this process is iterated for each translation (synthesis) step.

#*An Approach to Mixed Systems Co-Synthesis.
#@Thomas Benner,Rolf Ernst
#t1997
#cCODES
#index106054
#%450666
#%106101
#%106188
#%132209
#%450609
#%1135016
#%106162
#%134163
#%131778
#%1134995
#%106128
#%450621
#!The paper presents an extension of co-synthesis for data dominated applications to include reactive processes. The extension allows for rate constraints as used in data dominated applications as well as minimum and maximum time constraints for communication and I/O which is required to define reactive behavior of control tasks. A co-synthesis approach is proposed which differentiates global process and communication scheduling, which is non preemptive, and local scheduling which includes a restricted interrupt controlled process invocation to extend the design space. Several user parameters allow design space exploration. The approach includes buffering, process pipelining and parallelization for control as well as for data dominated tasks on different levels of granularity. It supports inter process time constraints which span processes with different periods. The target architectures are heterogeneous systems consisting of multiple processors, hardware components, memories and different types of communication media.

#*Driving forces behind SOC development.
#@Mojy C. Chian
#t2003
#cCODES+ISSS
#index106055
#!Over the next five years what will drive higher levels of integration, methodology, and innovation in System On Chip (SOC) development? Will there be more emphasis on application specific chips, faster migration to submicron process technologies, exotic packages, revolutionary design automation tools, and IP reuse? This will depend on the economic value they present. For instance, the fast pace of process technologies over the past several years has been a two edged sword. On one side, it has created a great opportunity to integrate many functional blocks on a die. On the other end, high mask cost and long yield maturity posed major development cost and time-to-production issues. System In a Package (SIP) might be a more viable solution than a single die SOC for a higher level of integration of systems with diverse technology requirements.In this presentation, we will examine the vectors of cost, methodology, technology, and their interrelationship in SOC development. We will stress that now, more than ever, methodology and technology choices for SOC design and implementation have to be economically driven. If the high mortality rate of small chip companies and depressed earnings of larger ones over the past three years are any indication, we will see renewed interest in business fundamentals such as total available market (TAM) and return on investment (ROI). This is perhaps one of the most vivid changes we will all experience in the post bubble era. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player

#*Iterative cache simulation of embedded CPUs with trace stripping.
#@Zhao Wu,Wayne Wolf
#t1999
#cCODES
#index106056
#%282537
#%596821
#%1079630
#%597633
#%1126050

#*System-level design tools: who needs them, who has them, and how much should they cost?
#@Reinaldo A. Bergamaschi,Grant Martin
#t2003
#cCODES+ISSS
#index106057
#!CAD vendors are always faced with the question of what tools to develop and how much can they charge for them. Designers on the other hand have real problems to solve and before investing in tools they have to assess how much a given tool will actually save them. CAD vendors and designers have to estimate the savings in design time and cost that a tool may provide and compare that with the existing way of doing things, to determine if the investment in tool creation is justified. For example, if a misguided architectural decision causes weeks of delay because of missing performance targets, then a tool for early architectural analysis may be very valuable. System-level design poses exactly these types of questions because it involves optimizations and analyses across many domains, from software, to architecture, to cycle-time, and is done very early in the design cycle where it has a profound impact.How much improvement in productivity and overall design quality (e.g., timing, area, and power) can be attained by current and future generations of system-level tools? If designers believe such improvements can be obtained, are they prepared to pay the appropriate price for the tools? Or do system-level CAD vendors still need to make believers out of designers?This panel will bring together industry experts to review the current and future industry needs for system-level design technologies as well as discuss how much saving in design time and cost such tools can hope to achieve and whether the designers believe the price is right for the return they can get.

#*Optimization and synthesis for complex reactive embedded systems by incremental collapsing.
#@Massimiliano Chiodo
#t2002
#cCODES
#index106058
#%1056831
#%114061
#!We propose a software synthesis procedure for reactive real-time embedded systems. In our approach, control parts of the system are represented in a decomposed form enabling more complex control structures to be represented. We propose a synthesis procedure for this representation that incrementally aggregates elements of the representation while keeping the resulting code size under tight control. This method combined with heuristic strategies works very well on real-life designs and demonstrates the potential to produce results that challenge or beat hand-written implementations.

#*Satisfying real-time constraints with custom instructions.
#@Pan Yu,Tulika Mitra
#t2005
#cCODES+ISSS
#index106059
#%282604
#%418734
#%499311
#%805601
#%1008391
#%77474
#%281912
#%565620
#%106004
#%565402
#%498980
#%214265
#%133596
#!Instruction-set extensible processors allow an existing processor core to be extended with application-specific custom instructions. In this paper, we explore a novel application of instruction-set extensions to meet timing constraints in real-time embedded systems. In order to satisfy real-time constraints, the worst-case execution time (WCET) of a task should be reduced as opposed to its average-case execution time. Unfortunately, existing custom instruction selection techniques based on average-case profile information may not reduce a task's WCET. We first develop an Integer Linear Programming (ILP) formulation to choose optimal instruction-set extensions for reducing the WCET. However, ILP solutions for this problem are often too expensive to compute. Therefore, we also propose an efficient and scalable heuristic that obtains quite close to the optimal results. Experiment results indicate that suitable choice of custom instructions can reduce the WCET of our benchmark programs by as much as 42% (23.5% on an average).

#*The future of system-level design: can we find the right solutions to the right problems at the right time?
#@Reinaldo A. Bergamaschi,Grant Martin,Wayne Wolf,Rolf Ernst,Kees A. Vissers,Jack Kouloheris
#t2003
#cCODES+ISSS
#index106060
#!Over the last 15 years we have seen and helped the evolution of design from behavioral modeling to hardware/software co-design, to today's system-level design. Arguably, many of the research efforts on behavioral synthesis, hardware / software co-design, co-simulation etc. have made their way into successful commercial tools, while others went no further than a conference paper. As we continue and expand system-level research with new approaches opening exciting new research avenues, we have an obligation to look back at our successes and failures. Then looking towards the future, we must answer the question: are we solving the right problems with the right solutions at the right time, or should we go back to the drawing board and think of brand new research approaches.This panel will bring together panelists experienced in various aspects of system-level design who will present different views on what this community has achieved over the last 15 years and draw a roadmap for future research.

#*Software Architecture Synthesis for Retargetable Real-time Embedded Systems.
#@Pai H. Chou,Gaetano Borriello
#t1997
#cCODES
#index106061
#%1056494
#%131778
#%281937
#%281938
#%563818
#%1128159
#%362134
#%134164
#!Retargetability of embedded system descriptions not only enables better exploration of the design space and evaluation of cost/performance tradeoffs but also enhances design maintainability and adaptivity to new technologies. Unfortunately, the traditional boundary between run-time support and user-code encourages use of ad hoc architecture-specific features that lack the structure to permit automatic code synthesis for the satisfaction of timing constraints. This work proposes a specification style for control-dominated embedded systems that can be easily retargeted via automatic synthesis of the software architecture and run-time support. Unlike previous work, user-specified modes are an integral part of the run-time system and isolate architecture-specific details while scoping timing constraints to enable more efficient scheduling.

#*Promises and challenges of mobile embedded system: : an industry perspective.
#@Nam Sung Woo
#t2006
#cCODES+ISSS
#index106062
#!Recent trends of IT industry include Mobile/Portable Solution, Integration and Faster Time-to-Market. These trends impose many interesting challenges to Embedded System development both in hardware and software. In this talk, we will first identify some of the challenges. Then, we will present both the current status and plans of Samsung Electronics (in particular, Samsung Semiconductor) to address and overcome the challenges.

#*SEAS: a system for early analysis of SoCs.
#@Reinaldo A. Bergamaschi,Youngsoo Shin,Nagu R. Dhanwada,Subhrajit Bhattacharya,William E. Dougherty,Indira Nair,John A. Darringer,Sarala Paliwal
#t2003
#cCODES+ISSS
#index106063
#%132281
#%891275
#%436525
#%1135480
#%857794
#%890285
#%194908
#!Systems-on-chip (SoC) continue to be very complex to design and verify, despite extensive component reuse. Although reusable components are pre-designed and pre-verified, when they are assembled in an SoC there is no guarantee that the whole system will behave as expected from a performance, cost and integration point of view. In many cases this is because of faulty early design decisions regarding the architecture, core selection, floorplanning, etc. This paper presents a system for early analysis of SoCs which helps designers make early design decisions regarding performance, area, timing and power; and allows them to quickly evaluate cross-domain effects, such as the effect that an architectural decision may have on the performance and chip area.

#*Towards interprocess communication and interface synthesis for a heterogeneous real-time rapid prototyping environment.
#@Franz Fischer,Annette Muth,Georg Färber
#t1998
#cCODES
#index106064
#%106217
#%564302

#*A path analysis based partitioning for time constrained embedded systems.
#@Luc Bianco,Michel Auguin,Guy Gogniat,Alain Pegatoquet
#t1998
#cCODES
#index106065
#%106070
#%106325
#%106216
#%132358
#%131937
#%858067
#%858146
#%106188
#%807064

#*A hardware/software prototyping environment for dynamically reconfigurable embedded systems.
#@Josef Fleischmann,Klaus Buchenrieder,Rainer Kress
#t1998
#cCODES
#index106066
#%215397
#%215635
#%282252

#*A language for multiple models of computation.
#@Dag Björklund,Johan Lilius
#t2002
#cCODES
#index106067
#%1056494
#%635115
#%52260
#!We introduce a new kernel language for modeling hardware/software systems, adopting multiple heterogenous models of computation. The language has formal operational semantics, and is well suited for model checking, code synthesis etc. For different blocks of code, different scheduling policies can be applied, to reflect the different interpretations of e.g. parallelism in different models of computation. The user can add his own scheduling policies, to use or explore different models of computation.

#*An analysis-based approach to composition of distributed embedded systems.
#@Pai H. Chou,Gaetano Borriello
#t1998
#cCODES
#index106068
#%545925
#%1056494
#%362134
#%2595
#%773608

#*Key technologies for the next generation wireless communications.
#@Kyung-Ho Kim
#t2006
#cCODES+ISSS
#index106069
#!The principal objectives of next generation wireless communication are the delivery of higher data rate services including video, audio, data and voice signals with worldwide compatibility. The promise of new radio spectrum encouraged the world's mobile tele-communication operators to pay very high prices for 3G licenses. Most 3G systems is arranged to operate in 2GHz frequency band. The 4G represents the next development stages of cellular evolution beyond 3G, and offers an ideal basis and bandwidth to provide more efficient cellular multicast services. At present, 4G exists only in the conceptual framework to discuss and address future high-speed network and handset requirements. In this context, we address the following important topics such as key technologies of wireless communication system, main standardization trends of next generation and major implementation issues for wireless SOC.

#*Critical path driven cosynthesis for heterogeneous target architectures.
#@Peter Bjørn-Jørgensen,Jan Madsen
#t1997
#cCODES
#index106070
#%769473
#%1059577
#%1125254
#%1125767
#%1126042
#!This paper presents a critical path driven algorithm to produce a static schedule of a single-rate system onto a heterogeneous target architecture. Our algorithm is a list based scheduling algorithm which concurrently assigns tasks to processors and allocates nets to interprocessor communication. Experimental results show that our algorithm is able to find good results, as compared to other methods, in small amount of CPU time.

#*A timing-accurate HW/SW co-simulation of an ISS with SystemC.
#@Luca Formaggio,Franco Fummi,Graziano Pravadelli
#t2004
#cCODES+ISSS
#index106071
#!The paper presents a system level co-simulation methodology for modeling, validating, and analyzing the performance of embedded systems. The proposed solution relies on the integration between an instruction set simulator (ISS) and the SystemC simulation kernel. In this way, the ISS is used to abstract the model of the real programmable device where the SW should run, while SystemC is used to model HW components that interact with the SW. A correct validation of such an architecture is infeasible without taking care of timing information. Thus, the paper proposes an effective timing synchronization mechanism, which uses timing information of an ISS (or a board) to synchronize the SystemC simulation.

#*FPGA resource and timing estimation from Matlab execution traces.
#@Per Bjuréus,Mikael Millberg,Axel Jantsch
#t2002
#cCODES
#index106072
#%106025
#%106042
#%203124
#%450505
#%106080
#%645153
#!We present a simulation-based technique to estimate area and latency of an FPGA implementation of a Matlab specification. During simulation of the Matlab model, a trace is generated that can be used for multiple estimations. For estimation the user provides some design constraints such as the rate and bit width of data streams. In our experience the runtime of the estimator is approximately only 1/10 of the simulation time, which is typically fast enough to generate dozens of estimates within a few hours and to build cost-performance trade-off curves for a particular algorithm and input data. In addition, the estimator reports on the scheduling and resource binding used for estimation. This information can be utilized not only to assess the estimation quality, but also as first starting point for the final implementation.

#*Power optimization of system-level address buses based on software profiling.
#@William Fornaciari,M. Polentarutti,Donatella Sciuto,Cristina Silvano
#t2000
#cCODES
#index106073
#%233660
#%1135262
#%1135234
#%1135015
#%1135128
#%858566
#%234062
#%141452
#!The paper aims at defining a methodology for the optimization of the switching power related to the processor-to memory communication on system-level buses. First, a methodology to profile the switching activity related to system-level buses has been defined, based on the tracing of benchmark programs running on the Sun SPARC V8 architecture. The bus traces have been analyzed to identify temporal correlations between consecutive patterns. Second, a framework has been set up for the design of high-performance encoder/decoder architectures to reduce the transition activity of the system-level buses. Novel bus encoding schemes have been proposed, whose performance has been compared with the most widely adopted power-oriented encodings. The experimental results have shown that the proposed encoding techniques provide an average reduction in transition activity up to 74.11% over binary encoding for instruction address streams. The results indicate the suitability of the proposed techniques for high-capacitance wide buses, for which the power saving due to the transition activity reduction is not offset by the extra power dissipation introduced in the system by the encoding/decoding logic.

#*A codesign case study in computer graphics.
#@Jens P. Brage,Jan Madsen
#t1994
#cCODES
#index106074
#%593563
#!This paper describes a codesign case study where a computer graphics application is examined with the intention to speed up its execution. The application is specified as a C program, and is characterized by the lack of a simple compute-intensive kernel. The hardware/software partitioning is based on information obtained from software profiling and the resulting design is validated through co-simulation. A locally developed interface model, Merlin, is used as the basis for co-simulation. The achieved speed-up is estimated based on an analysis of profile information.

#*Hardware/software co-design of an avionics communication protocol interface system: an industrial case study.
#@François Clouté,Jean-Noël Contensou,Daniel Esteve,Pascal Pampagnin,Philippe Pons,Yves Favard
#t1999
#cCODES
#index106075
#%857832
#%1056494
#%858040

#*Droplet-trace-based array partitioning and a pin assignment algorithm for the automated design of digital microfluidic biochips.
#@Tao Xu,Krishnendu Chakrabarty
#t2006
#cCODES+ISSS
#index106076
#%980579
#%282777
#%141582
#%134430
#%106105
#%134001
#%132469
#%143094
#!Microfluidics-based biochips combine electronics with biology to open new application areas such as point-of-care medical diagnostics, on-chip DNA analysis, and automated drug discovery. Bioassays are mapped to microfluidic arrays using synthesis tools, and they are executed through the manipulation of sample and reagent droplets by electrical means. Most prior work on CAD for biochips has assumed independent control of electrodes using a large number of (electrical) input pins. Such solutions are not feasible for low-cost disposable biochips that are envisaged for many field applications. A more promising design strategy is to divide the microfluidic array into smaller partitions and use a small number of electrodes to control the electrodes in each partition. We propose a partitioning algorithm based on the concept of "droplet trace", which is extracted from the scheduling and droplet routing results produced by a synthesis tool. An efficient pin assignment method, referred to as the "Connect-5 algorithm", is combined with the array partitioning technique based on droplet traces. The array partitioning and pin assignment methods are evaluated using a set of multiplexed bioassays.

#*Energy estimation for 32-bit microprocessors.
#@Carlo Brandolese,William Fornaciari,Fabio Salice,Donatella Sciuto
#t2000
#cCODES
#index106077
#%283294
#%857821
#!Estimation of software power consumption is becoming one of the major problems for many embedded applications. The paper presents a novel approach to compute the energy of an Instruction Set, through a suitable functional decomposition of the activities involved during instruction execution. One of the main advantages of this approach is the capability to predict the power figures of the overall Instruction-Set starting from a small subset. A formal discussion on the statistical properties of the model is included, together with its application on five commercial 32-bit microprocessors.


#*Whole program compilation for embedded software: the ADSL experiment.
#@Johan Cockx
#t2001
#cCODES
#index106078
#%470703
#%173049
#%522959
#%684429

#*The pipeline decomposition tree: : an analysis tool for multiprocessor implementation of image processing applications.
#@Dong-Ik Ko,Shuvra S. Bhattacharyya
#t2006
#cCODES+ISSS
#index106079
#%1135245
#%832707
#%614612
#!Modern embedded systems for image processing involve increasingly complex levels of functionality under real-time and resource-related constraints. As this complexity increases, the application of single-chip multiprocessor technology is attractive. To address the challenges of mapping image processing applications onto embedded multiprocessor platforms, this paper presents a novel data structure called the pipeline decomposition tree (PDT), and an associated scheduling framework, which we refer to as PDT scheduling. PDT scheduling exploits both heterogeneous data parallelism and task-level parallelism, which are important considerations for scheduling image processing applications. This paper develops the PDT representation for system synthesis, and presents methods using the PDT to derive customized pipelined architectures that are streamlined for the given implementation constraints.

#*Source-level execution time estimation of C programs.
#@Carlo Brandolese,William Fornaciari,Fabio Salice,Donatella Sciuto
#t2001
#cCODES
#index106080
#%131519
#%106042
#%134441
#%134030
#%450515
#%133072
#%1053194
#!In this paper a comprehensive methodology for software execution time estimation is presented. The methodology is supported by rigorous mathematical models of C statements in terms of elementary operations. The deterministic contribution is combined with a statistical term accounting for all those aspects that cannot be quantified exactly. The methodology has been validated by realizing a complete prototype toolset, used to carry out the experiments.

#*Development cost and size estimation starting from high-level specifications.
#@William Fornaciari,Fabio Salice,Umberto Bondi,Edi Magini
#t2001
#cCODES
#index106081
#!This paper addresses the problem of estimating cost and development effort of a system, starting from its complete or partial high-level description. In addition, some modifications to evaluate the cost-effectiveness of reusing VHDL-based designs, are presented. The proposed approach has been formalized using an approach similar to the COCOMO analysis strategy, enhanced by a project size prediction methodology based on a VHDL function point metric. The proposed design size estimation methodology has been validated through a significant benchmark, the LEON-1 microprocessor, whose VHDL description is of public domain

#*Co-design tool construction using APICES.
#@Ansgar Bredenfeld
#t1999
#cCODES
#index106082
#%1491969
#%131356
#%562563
#%131523
#%450666
#%159

#*Early estimation of the size of VHDL projects.
#@William Fornaciari,Fabio Salice,Daniele Paolo Scarpazza
#t2003
#cCODES+ISSS
#index106083
#%106081
#!The analysis of the amount of human resources required to complete a project is felt as a critical issue in any company of the electronics industry. In particular, early estimating the effort involved in a development process is a key requirement for any cost-driven system-level design decision.In this paper, we present a methodology to predict the final size of a VHDL project on the basis of a high-level description, obtaining a significant indication about the development effort. The methodology is the composition of a number of specialized models, tailored to estimate the size of specific component types. Models were trained and tested on two disjoint and large sets of real VHDL projects. Quality-of-result indicators show that the methodology is both accurate and robust.

#*Conflict analysis in multiprocess synthesis for optimized system integration.
#@Oliver Bringmann,Wolfgang Rosenstiel,Axel Siebenborn
#t2005
#cCODES+ISSS
#index106084
#%106300
#%142159
#%926993
#%281766
#%450498
#%450521
#%645970
#%575360
#%143022
#!This paper presents a novel approach for multiprocess synthesis supporting well-tailored module integration at system level. The goal is to extend the local scope of existing architectural synthesis approaches in order to apply global optimization techniques across process bounds for shared system resources (e.g. memories, busses, global ALUs) during scheduling and binding. This allows an area efficient implementation of un-timed or cycle-fixed multiprocess specifications at RT or algorithmic level of abstraction. Furthermore, this approach supports environment-oriented synthesis for optimized module integration by scheduling accesses to global resources with respect to the access schedules of other modules communicating to the same global resources. As a result, dynamic access conflicts can be avoided by construction, and hence, there is no need for dynamic arbitration of bus and memory accesses with potentially unpredictable timing behavior.

#*Power estimation for architectural exploration of HW/SW communication on system-level buses.
#@William Fornaciari,Donatella Sciuto,Cristina Silvano
#t1999
#cCODES
#index106085
#%1498430
#%1135128
#%1135015
#%858566
#%234062
#%141452
#%1135207
#%1135158
#%436615
#%132274
#%436736

#*Communication refinement in video systems on chip.
#@Jean-Yves Brunel,Erwin A. de Kock,W. M. Kruijtzer,H. J. H. N. Kenter,W. J. M. Smits
#t1999
#cCODES
#index106086
#%50123
#%106196
#%133707

#*A design framework to efficiently explore energy-delay tradeoffs.
#@William Fornaciari,Donatella Sciuto,Cristina Silvano,Vittorio Zaccaria
#t2001
#cCODES
#index106087
#%1135322
#%418565
#%1135113
#%106073
#%1080046
#%436615
#%499311
#%132274
#%436736
#%436575
#%436814
#!Comprehensive exploration of the design space parameters at the system-level is a crucial task to evaluate architectural tradeoffs accounting for both energy and performance constraints. In this paper, we propose a system-level design methodology for the efficient exploration of the memory architecture from the energy-delay combined perspective. The aim is to find a sub-optimal configuration of the memory hierarchy without performing the exhaustive analysis of the parameters space. The target system architecture includes the processor, separated instruction and data level- one caches, the main memory, and the system buses. The methodology is based on the sensitivity analysis of the optimization function with respect to the tuning parameters of the cache architecture (mainly cache size, block size and associativity). The effectiveness of the proposed methodology has been demonstrated through the design space exploration of a real-world example: a MicroSPARC2-based system running the Mediabench suite. Experimental results have shown an optimization speed up of 329 times with respect to the full search, while the near-optimal system-level configuration is characterized by a distance from the optimal full search configuration in the band of 10%.

#*A dynamic dataflow model suitable for efficient mixed hardware and software implementations of DSP applications.
#@Joseph T. Buck
#t1994
#cCODES
#index106088
#%858422
#%1125288
#%858145
#%1056831
#!This paper presents an analytical model for the behavior of dataflow graphs with data-dependent control flow and discusses its suitability to the generation of efficient software and hardware implementations of digital signal processing (DSP) applications. In the model, the number of tokens produced or consumed by each actor is given as a symbolic function of the Boolean values in the system; in addition, it may vary cyclically to permit more memory-efficient multirate implementations. The model can be used to extend the ability of block-diagram-oriented systems for DSP design, such as Ptolemy [1], to produce efficient hardware and software implementations; this permits the hardware-software codesign techniques of [2] to be efficiently targeted at a wider class of problems, those involving some asynchronous behavior, for example.

#*Compiler parallelization of C programs for multi-core DSPs with multiple address spaces.
#@Björn Franke,Michael F. P. O'Boyle
#t2003
#cCODES+ISSS
#index106089
#%1125583
#%360730
#%53641
#%806620
#!This paper develops a new approach to compiling C programs for multiple address space, multi-processor DSPs. It integrates a novel data transformation technique that exposes the processor location of partitioned data into a parallelization strategy. When this is combined with a new address resolution mechanism, it generates efficient programs that run on multiple address spaces without using message passing. This approach is applied to the UTDSP benchmark suite and evaluated on a four processor TigerSHARC board, where it is shown to outperform existing approaches and gives an average speedup of 3.25 on the parallel benchmarks.

#*Heterogeneous modeling and simulation of embedded systems in El Greco.
#@Joseph Buck,Radha Vaidyanathan
#t2000
#cCODES
#index106090
#%143989
#%106041
#%1056494
#%1056831
#%131785
#%132955
#%220990
#!This paper describes the functional specification and verification portions of El Greco, a system for high-level, heterogeneous functional specification, efficient compiled simulation, and software and hardware implementation. Specifications in the form of dataflow graphs, hierarchical finite state machines, or a mixture, are supported. These specifications can be arbitrarily nested, as in Ptolemy [1]. When dataflow graphs are placed in a control context, the graph execution is fully controllable; its execution can be restarted or suspended and parameters can be changed. We describe system modeling and simulation generation in El Greco and compare to other approaches.

#*Interface Optimization During Hardware-Software Partitioning.
#@Laurent Freund,Denis Dupont,Michel Israël,Frédéric Rousseau
#t1997
#cCODES
#index106091
#%1493486
#%450692
#%858146
#%282259
#%133370
#%281938
#%112553
#%858582
#%283380
#!This paper presents an approach allowing communication optimization during the hardware-software partitioning task. Our methodology focuses on systems represented by a data flow graph whose nodes are elements of libraries. To abstract the communication constraints, we include communication nodes in this graph. Consequently, assignment and scheduling of communications and operations can be determined together by the same partitioning algorithm. During partitioning, protocol optimization and bus scheduling are realized. We illustrate with a telecommunication system example the feasibility and the usefulness of our methodology.

#*Architectural versus physical solutions for on-chip communication challenges.
#@Doug Burger
#t2003
#cCODES+ISSS
#index106092
#!The growing gap between transistor and global wire speeds in sub-100 nanometer technologies poses numerous challenges to computer architects and circuit designers. This challenge looks to be even more significant in far-future technologies such as molecular-scale wire transmission, whether using carbon nanotubes or quantum dots. While a fixed design scales as its area decreases with feature size reductions, future designs that use a constant area see rapidly increasing global latencies.Two approaches to address these latencies are (1) to use signaling and design techniques to reduce the actual latencies, and (2) to use architectural innovations to reduce the distance that signals must be propagated in the common case. In this talk, after an overview of the communication latency issue, I describe current research that aims to reduce the average distance communicated for processing and memory system signals. For processor designs, I will describe the Static Placement, Dynamic Issue (SPDI) execution model, which allows the compiler to place dependent instructions near one another, and which is being implemented in the TRIPS processor. I will also describe Non-Uniform Caches Access (NUCA) designs, which attempt to reduce average signal distance for cache accesses.

#*Low energy security optimization in embedded cryptographic systems.
#@Catherine H. Gebotys
#t2004
#cCODES+ISSS
#index106093
#!Future embedded and wireless devices will be increasingly powerful supporting many applications including one of the most crucial, security. Although many wireless and embedded devices offer more resistance to bus probing attacks due to their compact size, susceptibility to power/electromagnetic attacks must be analyzed. This paper presents optimized synthesis of new low energy masking countermeasures into cryptographic software. In particular a model for key masking with the objective of minimizing energy overhead is presented. Experimental results using real power measurements are shown to support up to 2.5 energy overhead savings and improved security compared to previous research. With the emergence of security applications in PDAs, cell phones, line card accelerators, etc, optimizing low energy countermeasures for resistance to power/ electromagnetic attacks is crucial for supporting future secure embedded devices.

#*Transaction level modeling: an overview.
#@Lukai Cai,Daniel Gajski
#t2003
#cCODES+ISSS
#index106094
#%858394
#%857939
#%52279
#!Recently, the transaction-level modeling has been widely referred to in system-level design community. However, the transaction-level models(TLMs) are not well defined and the usage of TLMs in the existing design domains, namely modeling, validation, refinement, exploration, and synthesis, is not well coordinated. This paper introduces a TLM taxonomy and compares the benefits of TLMs' use.

#*Security wrappers and power analysis for SoC technologies.
#@Catherine H. Gebotys,Y. Zhang
#t2003
#cCODES+ISSS
#index106095
#%86974
#%131915
#%450650
#%805785
#!Future wireless internet enabled devices will be increasingly powerful supporting many more applications including one of the most crucial, security. Although SoCs offer more resistance to bus probing attacks, power/EM attacks on cores and network snooping attacks by malicious code are relevant. This paper presents a methodology for security on NoC at both the network level (or transport layer) and at the core level (or application layer) is proposed. For the first time a low cost security wrapper design is presented, which prevents unencrypted keys from leaving the cores and NoC. This is crucial to prevent untrusted software on or off the NoC from gaining access to keys. At the core level (application layer) power analysis attacks are examined for the first time for parallel and adiabatic architectural cores. With the emergence of secure IP cores in the market, a security methodology for designing NoCs is crucial for supporting future wireless internet enabled devices.

#*Uninterpreted Co-Simulation for Performance Evaluation of Hw/Sw Systems.
#@Jean Paul Calvez,Dominique Heller,Olivier Pasquier
#t1996
#cCODES
#index106096
#%106098
#%285797
#%858146
#%858582
#!Performance modeling and evaluation of embedded hardware/software systems is important to help the CoDesign process. The hardware/software partitioning needs to be evaluated before synthesizing the solution. This paper presents a co-simulation technique based on the use of an uninterpreted model able to accurately represent the behavior of the whole system. The performance model includes two complementary viewpoints: the structural viewpoint which describes the functional structure, the hardware structure, the functional to hardware mapping, and the behavioral viewpoint which specifies the temporal evolution of each function or process. Attributes are added to the graphical model to specify the local properties of all components. The performance properties of the solution are obtained by simulation with VHDL. Software functions are executed according to the availability of an execution resource which simulates a microprocessor. This technique leads to rapidly obtain a lot of results by modifying appropriate parameters of the model, and so to easily scan the CoDesign space to decide on the best implementation. This modeling and estimation technique is fully integrated in a whole development process based on the MCSE methodology.

#*How standards will enable hardware/software co-design.
#@Mark Genoe,Christopher K. Lennard,Joachim Kunkel,Brian Bailey,Gjalt G. de Jong,Grant Martin,M. M. Kamal Hashmi,Shay Ben-Chorin,Anssi Haverinen
#t1999
#cCODES
#index106097

#*A CoDesign experience with the MCSE methodology.
#@J. P. Calvez,D. Isidoro
#t1994
#cCODES
#index106098
#%806605
#%858582
#%858146
#!In this paper, we describe the experimentation of our codesign process to develop a communication system which needs to correctly mix hardware and software parts to satisfy required performance. The system design process is based on the MCSE methodology and we show its usefulness for CoDesign. CoDesign is shown as an enhancement of the implementation specification step of MCSE. System partitioning is the result of an interactive procedure based on performance and cost evaluations. The complete description of the implementation is obtained by transformations of the functional description: C or C++ for the software part, VHDL for the hardware part. The links between the hardware and software parts are also synthesized.Such a procedure and associated tools lead to efficiently obtain system prototypes in an incremental manner.

#*Blue matter on blue gene/L: massively parallel computation for biomolecular simulation.
#@Robert S. Germain,Blake G. Fitch,Aleksandr Rayshubskiy,Maria Eleftheriou,Michael Pitman,Frank Suits,Mark Giampapa,T. J. Christopher Ward
#t2005
#cCODES+ISSS
#index106099
#%989380
#%891612
#%988738
#!This paper provides an overview of the Blue Matter application development effort within the Blue Gene project that supports our scientific simulation efforts in the areas of protein folding and membrane-protein systems. The design philosophy of the Blue Gene/L architecture relies on large numbers of power efficient nodes (whose technology is derived from the world of embedded microprocessors) to enable packing of many such nodes into a small volume to achieve high performance. In order for an application to exploit the potential of this architecture, the application must scale well to large node counts. Because the scientific goals of the project entail simulating very long time-scales, up to microseconds, strong scaling of a fixed size problem to these large node counts is a requirement. In pursuit of this objective we have considered a variety of parallel decompositions and explored ways to exploit and map algorithms onto the two primary high performance interconnects provided by the Blue Gene architecture, the 3D-torus network and the collective network. Our current version of the application continues to speed up through 4096 nodes and is being used for studies of a protein/lipid system (for which some results have already been published) and for protein folding/unfolding simulations.

#*Software Implementation Techniques for Hw/Sw Embedded Systems.
#@Jean Paul Calvez,Olivier Pasquier,J. Peckol
#t1997
#cCODES
#index106100
#%105982
#%106096
#%131783
#%806605
#%105984
#!Our focus in this paper is the software implementation of control oriented systems. Such a task is one of the least automated portions of the contemporary CoDesign process. In systems that must respond to external events, often several asynchronous tasks are implemented on the same processor. We are studying such systems because often, they utilize a dynamic multi-rate scheduling technique using a multitasking real time kernel. Based upon the MCSE functional model as a specification input, we propose a set of transformation rules one can apply to the functional structure to reduce the complexity of the software design prior to implementation. We further show that after such optimizations, the microprocessor interrupt system can often be used as an efficient priority-based scheduler, thereby removing the need for a real time kernel. The resulting implementation is described using a software implementation diagram from which it is easy to prove the timing constraints are satisfied. We use a simplified control system to illustrate our approach and to show a smooth incremental CoDesign path with a better integration of software estimates into the partitioning decision.

#*A Co-Design Methodology Based on Formal Specification and High-level Estimation.
#@Carlos Carreras,Juan Carlos López,María Luisa López,Luis Sánchez,Carlos Delgado Kloos,Natividad Martínez Madrid
#t1996
#cCODES
#index106101
#%793483
#%858044
#%858146
#%2595
#%132601
#%213268
#%794887
#%3421
#%61365
#!This paper presents a methodology for hardware-software co-design. It is based on the formal description technique LOTOS in the specification phase, and on estimation methods at different levels of abstraction in the partitioning phase. The LOTOS specification describes the system as a set of interacting communicating processes. Our HW-SW partitioning algorithm is guided by communications, performance and area estimates and by the suitability of each process for implementation in hardware or software. A partition is evaluated against the design goals and constraints, first using high-level estimates and then, if requirements are met, computing estimates at lower levels of abstraction. If the partition fails, the partitioning model is updated with the new low-level estimates and a new partition is generated. If it succeeds, the resulting hardware and software specifications are synthesized using existing high-level synthesis tools and compilers.

#*A Case Study in Co-Design of Communication Controllers.
#@R. Gerndt
#t1996
#cCODES
#index106102
#%281937
#%858044
#!The main objective of our activities in the first place was the implementation of a number of communication controllers. Analyzing the high complexity of the designs a formalized design methodology became mandatory. To ease the design process we developed a co-design methodology that makes possible the implementation of highly complex real-time applications with comparable short design cycles. The outcome of hardware components satisfies all timing constraints that were imposed by protocol and the reactivity of the application. It also was of reasonable size.

#*Fast dynamic analysis of complex HW/SW-systems based on abstract state machine models.
#@Giuseppe Del Castillo,Wolfram Hardt
#t1998
#cCODES
#index106103
#%106122

#*Redesigning hardware-software systems.
#@Claudionor José Nunes Coelho Jr.,Jerry Chih-Yuan Yang,Vincent John Mooney III,Giovanni De Micheli
#t1994
#cCODES
#index106104
#%1083866
#%131778
#%806605
#%808572
#%1196278
#%858044
#%858582
#%132209
#%77

#*System-level design automation tools for digital microfluidic biochips.
#@Krishnendu Chakrabarty,Fei Su
#t2005
#cCODES+ISSS
#index106105
#%141582
#%282777
#%134001
#!Biochips based on digital microfluidics offer a powerful platform for massively parallel biochemical analysis such as clinical diagnosis and DNA sequencing. Current full-custom design techniques for digital microfluidic biochips do not scale well for increasing levels of system integration. Analogous to classical VLSI synthesis, a top-down system-level design automation approach can shorten the biochip design cycle and reduce human effort. We present here an overview of a system-level design methodology that includes architectural synthesis and physical design. The proposed design automation approach is expected to relieve biochip users from the burden of manual optimization of bioassays, time-consuming hardware design, and costly testing and maintenance procedures.

#*An Event-Driven Multi-Threading Architecture for Embedded Systems.
#@Reinhard Gerndt,Rolf Ernst
#t1997
#cCODES
#index106106
#%106102
#!In this paper we present an event driven multi-threading architecture and its underlying event flow system model of computation as a framework for the implementation of complex reactive and communication systems. Existing process oriented specification languages can be used to specify the system and embedded in the model. The target architecture covers a wide variety of architectures, varying from small FSMs to large processors, which are interconnected by a network template which performs dynamic scheduling and communication for different levels of process granularity and timing. Interconnect and module implementation and optimization is based on an event flow graph model (EFG). In this paper we present our system model and the architectural template and show how they can be applied to an industrial application example.

#*A flexible code generation framework for the design of application specific programmable processors.
#@François Charot,Vincent Messé
#t1999
#cCODES
#index106107
#%142020
#%132301
#%450637
#%234307

#*Architecture and synthesis for multi-cycle on-chip communication.
#@Jason Cong,Yiping Fan,Guoling Han,Xun Yang,Zhiru Zhang
#t2003
#cCODES+ISSS
#index106108
#%446399
#%282479

#*High-level architectural co-simulation using Esterel and C.
#@André Chátelain,Yves Mathys,Giovanni Placido,Alberto La Rosa,Luciano Lavagno
#t2001
#cCODES
#index106109
#%450486
#%134030
#%1056494
#!This paper introduces an architectural simulation environment, aimed at defining the best SOC architecture for complex system-level applications. The application is modeled using an abstract Timing Modeling Language, that describes the requests (e.g., memory accesses, I/Os, etc.) that the application makes to the architecture. The abstract architecture is modeled at the cycle-accurate level using a mixture of Esterel (a synchronous language) and C. We discuss the results of the application of this tool to a GSM/GPRS application, including a dramatic speed-up of the architectural exploration phase.

#*Parameterized system design.
#@Tony Givargis,Frank Vahid
#t2000
#cCODES
#index106110
#%234230
#%106085
#%282163
#%52285
#%858150
#%132274
#%1135015
#%106326
#%450689
#%360744
#%106352
#!Continued growth in chip capacity has led to new methodologies stressing reuse, not only of pre-designed processing components, but even of entire pre-designed architectures. To be used across a variety of applications, such architectures must be heavily parameterized, so they can adapt to those applications' differing constraints by trading off power, performance and size. We describe several parameterized system design issues, and provide results showing how a single architecture with easily configurable parameters can support a wide range of tradeoffs.

#*MAGELLAN: multiway hardware-software partitioning and scheduling for latency minimization of hierarchical control-dataflow task graphs.
#@Karam S. Chatha,Ranga Vemuri
#t2001
#cCODES
#index106111
#%1500634
#%450476
#%106113
#!The paper presents MAGELLAN, a heuristic technique for mapping hierarchical control-dataflow task graph specifications on heterogeneous architecture templates. The architecture can consist of multiple hardware and software processing elements as specified by the user. The objective of the technique is to minimize the worst case latency of the task graph subject to the area constraints on the architecture. The technique uses an iterative approach consisting of closely linked hardware-software partitioner and scheduler. Both the partitioner and scheduler operate on the task graph in a hierarchical top down manner. The technique optimizes deterministic loop constructs by applying clustering, unrolling and pipelining. The technique considers speculative execution for conditional constructs. The number of actual hardware/software implementations of a function in the task graph are also optimized by the technique. The effectiveness of the technique is demonstrated by a case study of an image compression algorithm.

#*Memory architecture for efficient utilization of SDRAM: a case study of the computation/memory access trade-off.
#@Thomas Gleerup,Hans Holten-Lund,Jan Madsen,Steen Pedersen
#t2000
#cCODES
#index106112
#%647927
#%593525
#%593626
#!This paper discusses the trade-off between calculations and memory accesses in a 3D graphics tile renderer for visualization of data from medical scanners. The performance requirement of this application is a frame rate of 25 frames per second when rendering 3D models with 2 million triangles, i.e. 50 million triangles per second, sustained (not peak). At present, a software implementation is capable of 3-4 frames per second for a 1 million triangle model.By using direct evaluation of certain interpolation parameters instead of forward differencing, writing back parameters to SDRAM is avoided. In software, forward differencing is usually better, but in this hardware implementation, the trade-off has made it possible to develop a very regular memory architecture with a buffering system, which can reach 95% bandwidth utilization using off-the-shelf SDRAM. This is achieved by changing the algorithm to use a memory access strategy with write-only and read-only phases, and a buffering system, which uses round-robin bank write-access combined with burst read-access.

#*RECOD: a retiming heuristic to optimize resource and memory utilization in HW/SW codesigns.
#@Karam S. Chatha,Ranga Vemuri
#t1998
#cCODES
#index106113
#%50300
#%106292
#%542822
#%131354

#*Future wireless convergence platforms.
#@C. John Glossner,Mayan Moudgill,Daniel Iancu,Gary Nacer,Sanjay Jinturkar,Stuart Stanley,Michael Samori,Tanuj Raja,Michael J. Schulte,Stamatis Vassiliadis
#t2005
#cCODES+ISSS
#index106114
#%1008381
#%243524
#%77
#%106230
#!As wireless platforms converge to multimedia systems, architectures must converge to support voice, data, and video applications. From a processor architecture perspective, support for signal processing (both audio and video), control code, and Java execution will be required in a convergent device. Traditionally, wireless communications systems have been implemented in hardware. Convergent devices must be able to roam seamlessly across multiple communications systems. To avoid excessive hardware costs, a Software Defined Radio (SDR) approach offers a programmable and dynamically reconfigurable method of reusing hardware to implement physical layer processing. In this paper, we discuss trends in wireless platforms which are inherently convergence platforms. We also present the Sandbridge state-of-the-art example platform that supports both communications and multimedia applications processing. The architecture efficiently executes Java, Digital Signal Processing (DSP), and control code. Architectural features that reduce power dissipation and enable real-time processing are described. All of the communications and multimedia processing is executed completely in software without specialized hardware support. The processor is programmed in C with supercomputer-class compiler support for automatic vectorization, multithreading, and DSP semantic analysis.

#*Energy savings through compression in embedded Java environments.
#@Guangyu Chen,Mahmut T. Kandemir,Narayanan Vijaykrishnan,Mary Jane Irwin,Wayne Wolf
#t2002
#cCODES
#index106115
#%106115
#%436542
#%597072
#%419587
#!Limited energy and memory resources are important constraints in the design of an embedded system. Compression is an useful and widely employed mechanism to reduce the memory requirements of the system. As the leakage energy of a memory system increases with its size and because of the increasing contribution of leakage to overall system energy, compression also has a significant effect on reducing energy consumption. However, storing compressed data/instructions has a performance and energy overhead associated with decompression at runtime. The underlying compression algorithm, the corresponding implementation of the decompression and the ability to reuse decompressed information critically impact this overhead.In this paper, we explore the influence of compression on overall memory energy using a commercial embedded Java virtual machine (JVM) and a customized compression algorithm. Our results show that compression is effective in reducing energy even when considering the runtime decompression overheads for most applications.

#*A generic multi-unit architecture for codesign methodologies.
#@Guy Gogniat,Michel Auguin,Cécile Belleudy
#t1997
#cCODES
#index106116
#%1502138
#%131250
#%858044
#%858146
#%343282
#%106188
#%193972
#!This paper introduces a template architecture for codesign methodologies. This architecture is based on a data synchronized control scheme that is well adapted to the implementation of numerous telecommunication applications specified with a data flow model. The template architecture permits an easy integration of HW and SW coarse grain units. Communications between internal units are assumed to have an asynchronous protocol that is the more general transfer mechanism but also the more expensive in hardware resources. Hence, a communication synthesis method is presented that transforms asynchronous communications into synchronous ones. Results on an acoustic echo canceller illustrate the interest of the approach.

#*Analyzing heap error behavior in embedded JVM environments.
#@Guilin Chen,Mahmut T. Kandemir,Narayanan Vijaykrishnan,Anand Sivasubramaniam,Mary Jane Irwin
#t2004
#cCODES+ISSS
#index106117
#!Recent studies have shown that transient hardware errors caused by external factors such as alpha particles and cosmic ray strikes can be responsible for a large percentage of system down-time. Denser processing technologies, increasing clock speeds, and low supply voltages used in embedded systems can worsen this problem. In many embedded environments, one may not want to provision extensive error protection in hardware because of (i) form-factor or power consumption limitations, and/or (ii) to keep costs low. Also, the mismatch between the hardware protection granularity and the field access granularity can lead to false alarms and error cancellations. Consequently, software-based approaches to identify and possibly rectify these errors seem to be promising. Towards this goal, this paper specifically looks to enhance the softwareýs ability to detect heap memory errors in a Java-based embedded system. Using several embedded Java applications, this paper first studies the tradeoffs between reliability, performance, and memory space overhead for two schemes that perform error checks at object and field granularities. We also study the impact of object characteristics (e.g., lifetime, re-use intervals, access frequency, etc.) on error propagation. Considering the pros and cons of these two schemes, we then investigate two hybrid strategies that attempt to strike a balance between memory space and performance overheads and reliability. Our experimental results clearly show that the granularity of error protection and its frequency can significantly impact static/dynamic overheads and error detection ability.

#*A method to derive application-specific embedded processing cores.
#@Olivier Hébert,Ivan C. Kraljic,Yvon Savaria
#t2000
#cCODES
#index106118
#%858146
#%1135056
#!The concept of system-on-a-chip is becoming increasingly popular for the integration of complex systems. New types of processor cores are now available that enable the designer to customize their processors for the target applications. These soft cores are not tightly coupled with the target application, and this leads to processing cores sub-optimal for their specific applications. This paper proposes a method to derive application-specific embedded processors from soft processor cores. The derivation process involves an analysis of the resources of the processing core used by the target application. Then a series of optimizations based on the analysis results are performed on an optimizable model of the processor core. We present the tool used to perform the analysis of the resources used by an application, and results from a real-world case. Then, various optimization methods are described.

#*Fast co-simulation of transformative systems with OS support on SMP computer.
#@Zhengting He,Aloysius K. Mok
#t2004
#cCODES+ISSS
#index106119
#%50012
#%832885
#%1135482
#%142180
#%534405
#!Transformative applications are a class of dataflow computation characterized by iterative behavior. The problem of partitioning a transformative application specification to a set of available hardware (HW) and software (SW) processing elements (PEs) and derivation of a job execution order (scheduling) on them has been quite well studied, but the problem of obtaining fast simulation of these applications poses different constraints. In this paper, we propose an efficient framework for a symmetric multi-processor (SMP) simulation host to achieve fast HW/SW co-simulation for transformative applications, given the partition solutions and the derived schedulers. The framework overcomes the limitations in existing Linux SMP kernel and requires only a reasonable amount of modifications to it. We also present a heuristic algorithm which effectively assigns simulation tasks to the processors on the simulation host, considering both average job simulation time on each processor and other simulation overhead. Our experiments show that the algorithm is able to find satisfactory suboptimal solutions with very little computation time. Based on the task assignment solution, the simulation time can be reduced by 25% to 50% from the obvious but naive approach.

#*Optimized rapid prototyping for real-time embedded heterogeneous multiprocessors.
#@Thierry Grandpierre,Christophe Lavarenne,Yves Sorel
#t1999
#cCODES
#index106120
#%857832
#%1127683
#%858040
#%989102
#%1125254
#%989138
#%989132
#%529850
#%600882
#%1035811

#*A unified approach to constrained mapping and routing on network-on-chip architectures.
#@Andreas Hansson,Kees Goossens,Andrei Radulescu
#t2005
#cCODES+ISSS
#index106121
#%338469
#%805785
#%141783
#%1124642
#%142871
#%141969
#%133849
#%131914
#%252784
#%52668
#%142746
#%142588
#%133273
#!One of the key steps in Network-on-Chip (NoC) based design is spatial mapping of cores and routing of the communication between those cores. Known solutions to the mapping and routing problem first map cores onto a topology and then route communication, using separated and possibly conflicting objective functions. In this paper we present a unified single-objective algorithm, called Unified MApping, Routing and Slot allocation (UMARS). As the main contribution we show how to couple path selection, mapping of cores and TDMA time-slot allocation such that the network required to meet the constraints of the application is minimized. The time-complexity of UMARS is low and experimental results indicate a run-time only 20% higher than that of path selection alone. We apply the algorithm to an MPEG decoder System-on-Chip (SoC), reducing area by 33%, power by 35% and worst-case latency by a factor four over a traditional multi-step approach.

#*Speed-up estimation for HW/SW-systems.
#@Wolfram Hardt,Wolfgang Rosenstiel
#t1996
#cCODES
#index106122
#%105984
#%2353
#%106135
#%132619
#%193972
#%193915
#%106346
#!HW/SW-codesign has been applied to a wide range of applications. Several partitioning methods have been suggested. Thus the designer selects modules for HW or SW-implementation for the best possible performance within a set of performance and design constraints. This paper describes an estimation method to approximate a priori the entire system performance. The estimation method has been integrated into the codesign tool COD and first results could be generated. The estimated speed-up has been determined for a ciphering algorithm and has been compared to the speed-up of the entire HW/SW-system. The estimation speed-up matches the final speedup.

#*Performance Analysis in CoDe-X Partitioning for Structural Programmable Accelerators.
#@Reiner W. Hartenstein,Jürgen Becker
#t1997
#cCODES
#index106123
#%106124
#%215219
#%858044
#%806605
#%52323
#%49923
#%245247
#%409206
#%214981
#%1053194
#%132619
#%1126010
#!The paper presents the performance analysis process within the parallelizing compilation environment CoDe-X for simultaneous programming of Xputer-based accelerators and their host. The paper introduces briefly its hardware/software co-design strategies at two levels of partitioning. CoDe-X performs both, at first level a profiling-driven host/accelerator partitioning for performance optimization, and at second level a resource-driven sequential/structural partitioning of the accelerator source code to optimize the utilization of its reconfigurable resources. The analysis of candidate (task) performances in CoDe-X has to be done for both, a procedural (sequential) programmable host processor, and the structural programmable data-driven accelerator processor. In complete application time estimation data-dependencies for parallel task execution (host/accelerators) are considered. To stress the significance of this application development methodology, the paper first gives an introduction to the target hardware platform.

#*Two-level Partitioning of Image Processing Algorithms for the Parallel Map-oriented Machine.
#@Reiner W. Hartenstein,Jürgen Becker,Rainer Kress
#t1996
#cCODES
#index106124
#%214981
#%215084
#%858044
#%806605
#%52323
#%1053194
#%286743
#%1126010
#!The partitioning of image processing algorithms with a novel hardware/software co-design framework (CoDe-X) is presented in this paper, where a new Xputer-architecture (parallel Map-oriented Machine) is used as universal accelerator based on a reconfigurable datapath hardware for speeding-up image processing applications. CoDe-X accepts C-programs and carries out both, the profiling-driven host/accelerator partitioning for performance optimization, and the resource-driven sequential/structural partitioning of the accelerator source code to optimize the utilization of its reconfigurable datapath resources.

#*A systematic approach to software peripherals for embedded systems.
#@Dimitris Lioupis,Apostolos Papagiannis,Dionysia Psihogiou
#t2001
#cCODES
#index106125
#%203232
#%131783
#%283294
#%808029
#%806356
#%857832
#!The continued growth of microprocessors' performance and the need for better CPU utilization, has led to the introduction of the software peripherals' approach: By this term we refer to software modules that can successfully emulate peripherals that, until now, were traditionally implemented in hardware. Software implementations offer great flexibility in product design and in functional upgrades, while they have high contribution in the cost/performance ratio optimization. We focus on embedded applications, where the cost and the short time to market are the leading issues. In this paper, we study the hardware and software requirements for developing a generic microprocessor with support for software peripherals. Additionally, we present three software peripherals, a Universal Asynchronous Receiver Transmitter, a keypad controller and a dot matrix LCD controller, and we analyze their impact in CPU occupation. Finally, we explore the impact of using a software UART on system power dissipation.

#*VL-CDRAM: variable line sized cached DRAMs.
#@Ananth Hegde,Narayanan Vijaykrishnan,Mahmut T. Kandemir,Mary Jane Irwin
#t2003
#cCODES+ISSS
#index106126
#%418603
#%418575
#%418924
#%1008815
#%418692
#!Many of the current memory architectures embed a SRAM cache within the DRAM memory. These architectures exploit a wide internal data bus to transfer an entire DRAM row to the on-memory cache. However, applications exhibit a varying spatial locality across the different DRAM rows that are accessed and buffering the entire row may be wasteful. In order to adapt to the changing spatial locality, we propose a Variable Line size Cached DRAM (VL-CDRAM) that can buffer portions of an accessed DRAM row. Our evaluation shows that the proposed approach is effective in not only reducing the energy consumption but also in improving the performance across various memory configurations.


#*Communication speed selection for embedded systems with networked voltage-scalable processors.
#@Jinfeng Liu,Pai H. Chou,Nader Bagherzadeh
#t2002
#cCODES
#index106127
#%106040
#%1135277
#%132986
#%282905
#%646246
#%1135127
#!High-speed serial network interfaces are gaining wide use in connecting multiple processors and peripherals in modern embedded systems, thanks to their size advantage and power efficiency. Many such interfaces also support multiple data rates, and this ability is opening a new dimension in the power/performance trade-offs between communication and computation on voltage scalable embedded processors. To minimize energy consumption in these networked architectures, designers must not only perform functional partitioning but also carefully balance the speeds between communication and computation, which compete for time and energy. Minimizing communication power without considering computation may actually lead to higher energy consumption at the system level due to elongated on-time as well as lost opportunities for dynamic voltage scaling on the processors. We propose a speed selection methodology for globally optimizing the energy consumption in embedded networked architectures. We formulate a multi-dimensional optimization problem by modeling communication dependencies between processors and their timing budgets. This enables engineers to systematically solve the problem of optimal speed selection for global energy reduction. We demonstrate the effectiveness of our speed selection approach with an image processing application mapped onto a multi-processor architecture with a multi-speed Ethernet.

#*The Interplay of Run-Time Estimation and Granularity in HW/SW Partitioning.
#@Jörg Henkel,Rolf Ernst
#t1996
#cCODES
#index106128
#%77
#%193991
#%450666
#%106003
#%858044
#%282259
#%450621
#%106162
#%193943
#%106188
#%132676
#%106319
#%193972
#!An important presupposition for HW/SW partitioning are sophisticated estimation algorithms at a high level of abstraction that obtain high quality results. Therefore the granularities of estimation and partitioning have to be adapted adequately. In this paper we discuss the effects that arise when the granularities of partitioning and estimation are not adapted in a necessary way. Furthermore we present our solution that allows to choose different levels of granularities adapted to the estimation and partitioning phase. The experiments show that this refinement in estimation at a high level of abstraction leads to an improvement (in terms of run-time and chip area) of the whole mixed HW/SW system.

#*A constraint-based application model and scheduling techniques for power-aware systems.
#@Jinfeng Liu,Pai H. Chou,Nader Bagherzadeh,Fadi J. Kurdahi
#t2001
#cCODES
#index106129
#%281951
#%450676
#%450618
#%1135077
#%131778
#%282292
#!New embedded systems must be power-aware, not just low-power. That is, they must track their power sources and the changing power and performance constraints imposed by the environment. Moreover, they must fully explore and integrate many novel power management techniques. Unfortunately, these techniques are often incompatible with each other due to overspecialized formulations or they fail to consider system-wide issues. This paper proposes a new graph-based model to integrate novel power management techniques and facilitate design-space exploration of power-aware embedded systems. It captures min/max timing and min/max power constraints on computation and non-computation tasks through a new constraint classification and enables derivation of flexible system-level schedules. We demonstrate the effectiveness of this model with a power-aware scheduler on real mission-critical applications. Experimental results show that our automated techniques can improve performance and reduce energy cost simultaneously. The application model and scheduling tool presented in this paper form the basis of the IMPACCT system-level framework that will enable designers to aggressively explore many power-performance trade-offs with confidence.

#*Energy-conscious HW/SW-partitioning of embedded systems: a case study on an MPEG-2 encoder.
#@Jörg Henkel,Yanbing Li
#t1998
#cCODES
#index106130
#%106216
#%282990
#%193972
#%282088
#%132715
#%436814
#%132396
#%131937
#%132358

#*Design space exploration of a hardware-software co-designed GF(2) galois field processor for forward error correction and cryptography.
#@Wei Ming Lim,Mohammed Benaissa
#t2003
#cCODES+ISSS
#index106131
#!This paper describes a hardware-software co-design approach for flexible programmable Galois Field Processing for applications which require operations over GF(2m), such as RS and BCH codes, Elliptic Curve Cryptography and the AES. Complexities of flexible implementations of different applications on a same computation architecture can be migrated to software during design time. However, the underlying GF(2m) arithmetic architecture needs to be designed with software programmability (or reconfigurability) in mind. We describe novel reconfigurable subword parallel GF(2m) arithmetic architectures designed with an associated instruction set architecture for different applications over GF(2m) and same applications with differing parameters. Design space exploration is carried out with two simple parameters P and Q which can be changed at design time and will affect the performance of different applications and flexibility of the final implementation. We show implementation results given for an FPGA prototype of the processor and programmed for RS and BCH coding, AES and elliptic curve cryptography with differing parameters. Complexity figures and configuration overheads for subword parallel GF(2m) arithmetic architectures are also estimated and discussed.

#*Aggressive snoop reduction for synchronized producer-consumer communication in energy-efficient embedded multi-processors.
#@Chenjie Yu,Peter Petrov
#t2007
#cCODES+ISSS
#index106132
#%131389
#%252922
#%436691
#%1008306
#%410164
#%233981
#%419215
#%419612
#%499311
#!Snoop-based cache coherence protocols are typically used when multiple processor cores share memory through a common bus. It is well known, however, that these coherence protocols introduce an excessive power overhead.To help alleviate this problem, we propose an application-driven customization technique where application knowledge regarding data sharing in producer-consumer relationships is used in order to aggressively eliminate unnecessary and predictable snoop-induced cache tag lookups even for references to shared data, thus, achieving significant power reduction with minimal hardware cost. Snoop-induced cache tag lookups for accesses to both shared and private data are eliminated when it is ensured that such lookups will not result in extra knowledge regarding the cache state in respect to the other caches and memories.The proposed methodology relies on the combined support from the compiler, the operating system, and the hardware architecture. Our experiments show average power reductions of more than 80% compared to a general-purpose snoop protocol.

#*Implementation of dynamic streaming Applications on heterogeneous multi-Processor architectures.
#@Tomas Henriksson,Jeffrey Kang,Pieter van der Wolf
#t2005
#cCODES+ISSS
#index106133
#%450550
#%776406
#%181318
#%106351
#%77578
#!System design based on static task graphs does not match well with modern consumer electronic devices with dynamic stream processing applications.We propose the TTL API for task graph reconfiguration services,which can be used to describe the dynamic behaviour of applications.We demonstrate the efficient implementation of the TTL API on a heterogeneous multi-processor architecture.It is possible to design dynamic streaming applications with reusable reconfiguration-aware tasks and we argue that the TTL API serves as a good starting point for standardization.

#*Software timing analysis using HW/SW cosimulation and instruction set simulator.
#@Jie Liu,Marcello Lajolo,Alberto L. Sangiovanni-Vincentelli
#t1998
#cCODES
#index106134
#%134030
#%133702
#%282088

#*An approach to the adaptation of estimated cost parameters in the COSYMA system.
#@Dirk Herrmann,Jörg Henkel,Rolf Ernst
#t1994
#cCODES
#index106135
#%282259
#%858044
#%132209
#%77
#!Hardware/software partitioning is one of the key issues in hardware/software co-design. The system COSYMA uses simulated annealing based on estimated costs. Deviations between estimations and real costs seem unavoidable due to synthesis, compiler and communication effects. This paper describes an approach to adapt the estimation. The results show fast convergence of estimated to real costs.

#*A low-cost and low-power multi-standard video encoder.
#@Rafael Peset Llopis,Ramanathan Sethuraman,Carlos A. Alba Pinto,Harm Peters,Steffen Maul,Marcel Oosterhuis
#t2003
#cCODES+ISSS
#index106136
#%1165740
#!Video encoders are an important IP block in mobile multimedia systems. In this paper, we describe a low-cost low-power multi-standard (MPEG4, JPEG, and H.263) video/image encoder. The low-cost and low-power aspects are achieved by the right choice of algorithms and architectures. In the algorithm front, an embedded compression technique for reducing the size of loop memory has enabled a single-chip low-cost realization of the encoder. In the architectural front, an efficient hardware-software partitioning has contributed to the design of a low-power encoder. Further, the hardware components that accelerate the kernels of encoding are implemented as application specific instruction-set processors (ASIPs) thereby providing flexibility to address multi-standard encoding. The power and area estimates for the encoder for QCIF@15fps in 0.18um CMOS technology are 30mW and 20mm2 respectively including the loop memory.

#*Optimizing communication in embedded system co-simulation.
#@Ken Hines,Gaetano Borriello
#t1997
#cCODES
#index106137
#%131408
#%281938
#!The Pia hardware-software co-simulator provides substantial speedups over traditional co-simulation methods by permitting dynamic changes in the level of detail when simulating communication channels between system components. However, it places a burden on the designer to develop several communication routines, at different levels of abstraction, for each communication operation. This often requires an intimate understanding of both the simulator and the design being simulated. We present and demonstrate a way to use communication transaction annotations to provide a platform independent language for describing fast communication primitives. Additionally we show a tool for automatically generating some of these annotations, so that the designer does not even require an intimate understanding of the design under simulation. This can be important when simulating systems where the design itself is synthesized by automatic tools, and is liable to change frequently.

#*Low-power task scheduling for multiple devices.
#@Yung-Hsiang Lu,Luca Benini,Giovanni De Micheli
#t2000
#cCODES
#index106138
#%141744
#%142412
#%436605
#%436511
#%1141293
#%282732
#%133894
#!Power management saves power by shutting down idle devices. These devices often serve requests from concurrently running tasks. Ordering task execution can adjust the lengths of idle periods and exploit better opportunities for power management. This paper presents an on-line low-power scheduling algorithm for multiple devices. Simulations show that it can save up to 33% power and reduce 40% state-transition delays. This algorithm is robust under imperfect knowledge of future requests and timing constraints; therefore, it is applicable to interactive systems.

#*The priority queue as an example of hardware/software codesign.
#@Flemming Høeg,Niels Mellergaard,Jørgen Staunstrup
#t1994
#cCODES
#index106139
#%777059
#%1056831
#!This paper identifies a number of issues that we believe are important for hardware/software codesign. The issues are illustrated by a small comprehensible example: a priority queue. Based on simulations of a real application, we suggest a combined hardware/software realization of the priority queue.

#*Software controlled power management.
#@Yung-Hsiang Lu,Tajana Simunic,Giovanni De Micheli
#t1999
#cCODES
#index106140
#%233997
#%141744
#%1135177
#%282355
#%436949
#%133441
#%1135077

#*Hardware and software architectures for the CELL processor.
#@H. Peter Hofstee,Michael N. Day
#t2005
#cCODES+ISSS
#index106141

#*A trace transformation technique for communication refinement.
#@Paul Lieverse,Pieter van der Wolf,Ed F. Deprettere
#t2001
#cCODES
#index106142
#%50123
#%132734
#%106086
#%114329
#%486206
#!Models of computation like Kahn and dataflow process networks provide convenient means for modeling signal processing applications. This is partly due to the abstract primitives that these models offer for communication between concurrent processes. However, when mapping an application model onto an architecture, these primitives need to be mapped onto architecture level communication primitives. We present a trace transformation technique that supports a system architect in performing this communication refinement. We discuss the implementation of this technique in a tool for architecture exploration named SPADE and present examples.

#*Secure FPGA circuits using controlled placement and routing.
#@Pengyuan Yu,Patrick Schaumont
#t2007
#cCODES+ISSS
#index106143
#%805844
#%1082096
#%895300
#!In current Field-Programmable-Logic Architecture (FPGA) design flows, it is very hard to control the routing of submodules. It is thus very hard to make an identical copy of an existing circuit within the same FPGA fabric. We have solved this problem in a way that still enables us to modify the logic function of the copied sub-module. Our technique has important applications in the design of side-channel resistant implementations in FPGA. Starting from an existing single-ended design, we are able to create a complementary circuit. The resulting overall circuit strongly reduces the power-consumption-dependent information leaks. We show that the direct mapping of a secure ASIC circuit-style in an FPGA does not preserve the same level of security, unless our symmetrical routing technique is employed. We demonstrate our approach on an FPGA prototype of a cryptographic design, and show through power-measurements followed by side-channel power analysis that secure logic implemented with our approach is resistant whereas non-routing-aware directly mapped circuits can be successfully attacked.

#*HiPART: a new hierarchical semi-interactive HW-/SW partitioning approach with fast debugging for real-time embedded systems.
#@Thomas Hollstein,Jürgen Becker,Andreas Kirschbaum,Manfred Glesner
#t1998
#cCODES
#index106144
#%106150
#%106124
#%106325
#%106216
#%131250
#%806605
#%193991
#%858044

#*Towards a declarative framework for hardware-software codesign.
#@Wayne Luk,Teddy Wu
#t1994
#cCODES
#index106145
#%808448
#%2595
#%1165929
#!We present an experimental framework for mapping declarative programs, written in a language known as Ruby, into various combinations of hardware and software. Strategies for parametrised partitioning into hardware and software can be captured concisely in this framework, and their validity can be checked using algebraic reasoning. The method has been used to guide the development of prototype compilers capable of producing, from a Ruby expression, a variety of implementations involving field-programmable gate arrays (FPGAs) and microprocessors. The viability of this approach is illustrated using a number of examples for two reconfigurable systems, one containing an array of Algotronix devices and a PC host, and the other containing a transputer and a Xilinx device.

#*A practical tool box for system level communication synthesis.
#@Denis Hommais,Frédéric Pétrot,Ivan Augé
#t2001
#cCODES
#index106146
#%141996
#%106086
#%131540
#%281938
#%1135119
#%2595
#!This paper presents a practical approach to communication synthesis for hardware/software system specified as tasks communicating through lossless blocking channels. It relies on a limited set of templates that characterize the way data are exchanged between tasks realized either in software or in hardware. The templates are highly portable because their software part is implemented using the POSIX thread functions, and their hardware part is a hand crafted synthesizable module with a System VCI interface. These Interface Modules allow simple Virtual Component reuse since they not only implement protocol compatibility through the use of the System VCI/OCB standard but also system level communications through semantics widely accepted in the design community.

#*A codesigned on-chip logic minimizer.
#@Roman L. Lysecky,Frank Vahid
#t2003
#cCODES+ISSS
#index106147
#%133014
#%133988
#%203080
#%105977
#%1008243
#!Boolean logic minimization is traditionally used in logic synthesis tools running on powerful desktop computers. However, logic minimization has recently been proposed for dynamic use in embedded systems, including network route table reduction, network access control list table reduction, and dynamic hardware/software partitioning. These new uses require logic minimization to run dynamically as part of an embedded system's active operation. Performing such dynamic logic minimization on-chip greatly reduces system complexity and security versus an approach that involves communication with a desktop logic minimizer. An on-chip minimizer must be exceptionally lean yet yield good enough results. Previous software-only on-chip minimizer results have been good, but we show that a codesigned minimizer can be much better, executing nearly 8 times faster and consuming nearly 60% less energy, while yielding identical results.

#*RTOS-centric hardware/software cosimulator for embedded system design.
#@Shinya Honda,Takayuki Wakabayashi,Hiroyuki Tomiyama,Hiroaki Takada
#t2004
#cCODES+ISSS
#index106148
#!This paper presents an RTOS-centric hardware/software cosimulator which we have developed for embedded system design. One of the most remarkable features in our cosimulator is that it has a complete simulation model of an RTOS which is widely used in industry, so that application tasks including RTOS service calls are natively executed on a host computer. Our cosimulator also features cosimulation with functional simulation models of hardware written in C/C++ and cosimulation with HDL simulators. A case study with a JPEG decoder application demonstrates the effectiveness of our cosimulator.

#*Embedded system synthesis under memory constraints.
#@Jan Madsen,Peter Bjørn-Jørgensen
#t1999
#cCODES
#index106149
#%50123
#%1493486
#%106070
#%106020
#%1125103
#%1059577
#%450544
#%1125254
#%1166072
#%1125767

#*Process Partitioning for Distributed Embedded Systems.
#@Junwei Hou,Wayne Wolf
#t1996
#cCODES
#index106150
#%450609
#%858146
#%858044
#%193972
#%106045
#%450659
#%106003
#%1135127
#%193816
#%1128420
#%132619
#!We present a new technique for partitioning processes in distributed embedded systems. Our heuristic algorithm minimizes both context switch and communication overhead under real-time deadline and process size constraints; it also tries to allocate functions to processors which are well-suited to that function. The algorithm analyzes the sensitivity of the latency of the task graph to changes in vertices hierarchical clustering, splitting and border adjusting. This algorithm can be used for initial partitioning during co-synthesis of distributed embedded systems. Synthesis of examples partitioned by our algorithm with implementations synthesized directly from the original example shows that our partitioning algorithm significantly improves the results obtainable by practical co-synthesis algorithms.

#*Analytical models for leakage power estimation of memory array structures.
#@Mahesh Mamidipaka,Kamal S. Khouri,Nikil D. Dutt,Magdy S. Abadir
#t2004
#cCODES+ISSS
#index106151
#!There is a growing need for accurate power models at the system level. Memory structures such as caches, Branch Target Buffers (BTBs), and register files occupy significant area in contemporary SoC designs and are the main contributors to system leakage power dissipation. Existing models for leakage power estimation in array structures typically use coefficients derived from elaborate SPICE simulations. However, these methodologies are not applicable to array designs in a newer technology, that require power estimates early in the design cycle. In this paper, we propose analytical models for array structures that are based only on high level design parameters. Assuming typical circuit implementation styles, we identify the transistors that contribute to the leakage power in each array sub-circuit and develop models as a function of the operation (read/write/idle) on the array and organizational parameters of the array. The developed models are validated by comparing their estimates against the leakage power measured using SPICE simulations on industrial array designs belonging to the e5001 processor core. The comparison shows that the models are accurate with an error margin of less than 21.5% and thus can be used in high-level power-performance exploration. Interestingly, in array designs with dual threshold voltage technology, we observed that contrary to the general expectation, the array memory core contributes to just 9% and the address decoder contributes to as much as 62% of the total leakage power.

#*Modeling micro-controller peripherals for high-level co-simulation and synthesis.
#@Harry Hsieh,Alberto L. Sangiovanni-Vincentelli
#t1997
#cCODES
#index106152
#%131356
#%1135062
#!Luciano Lavagno, Claudio Passerone, and Claudio SansoePolitecnico di TorinoMapping a behavior on an embedded system involves hardware-software partitioning and assignment of software and hardware tasks to different components. In particular, software tasks in embedded controllers are mostly assigned to a micro-controller. However, some micro-controller peripherals are implemented with partly programmable components that can be regarded as very simple co-processors with limited instruction sets and capabilities. Embedded system designers are used to mapping some simple software tasks onto these simple co-processors, obtaining overall performances that can be orders of magnitude superior to the ones obtained mapping all software tasks to the micro-controller itself. In this paper, we propose a methodology to specify, simulate, and partition tasks that can be implemented on programmable micro-controller peripherals such as Timing Processing Units (TPUs). Following our general philosophy, we let the designer propose a partition, and we provide an environment to: - efficiently simulate and evaluate a particular implementation choice, - automate downstream synthesis for software, hardware, as well as peripheral programming routines.

#*Optimizing the memory bandwidth with loop fusion.
#@Paul Marchal,José Ignacio Gómez,Francky Catthoor
#t2004
#cCODES+ISSS
#index106153
#!The memory bandwidth largely determines the performance and energy cost of embedded systems. At the compiler level, several techniques improve the memory bandwidth at the scope of a basic block, but often fail to exploit all. We propose a technique to optimize the memory bandwidth across the boundaries of a basic block. Our technique incrementally fuses loops to better use the available bandwidth. The resulting performance depends on how the data is assigned to the memories of the memory layer. At the same time, the assignment also strongly influences the energy cost. Therefore, we combine in our approach the fusion and assignment decisions. Designers can use our output to trade-off the energy cost with the systemýs performance.

#*Formal synthesis and code generation of embedded real-time software.
#@Pao-Ann Hsiung
#t2001
#cCODES
#index106154
#%1117741
#%106156
#%133848
#%132938
#%564969
#%1275169
#%1117743
#%1123734
#!Due to rapidly increasing system complexity, shortening time-to-market, and growing demand for hard real-time systems, formal methods are becoming indispensable in the synthesis of embedded systems, which must satisfy stringent temporal, memory, and environment constraints. There is a general lack of practical formal methods that can synthesize complex embedded real-time software (ERTS). In this work, a formal method based on Time Free-Choice Petri Nets (TFCPN) is proposed for ERTS synthesis. The synthesis method employs quasi-static data scheduling for satisfying limited embedded memory requirements and uses dynamic real-time scheduling for satisfying hard real-time constraints. Software code is then generated from a set of quasi-statically and dynamically scheduled TFCPNs. Finally, an application example is given to illustrate the feasibility of the proposed TFCPN-based formal method for ERTS synthesis.

#*What will system level design be when it grows up?
#@Grant Martin,Daniel Gajski,David Goodwin,Patrick Lysaght,Peter Marwedel,Mike Muller,Jeff Welser
#t2005
#cCODES+ISSS
#index106155
#!We have seen a growing new interest in Electronic System Level (ESL) architectures, design methods, tools and implementation fabrics in the last few years. But the picture of what types and approaches to building embedded systems will become the most widely-accepted norms in the future remains fuzzy at best. Everyone want to know where systems and system design is going "when it grows up", if it ever "grows up". Some of the key questions that need to be answered include which applications will be key system drivers, what SW & HW architectures will suit best, how programmable and configurable will they be, will systems designers need to deal with physical implementation issues or will that be hidden behind fabric abstractions and programming models, and what will those abstractions and models be? Moreover, will these abstractions stabilize and be still useful as the underlying technology keeps developing at high speed.This panel consists of proponents of a number of alternative visions for where we will end up, and how we will get there.

#*Timing coverification of concurrent embedded real-time systems.
#@Pao-Ann Hsiung
#t1999
#cCODES
#index106156
#%1117741
#%1088786
#%131356
#%450666
#%858044
#%625158
#%564282
#%114424
#%239227

#*Embedded UML: a merger of real-time UML and co-design.
#@Grant Martin,Luciano Lavagno,Jean Louis-Guerin
#t2001
#cCODES
#index106157
#%131879
#%775896
#%979731
#%805750
#%808085
#%1056831
#!In this paper, we present a proposal for a UML profile called `Embedded UML'. Embedded UML represents a synthesis of various ideas in the real-time UML community, and concepts drawn from the Hardware-Software co-design field. Embedded UML first selects from among the competing real-time UML proposals, the set of ideas which best allow specification and analysis of mixed HW-SW systems. It then adds the necessary concept of underlying deployment architecture that UML currently lacks in complete form, using the notion of an embedded HW-SW `platform'. It supplements this with the concept of a `mapping', which is a platform-dependent refinement mechanism that allows efficient generation of an optimised implementation of the executable specification in both HW and SW. Finally, it provides an approach which supports the development of automated analysis, simulation, synthesis and code generation tool capabilities which can be provided for design usage even while the embedded UML standardisation process takes place.

#*Synthesis of real-time embedded software with local and global deadlines.
#@Pao-Ann Hsiung,Cheng-Yi Lin
#t2003
#cCODES+ISSS
#index106158
#%106037
#%213179
#%47247
#%106156
#%133848
#%132938
#%106154
#%1275169
#%1123734
#%645263
#%564969
#!Current methods cannot synthesize real-time embedded software applications when the global deadline of a task is shorter than the total of all local deadlines along a critical path in the task. This creates unnecessary modeling limitations which directly affect the types of systems synthesizable. We propose a quasi-dynamic scheduling algorithm for simultaneously guaranteeing both local and global deadlines, while satisfying all precedence constraints among subtasks and among tasks. Through this scheduling procedure, we are able to formally synthesize real-time embedded software from a network of Real-Time Petri Nets specification. Application examples, including a driver for the Master/Slave role switch in Bluetooth wireless communication devices, are given to illustrate the feasibility of the scheduling algorithm.

#*Secure and safety-critical vs. insecure, non safety-critical embedded systems: do they require completely different design approaches?
#@Peter Marwedel,Catherine H. Gebotys
#t2004
#cCODES+ISSS
#index106159
#%806986
#%77486
#%106095
#!As we move forward into the era of ubiquitous pervasive computing, the design of secure safety-critical systems will become increasingly complex. For example, future automobiles will become the ultimate mobile wireless device containing a distributed network with multiple vendor software and hardware. However the car's embedded software which is expected to increase in size by 100 fold, will create a significant impact on the overall system safety. Furthermore wireless communications may create the possibility of terrorists or attackers gaining control of the automobile, hence security is also an important issue. How will designers cope with this complexity while at the same time ensure safety and security? Will new design approaches be required? Or can current design methodologies be used with new metrics, safety and security? This panel will bring together experts from the safety-critical industry, security industry, and experts from the insecure non-safety critical industry.

#*FIDES: an advanced chip multiprocessor platform for secure next generation mobile terminals.
#@Hiroaki Inoue,Akihisa Ikeno,Masaki Kondo,Junji Sakai,Masato Edahiro
#t2005
#cCODES+ISSS
#index106160
#%636411
#%636189
#!We propose a secure platform on a chip multiprocessor, known as FIDES, in order to enable next generation mobile terminals to execute downloaded native applications for Linux. Its most important feature is the higher security based on multi-grained separation mechanisms: coarse-grained processor-level separation of the basic-function domain from other domains for such downloaded applications, medium-grained OS-level separation, and fine-grained process-level separation within SELinux. Four new technologies, which include three enhancements to SELinux, support the FIDES platform: 1) bus filter logic for processor-level separation can be implemented as a small logic, 2) XIP kernels for memory-efficient OS-level separation can reduce memory requirements by 182%, 3) policy separation for enhanced process-level separation can apply policies 2.1 times faster at system boot-up, and 4) dynamic access control can provide secure Inter-Domain Communications (IDCs) with an overhead of only 4% for IDC system calls. We implemented SELinuxes on an ARM-based multiprocessor. Therefore, the best-suited platform to secure next generation mobile terminals is the FIDES platform, which can provide higher security as well as higher performance and lower power consumption on chip multiprocessors leading the current technology trend of microprocessors.

#*Embedded systems education: how to teach the required skills?
#@Peter Marwedel,Daniel Gajski,Erwin A. de Kock,Hugo De Man,Mariagiovanna Sami,Ingemar Söderquist
#t2004
#cCODES+ISSS
#index106161
#!The goal of this panel is to contrast existing approaches to embedded system education with the needs in industry.

#*COSMOS: a codesign approach for communicating systems.
#@Tarek Ben Ismail,Mohamed Abid,Ahmed Amine Jerraya
#t1994
#cCODES
#index106162
#%86927
#%858582
#%858146
#%858145
#!This paper presents COSMOS, a method for modeling and synthesis of complex communicating systems. COSMOS starts from a system-level specification based on an extended finite state machine model allowing for the specification of complex protocols. System-level synthesis is composed of three tasks: partitioning systems into inter-dependent sub-systems, inter-sub-system communication synthesis and architecture generation. The output is a flexible architecture model which includes both hardware and software components. The overall method will be illustrated through an example.

#*A loop accelerator for low power embedded VLIW processors.
#@Binu K. Mathew,Al Davis
#t2004
#cCODES+ISSS
#index106163
#!The high transistor density afforded by modern VLSI processes have enabled the design of embedded processors that use clustered execution units to deliver high levels of performance. However, delivering data to the execution resources in a timely manner remains a major problem that limits ILP. It is particularly significant for embedded systems where memory and power budgets are limited. A distributed address generation and loop acceleration architecture for VLIW processors is presented. This decentralized on-chip memory architecture uses multiple SRAMs to provide high intra-processor bandwidth. Each SRAM has an associated stream address generator capable of implementing a variety of addressing modes in conjunction with a shared loop accelerator. The architecture is extremely useful for generating application specific embedded processors, particularly for processing input data which is organized as a stream. The idea is evaluated in the context of a fine grain VLIWarchitecture executing complex perception algorithms such as speech and visual feature recognition. Transistor level Spice simulations are used to demonstrate a 159x improvement in the energy delay product when compared to conventional architectures executing the same applications.

#*Resource constrained dataflow retiming heuristics for VLIW ASIPs.
#@Margarida F. Jacome,Gustavo de Veciana,Cagdas Akturan
#t1999
#cCODES
#index106164
#%1124703
#%132288
#%133276

#*Keynote: cellular handset technology system requirements and integration trends.
#@Sven Mattisson
#t2004
#cCODES+ISSS
#index106165
#!In ten years the cellular telephone has evolved from a tool for the professional to an indispensable consumer product with a very high market penetration. At the same time, the handset cost, weight, and standby time have been reduced by more than a factor of ten. These factors have been critical for the success story of the mobile phone.The technical aspects behind the rapid handset evolution are discussed. In particular, what advances in the radio architecture, for example the zero-IF GSM receiver, the baseband (CMOS) technology, and the radio system design areas have meant for the reduction of size, weight, cost, and power consumption is discussed.Future challenges, like SW-DSP-digital-RF partitioning, linear multi-mode modulation with high linearity requirements, digital leakage issues, and power consumption limitations in multimedia handsets are discussed with future generation handsets in mind.

#*Evaluating register file size in ASIP design.
#@Manoj Kumar Jain,Lars Wehmeyer,Stefan Steinke,Peter Marwedel,M. Balakrishnan
#t2001
#cCODES
#index106166
#%193881
#%286743
#%281929
#%52282
#%645137
#%645310
#!Interest in synthesis of Application Specific Instruction Set Processors or ASIPs has increased considerably and a number of methodologies have been proposed for ASIP design. A key step in ASIP synthesis involves deciding architectural features based on application requirements and constraints. In this paper we observe the effect of changing register file size on the performance as well as power and energy consumption. Detailed data is generated and analyzed for a number of application programs. Results indicate that choice of an appropriate number of registers has a significant impact on performance.

#*DVS for buffer-constrained architectures with predictable QoS-energy tradeoffs.
#@Alexander Maxiaguine,Samarjit Chakraborty,Lothar Thiele
#t2005
#cCODES+ISSS
#index106167
#%1135085
#%805601
#%1098584
#%53700
#%286415
#!We present a new scheme for dynamic voltage and frequency scaling (DVS) for processing multimedia streams on architectures with restricted buffer sizes. The main advantage of our scheme over previously published DVS schemes is its ability to provide hard QoS guarantees while still achieving considerable energy savings. Our scheme can handle workloads characterized by both, the data-dependent variability in the execution time of multimedia tasks and the burstiness in the on-chip traffic arising out of multimedia processing. Many previous DVS algorithms capable of handling such workloads rely on control-theoretic feedback mechanisms or prediction schemes based on probabilistic techniques. Usually it is difficult to provide QoS guarantees with such schemes. In contrast, our scheme relies on worst-case interval-based characterization of the workload. The main novelty of our scheme is a combination of offline analysis and runtime monitoring to obtain worst case bounds on the workload and then improving these bounds at runtime. Our scheme is fully scalable and has a bounded application-independent runtime overhead.

#*A novel codesign methodology for real-time embedded COTS multiprocessor-based signal processing systems.
#@Randall S. Janka,Linda M. Wills
#t2000
#cCODES
#index106168
#%1135081
#!The process of designing large real-time embedded signal processing systems is plagued by a lack of coherent specification and design methodology (SDM). Powerful frameworks exist for each individual phase of this canonical design process, but no single methodology exists which enables these frameworks to work together coherently, i.e., allowing the output of a framework used in one phase to be consumed by a different framework used in the next phase. A specification and design methodology (SDM) known as &ldquo;Search-Explore-Refine&rdquo; (SER) was developed by Gajski, Vahid, et al. for an application and technology domain that is different from that of real-time embedded signal processing systems implemented with commercial-off-the-shelf multiprocessing hardware and software. However, due to similarities between the fundamental design objects of these two domains, a new SDM was developed and prototyped based on SER known as the MAGIC SDM. The &ldquo;tools and rules&rdquo; of the MAGIC SDM are presented. The MAGIC SDM achieves a high degree of model continuity based largely on its use of standards-based computation (VSIPL) and communication (MPI) middleware.

#*Tuning SoC platforms for multimedia processing: identifying limits and tradeoffs.
#@Alexander Maxiaguine,Yongxin Zhu,Samarjit Chakraborty,Weng-Fai Wong
#t2004
#cCODES+ISSS
#index106169
#!We present a analytical framework to identify the tradeoffs and performance impacts associated with different SoC platform configurations in the specific context of implementing multimedia applications. "Configurations" in this case might include sizes of different on-chip buffers and scheduling mechanisms (or associated parameters) implemented on the different processing elements of the platform. Identifying such tradeoffs is difficult because of the bursty nature of on-chip traffic arising out of multimedia processing and the high variability in their execution requirements, which result in a highly irregular design space. We show that this irregularity in the design space can be precisely captured using an abstraction called variability characterization curves.

#*On the roles of functions and objects in system specification.
#@Axel Jantsch,Ingo Sander
#t2000
#cCODES
#index106170
#%805940
#%684744
#%832939
#%776181
#%1071851
#%1117931

#*Efficient performance analysis of asynchronous systems based on periodicity.
#@Peggy B. McGee,Steven M. Nowick,Edward G. Coffman Jr.
#t2005
#cCODES+ISSS
#index106171
#%55200
#%55271
#%55235
#%55196
#%55037
#%55071
#%55168
#%55222
#%49827
#%418954
#%286301
#%285726
#%285628
#%1134639
#!This paper presents an efficient method for the performance analysis and optimization of asynchronous systems. An asynchronous system is modeled as a marked graph with probabilistic delay distributions. We show that these systems exhibit inherent periodic behaviors. Based on this property, we derive an algorithm to construct the state space of the system through composition and capture the time evolution of the states into a periodic Markov chain. The system is solved for important performance metrics such as the distribution of input arrival time at a component, which is useful for subsequent system optimization, as well as relative component utilization, system latency and throughput. We also present a tool to demonstrate the feasibility of this method. Initial experimental results are promising, showing over three orders of magnitude improvement in runtime and nearly two orders of magnitude decrease in the size of the state space over previously published results. While the focus of this paper is on asynchronous digital systems, our technique can be applied to other concurrent systems that exhibit global asynchronous behavior, such as GALS and embedded systems.

#*The usage of stochastic processes in embedded system specifications.
#@Axel Jantsch,Ingo Sander,Wenbiao Wu
#t2001
#cCODES
#index106172
#%106287
#%106170
#%546469
#%310267
#%645957
#!We review the use of nondeterminism and identify two different purposes. The descriptive purpose handles uncertainties in the behaviour of existing entities. The constraining purpose is used in specifications to constrain implementations. For the specification of embedded systems we suggest a stochastic processor instead of nondeterminism. It serves mostly the descriptive purpose but can also be used to constrain the system. We carefully distinguish different interpretations of these concepts by the different design activities simulation, synhesis and verification.

#*Linking codesign and reuse in embedded systems design.
#@Matthias Meerwein,C. Baumgartner,W. Glauert
#t2000
#cCODES
#index106173
#%106325
#%142859
#%858044
#%106144
#%142261
#%142676
#!This paper presents a complete codesign environment for embedded systems which combines automatic partitioning with reuse from a module database. Special emphasis has been put on satisfying the requirements of industrial design practice and on the technical and economic constraints associated with automotive control applications. The object-oriented database architecture allows efficient management of a large number of modules. Experimental results from a real-world example demonstrate the viability and advantages of the presented methodology.

#*The importance of interfaces: a HW/SW codesign case study.
#@D. C. R. Jensen,Jan Madsen,Steen Pedersen
#t1997
#cCODES
#index106174
#%167409
#%106216
#!This paper presents a codesign case study in image analysis. The main objective is to stress the importance of handling HW/SW interfaces more precisely at the system level. In the presented case study, there is an intuitive and simple HW/SW interface, which is based upon the functional modules in the application. However, it is found that this seemingly sound choice caused a number of practical problems and sub-optimal solutions during the implementation of the prototype system.

#*A case study of mapping a software-defined radio (SDR) application on a reconfigurable DSP core.
#@Behzad Mohebbi,Eliseu Chavez Filho,Rafael Maestre,Mark Davies,Fadi J. Kurdahi
#t2003
#cCODES+ISSS
#index106175
#%807321
#%1165953
#!We present a case study involving the implementation of a complete Wideband CDMA (WCDMA) digital receiver part of an AMR channel onto a reconfigurable core. WCDMA is one of the two major standards for the third generation (3G) cellular systems. Traditionally most of the receiver components were confined to ASIC implementation for performance, size and power consumption reasons. The MS1 reconfigurable DSP core provides both a microprocessor and reconfigurable fabric as well as a variety of peripherals. The various functions of the receiver were mapped onto different core components. The complete system was tested both in simulation as well as on a hardware platform comprising a silicon implementation of the MS1 DSP core.

#*Transformation of SDL specifications for system-level timing analysis.
#@Marek Jersak,Kai Richter,Rafik Henia,Rolf Ernst,Frank Slomka
#t2002
#cCODES
#index106176
#%562570
#%105994
#%52241
#%1052993
#%1056831
#%450506
#%142866
#%106302
#%1053257
#%1135494
#!Complex embedded systems are typically specified using multiple domain-specific languages. After code-generation, the implementation is simulated and tested. Validation of non-functional properties, in particular timing, remains a problem because full test coverage cannot be achieved for realistic designs. The alternative, formal timing analysis, requires a system representation based on key application and architecture properties. These properties must first be extracted from a system specification to enable analysis. In this paper we present a suitable transformation of SDL specifications for system-level timing analysis. We show ways to vary modeling accuracy in order to apply available formal techniques. A practical approach utilizing a recently developed system model is presented.

#*Automated data cache placement for embedded VLIW ASIPs.
#@Paul Morgan,Richard Taylor,Japheth Hossell,George Bruce,Barry O'Rourke
#t2005
#cCODES+ISSS
#index106177
#%132243
#%1117875
#%452386
#%419661
#%858383
#%1098566
#%600814
#%141971
#%807392
#!Memory bandwidth issues present a formidable bottleneck to accelerating embedded applications, particularly data bandwidth for multiple-issue VLIW processors. Providing an efficient ASIP data cache solution requires that the cache design be tailored to the target application. Multiple caches or caches with multiple ports allow simultaneous parallel access to data, alleviating the bandwidth problem if data is placed effectively. We present a solution that greatly simplifies the creation of targeted caches and automates the process of explicitly allocating individual memory access to caches and banks. The effectiveness of our solution is demonstrated with experimental results.

#*Logic optimization and code generation for embedded control applications.
#@Yunjian Jiang,Robert K. Brayton
#t2001
#cCODES
#index106178
#%131782
#%79274
#%282381
#%1056494
#!We address software optimization for embedded control systems. The Esterel language is used as the front-end specification; Esterel compiler v6 is used to partition the control circuit and data path; the resulting intermediate representation of the design is a control-data network. This paper emphasizes the optimization of the control circuit portion and the code generation of the logic network. The new control-data network representation has four types of nodes: control, multiplexer, predicate and data expression; the control portion is a multi-valued logic network (MV-network). We use an effective multi-valued logic network optimization package called MVSIS for the control optimization. It includes algebraic methods to perform multi-valued algebraic division, factorization and decomposition and logic simplification methods based on observability don't cares. We have developed methods to evaluate a control-data network based on both an MDD and sum-of-products representation of the multi-valued logic functions. The MDD-based approach uses multi-valued intermediate variables and generates code according to the internal BDD structure. The SOP-based code is proportional to the number of cubes in the logic network. Preliminary results compare the two approaches and the optimization effectiveness.

#*Performance and power analysis of computer systems.
#@Trevor N. Mudge
#t2005
#cCODES+ISSS
#index106179
#!This tutorial will present an overview of techniques for architectural-level performance and power analysis of computer systems. It starts with a discussion of metrics for both performance and power, followed by an overview of some widely used benchmarks including SPEC, Mediabench, and MiBench. It then illustrates the use of these benchmarks with some published performance results. After this initial overview, the tutorial will focus on a discussion of architectural simulators to measure performance and power.Architectural simulators model systems on a (clock) cycle-by-cycle basis. Their operation will be illustrated with two popular examples: SimpleScalar and M5. Besides performance analysis, these simulators can be extended to include power estimation. Full simulations of complete applications can be extremely time consuming. The tutorial will explain how sampling techniques can be used to reduce simulation time. Finally, it will conclude with a discussion on the accuracy that can be expected from architectural simulators.

#*An automated exploration framework for FPGA-based soft multiprocessor systems.
#@Yujia Jin,Nadathur Satish,Kaushik Ravindran,Kurt Keutzer
#t2005
#cCODES+ISSS
#index106180
#%132154
#!FPGA-based soft multiprocessors are viable system solutions for high performance applications. They provide a software abstraction to enable quick implementations on the FPGA. The multiprocessor can be customized for a target application to achieve high performance. Modern FPGAs provide the capacity to build a variety of micro-architectures composed of 20-50 processors, complex memory hierarchies, heterogeneous interconnection schemes and custom co-processors for performance critical operations. However, the diversity in the architectural design space makes it difficult to realize the performance potential of these systems. In this paper we develop an exploration framework to build efficient FPGA multiprocessors for a target application. Our main contribution is a tool based on Integer Linear Programming to explore micro-architectures and allocate application tasks to maximize throughput. Using this tool, we implement a soft multiprocessor for IPv4 packet forwarding that achieves a throughput of 2 Gbps, surpassing the performance of a carefully tuned hand design.

#*Organic computing: on the feasibility of controlled emergence.
#@Christian Müller-Schloer
#t2004
#cCODES+ISSS
#index106181
#!This paper gives an introduction to the new research area of Organic Computing and shows chances, opportunities and problems currently tackled by researchers. First the visions that lead to this new research area are discussed briefly. It is shown that the notion of emergence, a central phenomenon in Organic Compting, is a typical bottom-up effect with the interesting property of generating order from randomness. The classical design, however, is a top-down process. This apparent contradiction can be overcome by introducing so-called Observer/Controller architectures leading to the possibility to controlled emergence. The paper concludes with a description of current research problems in Organic Computing.

#*Future processors: flexible and modular.
#@Charlie Johnson,Jeff Welser
#t2005
#cCODES+ISSS
#index106182
#%418920
#!The ability to continue increasing processor frequency and single thread performance is being severely limited by exponential increases in leakage and active power. To continue to improve system performance, future designs will rely on increasing numbers of smaller, more power efficient cores and special purpose accelerators integrated on a chip. In this paper, we describe how these trends are leading to more modular, SoC-like designs for future processor chips, which can still achieve very high throughput performance while using simplified components and a cost efficient design methodology.

#*The challenges of embedded system design.
#@Mike Muller
#t2005
#cCODES+ISSS
#index106183

#*Hardware synthesis from coarse-grained dataflow specification for fast HW/SW cosynthesis.
#@Hyunuk Jung,Soonhoi Ha
#t2004
#cCODES+ISSS
#index106184
#!This paper concerns automatic hardware synthesis from data flow graph (DFG) specification for fast HW/SW cosynthesis. A node in DFG represents a coarse grain block such as FIR and DCT and a port in a block may consume multiple data samples per invocation, which distinguishes our approach from behavioral synthesis and complicates the problem. In the presented design methodology, a dataflow graph with specified algorithm can be mapped to various hardware structures according to the resource allocation and schedule information. This simplifies the management of the area/performance tradeoff in hardware design and widens the design space of hardware implementation of a dataflow graph compared with the previous approaches. Through experiments with some examples, the usefulness of the proposed technique is demonstrated.

#*Current flattening in software and hardware for security applications.
#@Radu Muresan,Catherine H. Gebotys
#t2004
#cCODES+ISSS
#index106185
#!This paper presents a new current flattening technique applicable in software and hardware. This technique is important in embedded cryptosystems since power analysis attacks (that make use of the current variation dependency on data and program) compromise the security of the system. The technique flattens the current internally by exploiting current consumption differences at the instruction level. Code transformations supporting current variation reductions due to program dependencies are presented. Also, a new real-time hardware architecture capable of reducing the current to data and program dependencies is proposed. Measured and simulated current waveforms of cryptographic software are presented in support of these techniques.

#*Locality-conscious process scheduling in embedded systems.
#@Ismail Kadayif,Mahmut T. Kandemir,Ibrahim Kolcu,Guangyu Chen
#t2002
#cCODES
#index106186
#%858040
#%116
#!In many embedded systems, existence of a data cache might influence the effectiveness of process scheduling policy significantly. Consequently, a scheduling policy that takes inter-process data reuse into account might result in large performance benefits. In this paper, we focus on array-intensive embedded applications and present a locality-conscious scheduling strategy where we first evaluate the potential data reuse between processes, and then, using the results of this evaluation, select an order for process executions. We also show how process codes can be transformed by an optimizing compiler for increasing inter-process data reuse, thereby making locality-conscious scheduling more effective. Our experimental results obtained using two large, multi-process application codes indicate significant runtime benefits.

#*Power-smart system-on-chip architecture for embedded cryptosystems.
#@Radu Muresan,Haleh Vahedi,Y. Zhanrong,Stefano Gregori
#t2005
#cCODES+ISSS
#index106187
#%87045
#%86971
#%19209
#%1098650
#%646055
#%106185
#%1135567
#!In embedded cryptosystems, sensitive information can leak via timing, power, and electromagnetic channels. We introduce a novel power-smart system-on-chip architecture that provides support for masking these channels by controlling, in real-time, the power and the current consumption of a system to predefined programmable values. The main components of the architecture are a processor core, a current sensor module, a dynamically controlled power supply module, a clock frequency control module, and a current injection module. Real-time current measurements and power-aware voltage control are used in closed loop architecture to regulate and minimize the total power consumption of the system. Simulation results show that the current consumption of the system can be regulated to a reference level with reduced power-to-security trade off (power overhead less than 12% of the total power).

#*A global criticality/local phase driven algorithm for the constrained hardware/software partitioning problem.
#@Asawaree Kalavade,Edward A. Lee
#t1994
#cCODES
#index106188
#%1166086
#%132601
#%1125767
#%858422
#%858145
#%134133
#!An algorithm for the constrained hardware/software partitioning (assignment and scheduling) problem is presented. The key feature of the algorithm is the adaptive objective mechanism governed by the combination of global and local measures. As hardware area minimization and latency constraints present contradictory objectives, a global time-criticality (GC) measure selects an objective function in accordance with feasibility. In addition to global consideration, local characteristics of the nodes are emphasized by classifying nodes into local phase (LP) types. A local phase 1 node (extremity) has an obvious preference for an implementation on the basis of its arealtime requirements. A local phase 2 node (repeller) is a repeller to an implementation on the basis of relative preferences of other nodes. At each iteration, the global and local criteria are superimposed by a thresh-old mechanism so as to determine the best implementation. The algorithm has quadratic complexity in the number of nodes and has shown promising behavior on the examples tested.

#*System canvas: a new design environment for embedded DSP and telecommunication systems.
#@Praveen K. Murthy,Etan G. Cohen,Steve Rowland
#t2001
#cCODES
#index106189
#%106090
#%132955
#%1127352
#%739359
#%1056494
#!We present a new design environment, called System Canvas, targeted at DSP and telecommunication system designs. Our environment uses an easy-to-use block-diagram syntax to specify systems at a very high level of abstraction. The block diagram syntax is based on formal semantics, and uses a number of different models of computation including cyclo-static dataflow, dynamic dataflow, and a discrete-event model. A key feature of our tool is that the user does not need to have an awareness of which model is being used; the models can be freely mixed and matched and a simulation can consist of an arbitrary combination of models. The blocks are written in `C'or `C++' and it is straightforward to write custom blocks and incorporate them into custom libraries. Other key features include the ability to control simulations via language-neutral scripts, and a powerful optimization engine that enables optimization of the system over arbitrarily specified parameters, constraints, and cost functions. Fixed-point analysis capability allows any signal or variable in the system to be set to any type of number system before the simulation proceeds. The tool is available on the Windows NT platform and incorporates modern and ubiquitous Windows GUI look and feel.

#*Energy conscious online architecture adaptation for varying latency constraints in sensor network applications.
#@Sankalp Kallakuri,Alex Doboli
#t2005
#cCODES+ISSS
#index106190
#%283199
#%133988
#%505709
#%142430
#%142543
#%142231
#!Sensor network applications face continuously changing environments, which impose varying processing loads on the sensor node. This paper presents an online control method which adapts the architecture to minimize energy consumption while satisfying varying latency constraints. The method predicts processing load requirements over a finite time window and accordingly adapts the architecture. The behaviour of the hardware modules over time has been approximated with a Continuous Time Markov Process. Adaptive image processing for vehicle tracking was used as a case study for this approach.

#*Simulation bridge: a framework for multi-processor simulation.
#@G. D. Nagendra,V. G. Prem Kumar,B. S. Sheshadri Chakravarthy
#t2002
#cCODES
#index106191
#%489565
#%773608
#!Multi-processor solutions in the embedded world are being designed to meet the ever increasing computational demands of the emerging applications. Such architectures comprise two or more processors (often a mix of general purpose and digital signal processors) together with a rich peripheral mix to provide a high performance computational platform. While there are many simulation solutions in the industry available to address the system partitionaing issues and also the verification of HW-SW interactions in these complex systems, there are very few solutions targetted towards the SW application developers' needs.The primary concern of the SW application developers is to debug and optimize their code. Hence, cycle accuracy and performance of the simulation solution becomes the key enablers. Desired observability and controllability of the models are additional careabouts. Secondly, application devlopers are more comfortable at instruction level simulations than they are with RTL or gate level simulation. These specific requirements have a bearing on the choices in the simulation solutions.This paper describes the design of a generic, C based multi-processor instruction set simulator framework in the context of the above parameters. This framework, termed the "simulation bridge", facilitates highly accurate, yet efficient simulation. The SimBridge performs clock correct lock-step simulation of the models in the architecture using a global simulation engine that handles both intra-processor and inter-processor communication in a homogenous fashion. It addresses the multiple key issues of execution control, synchronization, connectivity and communication.The paper concludes with the performance analysis of the SimBridge in an experimental test setup as well as in the Texas Instruments (TI) TMS320C54x-based simulators.

#*Compiler-directed selection of dynamic memory layouts.
#@Mahmut T. Kandemir,Ismail Kadayif
#t2001
#cCODES
#index106192
#%542505
#%116
#%542461
#%1123732
#%499235
#%567592
#%9792
#!Compiler technology is becoming a key component in the design of embedded systems, mostly due to increasing participation of software in the design process. Meeting system-level objectives usually requires flexible and retargetable compiler optimizations that can be ported across a wide variety of architectures. In particular, source-level compiler optimizations aiming at increasing locality of data accesses are expected to improve the quality of the generated code. Previous compiler-based approaches to improving locality have mainly focused on determining optimal memory layouts that remain in effect for the entire execution of an application. For large embedded codes, however, such static layouts may be insufficient to obtain acceptable performance. The selection of memory layouts that dynamically change over the course of a program's execution adds another dimension to data locality optimization. This paper presents a technique that can be used to automatically determine which layouts are most beneficial over specific regions of a program while taking into account the added overhead of dynamic (run time) layout changes. The results obtained using two benchmark codes show that such a dynamic approah brings significant benefits over a static state-of-the-art technique.

#*Accurate estimation of cache-related preemption delay.
#@Hemendra Singh Negi,Tulika Mitra,Abhik Roychoudhury
#t2003
#cCODES+ISSS
#index106193
#%132939
#%106322
#%1128731
#%77531
#%134303
#%282537
#%1078390
#!Multitasked real-time systems often employ caches to boost performance. However the unpredictable dynamic behavior of caches makes schedulability analysis of such systems difficult. In particular, the effect of caches needs to be considered for estimating the inter-task interference. As the memory blocks of different tasks can map to the same cache blocks, preemption of a task may introduce additional cache misses. The time penalty introduced by these misses is called the Cache-Related Preemption Delay (CRPD).In this paper, we provide a program path analysis technique to estimate CRPD. Our technique performs path analysis of both the preempted and the preempting tasks. Furthermore, we improve the accuracy of the analysis by estimating the possible states of the entire cache at each possible preemption point rather than estimating the states of each cache block independently. To avoid incurring high space requirements, the cache states can be maintained symbolically as a Binary Decision Diagram. Experimental results indicate that we obtain tight CRPD estimates for realistic benchmarks.

#*Compiler-directed code restructuring for reducing data TLB energy.
#@Mahmut T. Kandemir,Ismail Kadayif,Guilin Chen
#t2004
#cCODES+ISSS
#index106194
#!Prior work on TLB power optimization considered circuit and architectural techniques. A recent software-based technique for data TLBs has considered the possibility of storing the frequently used virtual-to-physical address translations in a set of translation registers (TRs), and using them when necessary instead of going to the data TLB. This paper presents a compiler-based strategy for increasing the effectiveness of TRs. The idea is to restructure the application code in such a fashion that once a TR is loaded, its contents are reused as much as possible. Our experimental evaluation with six array-based benchmarks from the Spec2000 suite indicates that the proposed TR reuse strategy brings significant reductions in data TLB energy over an alternate strategy that employs TRs but does not restructure the code for TR reuse

#*Reducing power and latency in 2-D mesh NoCs using globally pseudochronous locally synchronous clocking.
#@Erland Nilsson,Johnny Öberg
#t2004
#cCODES+ISSS
#index106195
#!One of the main problems when designing large ASICs today is to distribute a low power synchronous clock over the whole chip and a lot of remedies to this problem has been proposed over the years. For Networks-on-Chip (NoC), where computational Resources are organised in a 2-D mesh connected together through Switches in an on-chip interconnection network, another possibility exists: Globally Pseudochronous Locally Synchronous clock distribution. In this paper, we present a clocking scheme for NoCs that we call Globally Pseudochronous Locally Synchronous, in which we distribute a clock with a constant phase difference between the switches. As a consequence of the phase difference, some paths along the NoC switch network become faster than the others. We call these paths Data Motorways. By adapting the switching policy in the switches to prefer data to use the motorways, we show that the latency within the network is reduced with up to 40% compared to a synchronous reference case. The phase difference between the resources also makes the circuit more tolerant to clock skew. It also distributes the current peaks more evenly across the clock period, which lead to a reduction in peak power, which in turn further reduces the clock skew and the jitter in the clock network.

#*Designing digital video systems: modeling and scheduling.
#@H. J. H. N. Kenter,Claudio Passerone,W. J. M. Smits,Yosinori Watanabe,Alberto L. Sangiovanni-Vincentelli
#t1999
#cCODES
#index106196
#%50123
#%106086

#*Scheduling-based code size reduction in processors with indirect addressing mode.
#@Sungtaek Lim,Jihong Kim,Kiyoung Choi
#t2001
#cCODES
#index106197
#%282669
#%542720
#%2346
#%1073474
#!DSPs are typically equipped with indirect addressing modes with auto-increment and auto-decrement, which provide efficient address arithmetic calculations. Such an addressing mode is maximally utilized by careful placement of variables in storage, thereby reducing the amount of address arithmetic instructions. Finding proper placement of variables in storage is called storage assignment problem and the result highly depends on the access sequence of variables. This paper suggests statement scheduling as a compiler optimization step to generate a better access sequence. Experimental results show 3.6% improvement on the average over naive storage assignment.

#*An architectural level design methodology for embedded face detection.
#@Vida Kianzad,Sankalita Saha,Jason Schlessman,Gaurav Aggarwal,Shuvra S. Bhattacharyya,Wayne Wolf,Rama Chellappa
#t2005
#cCODES+ISSS
#index106198
#%483756
#%1033393
#%646163
#!Face detection and recognition research has attracted great attention in recent years. Automatic face detection has great potential in a large array of application areas, including banking and security system access control, video surveillance, and multimedia information retrieval. In this paper, we discuss an architectural level design methodology for implementation of an embedded face detection system on a reconfigurable system on chip. We present models for performance estimation and validate these models with experimental values obtained from implementing our system on an FPGA platform. This modeling approach is shown to be efficient, accurate, and intuitive for designers to work with. Using this approach, we present several design options that trade-off various architectural features.

#*Complexity challenges towards 4th generation communication solutions.
#@Hermann Eul
#t2007
#cCODES+ISSS
#index106199
#!The market for cellular phones is with more than 1 billion units one of the most exciting and at the same time technically challenging markets for embedded systems. As it develops from a strongly technology and network centric into a consumer centric environment some of the existing paradigms for the design of the respective embedded systems need to be revisited. Examples are the split between hardware and software, the partitioning between RF, mixed signal and digital architectures and devices. There are some already visible changes in the consumer behaviour that drive such changes like the so-called "Web 2.0", new types of content or new business models like flat rate tariffs. The evolution of communication technologies towards 4th generation mobile devices result in a strong increase of data rates, convergence of services in fixed and mobile communication networks and the increased expectation of service quality and service continuity. While convergence, not only of data and voice, fixed and mobile but also of device types (multimedia, music, internet etc.) is a general trend that can be observed and that lends to ever higher levels of integration into the embedded system, there is also a need for device manufacturers and OEMs to differentiate and a trend for fragmentation in the market where ultra low cost mass market devices, fashion consumer devices with some dedicated feature themes and high end fully integrated devices co-exist. The challenges that arise from this environment for the embedded system architect are on the one side rooted in the complexity of technologies and features employed in future products but also in the nature of embedded systems, namely strong cost, resource and power constraints. One of the consequences of the increasing complexity of subsystems to be integrated into the overall product is the verification complexity, because the combination of even pre-integrated subsystems generates dependencies on embedded architectures that require tremendous efforts at late stages of the development process. A further aspect that drives future system architecture decision is the span of possible and required innovation cycles in different areas of a mobile consumer device. This may lead to different, sometimes segment specific partitioning decisions. Progress of basic technologies like semiconductor manufacturing processes, package technologies but also SW technologies, however, also allow for new opportunities to master these challenges. One example are new CMOS radio frequency architectures that allow to effectively integrate digital signal processing and RF circuit technology and so can result in a partitioning between RF and baseband with an interface in between that abstracts from hard RF processing and timing aspects and thus shields the RF engine and takes complexity away from the baseband development. More generally a unification of subsystem interfaces and definition of suitable abstractions across product families can lead to significantly reduced verification efforts. To decouple the development and innovation processes of the hardware, system and end-product design higher use of software instead of dedicated hardware are used, which in turn require suitable SW architecture and development concepts. One of the major architectural approaches both in the user application and the modem systems can be multiprocessor architectures. For these effective programming and SW verification and maintenance solutions that hold up to a competitive industry environment will be required. Amongst other research challenges we see the effective modelling (and verification) of heterogeneous embedded systems a very important one. This should give early feedback about essential criteria like cost and power and allows for a predictable integration of legacy (or COTS) system components.

#*Dynamic run-time HW/SW scheduling techniques for reconfigurable architectures.
#@Juanjo Noguera,Rosa M. Badia
#t2002
#cCODES
#index106200
#%857832
#%215073
#%282058
#%106020
#%214452
#%52425
#%132600
#%142444
#%142648
#%1081422
#%143289
#!Dynamic run-time scheduling in System-on-Chip platforms has become recently an active area of research because of the performance and power requirements of new applications. Moreover, dynamically reconfigurable logic (DRL) architectures are an exciting alternative for embedded systems design. However, all previous approaches to DRL multi-context scheduling and HW/SW scheduling for DRL architectures are based on static scheduling techniques. In this paper, we address this problem and present: (1) a dynamic scheduler hardware architecture, and (2) four dynamic run-time scheduling algorithms for DRL-based multi-context platforms. The scheduling algorithms have been integrated in our codesign environment, where a large number of experiments have been carried out. Results demonstrate the benefits of our approach.

#*The construction of a retargetable simulator for an architecture template.
#@Bart Kienhuis,Ed F. Deprettere,Kees A. Vissers,Pieter van der Wolf
#t1998
#cCODES
#index106201
#%50123
#%143910
#%807025
#%360223
#%1166185
#%131508


#*Power-performance trade-offs for reconfigurable computing.
#@Juanjo Noguera,Rosa M. Badia
#t2004
#cCODES+ISSS
#index106202
#!In this paper, we explore the system-level power-performance trade-offs available when implementing streaming embedded applications on fine-grained reconfigurable architectures. We show that an efficient hardware-software partitioning algorithm is required when targeting low-power. However, if the application objective is performance, then we propose the use of dynamically reconfigurable architectures. This work presents a configuration-aware data size partitioning approach. We propose a design methodology that adapts the architecture and used algorithms to the application requirements. The methodology has been proven to work on a real research platform based on Xilinx devices. Finally, we have applied our methodology and algorithms to the case study of image sharpening, which is required nowadays in digital cameras and mobile phones.

#*Compaan: deriving process networks from Matlab for embedded signal processing architectures.
#@Bart Kienhuis,Edwin Rijpkema,Ed F. Deprettere
#t2000
#cCODES
#index106203
#%50224
#%143910
#%49957
#%106201
#!This paper presents the Compaan tool that automatically transforms a nested loop program written in Matlab into a process network specification. The process network model of computation fits better with the new emerging kind of embedded architectures that use coprocessors. Process networks can describe both fine-grained and coarse-grained parallelism, making the mapping of the applications easier.

#*Key research problems in NoC design: a holistic perspective.
#@Ümit Y. Ogras,Jingcao Hu,Radu Marculescu
#t2005
#cCODES+ISSS
#index106204
#%360652
#%282627
#%805785
#%1134547
#%141515
#%142669
#%141808
#%286159
#%143299
#%131914
#%418812
#%282307
#%645213
#%142588
#%142153
#%133273
#%286698
#%131304
#%141646
#%141428
#%1134646
#%990953
#%142537
#!Networks-on-Chip (NoCs) have been recently proposed as a promising solution to complex on-chip communication problems. The lack of an unified representation of applications and architectures makes NoC problem formulation and classification both difficult and obscure. To remedy this situation, we provide a general description for NoC architectures and applications and then enumerate several outstanding research problems (denoted by P1-P8) organized under three topics: communication infrastructure synthesis, communication paradigm selection, and application mapping optimization. Far from being exhaustive, the discussed problems are deemed essential for future NoC research.

#*Schedule-aware performance estimation of communication architecture for efficient design space exploration.
#@Sungchan Kim,Chaeseok Im,Soonhoi Ha
#t2003
#cCODES+ISSS
#index106205
#%282565
#%1063860
#%283380
#%450524
#%106218
#%133707
#%450514
#!In this paper, we are concerned about the performance estimation of bus-based architectures assuming that the task partitioning on the processing components is already determined. Since the communication behavior is usually unpredictable due to dynamic bus requests of processing components, bus contention, and so on, simulation based approach seems inevitable for accurate performance estimation. But it is too time consuming to explore the wide design space. To overcome this serious drawback, we propose a static performance estimation method that is based on the queuing model and makes use of memory traces and task execution schedule information. We propose to use this static estimation approach to prune the design space drastically before applying a simulation-based approach. Comparison with trace-driven simulation results proves the validity of our static estimation technique.

#*Shift buffering technique for automatic code synthesis from synchronous dataflow graphs.
#@Hyunok Oh,Nikil D. Dutt,Soonhoi Ha
#t2005
#cCODES+ISSS
#index106206
#!This paper proposes a new efficient buffer management technique called shift buffering for automatic code synthesis from synchronous dataflow graphs (SDF). Two previous buffer management methods, linear buffering and modulo (or circular) buffering, assume that samples are queued in the arc buffers in the arrival order and are accessed by moving the buffer indices. But both methods have significant overhead for general multi-rate systems: the linear buffering method requires large size buffers and the modulo buffering method needs run-time overhead of buffer index computation. The proposed shift buffering method shifts samples rather than moving buffer indices. We develop optimal shift buffering algorithms to minimize the number of shifted samples. Our experimental results show that the proposed algorithm saves up to 90% of performance overhead while requiring the same amount of buffer memory as modulo buffering. Considering the sample copy overhead, shift buffering is applicable when memory size is more crucial than performance overhead, and the shifting overhead is less than the modulo addressing overhead. Another advantage of the shift buffering technique is that it supports the library code written with the linear buffering assumption, which is practically more important.

#*Efficient exploration of on-chip bus architectures and memory allocation.
#@Sungchan Kim,Chaeseok Im,Soonhoi Ha
#t2004
#cCODES+ISSS
#index106207
#!Separation between computation and communication in system design allows the system designer to explore the communication architecture independently of component selection and mapping. In this paper we present an iterative two-step exploration methodology for bus-based on-chip communication architecture and memory allocation, assuming that memory traces from the processing elements are given from the mapping stage. The proposed method uses a static performance estimation technique to reduce the large design space drastically and quickly, and applies a trace-driven simulation technique to the reduced set of design candidates for accurate performance estimation. Since local memory traffic as well as shared memory traffic are involved in bus contention, memory allocation is considered as an important axis of the design space in our technique. The viability and efficiency of the proposed methodology are validated by two real-life examples, 4-channel digital video recorder (DVR) and an equalizer for OFDM DVB-T receiver.

#*FlexPath NP: a network processor concept with application-driven flexible processing paths.
#@Rainer Ohlendorf,Andreas Herkersdorf,Thomas Wild
#t2005
#cCODES+ISSS
#index106208
#%890182
#%807088
#%77459
#!In this paper, we present a new architectural concept for network processors called FlexPath NP. The central idea behind FlexPath NP is to systematically map network processor (NP) application sub-functions onto both SW programmable processor (CPU) resources and (re-)configurable HW building blocks, such that different packet flows are forwarded via different, optimized processing paths through the NP. Packets with well understood, relatively simple processing requirements may even bypass the central CPU complex (AutoRoute). In consequence, CPU processing resources are more effectively used and the overall NP performance and throughput are improved compared to conventional NP architectures. We present analytical performance estimations to quantify the performance advantage of FlexPath (expressed as available CPU instructions for each packet traversing the CPUs) and introduce a platform-based System on Programmable Chip (SoPC) based architecture which implements the FlexPath NP concept.

#*Designing real-time H.264 decoders with dataflow architectures.
#@Youngsoo Kim,Suleyman Sair
#t2005
#cCODES+ISSS
#index106209
#%142796
#%498979
#%282933
#%142513
#%133700
#!High performance microprocessors are designed with general-purpose applications in mind. When it comes to embedded applications, these architectures typically perform control-intensive tasks in a System-on-Chip (SoC) design. But they are significantly inefficient for data-intensive tasks such as video encoding/decoding. Although configurable processors fill this gap by complementing the existing functional units with instruction extensions, their performance lags behind the needs of real-time embedded tasks. In this paper, we evaluate the performance potential of a dataflow processor for H.264 video decoding. We first profile the H.264 application to capture the amount of data traffic among modules. We use this information to guide the placement of H.264 modules in the WaveScalar dataflow architecture. A simulated annealing based placement algorithm produces the final placement aiming to optimize the communication costs between the modules in the dataflow architecture. In addition to outperforming contemporary embedded and customized processors, our simulated annealing guided design shows a speedup of 13% in execution time over the original WaveScalar architecture. With our dataflow design methodology, emerging embedded applications requiring several GOPS to meet real-time constraints can be drafted within a reasonable amount of design time.

#*Empirical comparison of software-based error detection and correction techniques for embedded systems.
#@Royan H. L. Ong,Michael J. Pont
#t2001
#cCODES
#index106210
#!&ldquo;Function Tokens&rdquo; and &ldquo;NOP Fills&rdquo; are two methods proposed by various authors to deal with Instruction Pointer corruption in microcontrollers, especially in the presence of high electromagnetic interference levels. An empirical analysis to assess and compare these two techniques is presented in this paper. Two main conclusions are drawn: [1] NOP Fills are a powerful technique for improving the reliability of embedded applications in the presence of EMI, and [2] the use of Function Tokens can lead to a reduction in overall system reliability.

#*A Hardware/Software Codesign Method for a General Purpose Reconfigurable Co-Processor.
#@Shinji Kimura,Yasufumi Itou,Makoto Hirao,Katsumasa Watanabe,Mitsuteru Yukishita,Akira Nagoya
#t1997
#cCODES
#index106211
#%283215
#%806531
#%805564
#%858582
#!This paper shows a hardware/software codesign method for a computer system with a reconfigurable co-processor. The reconfigurable co-processor is constructed from FPGA's, internal cache and a control part, and is connected to the system bus of the computer system. This paper shows the architecture of the reconfigurable co-processor, a hardware/software separation method and a co-operation method via the DMA based memory sharing. We also show co-operation examples and the effectiveness of our approach for the fast execution of user processes.

#*Intra- and inter-processor hybrid performance modeling for MPSoC architectures.
#@Frank E. B. Ophelders,Samarjit Chakraborty,Henk Corporaal
#t2008
#cCODES+ISSS
#index106212
#%807927
#%1135494
#%106260
#%142866
#%857832
#%596927
#%141631
#%565633
#%25055
#%588749
#%143619
#%1275423
#%564111
#!The heterogeneity of modern MPSoC architectures, coupled with the increasing complexity of the applications mapped onto them has recently led to a lot of interest in hybrid performance modeling techniques. Here, the idea is to apply different modeling and analysis techniques to different subsystems/components of an architecture/application. Such hybrid techniques often turn out to be more efficient and accurate compared to relying on a single analysis technique for the entire system. However, the challenge associated with this approach is to combine the different analysis results effectively to obtain conservative performance estimates for the entire system. In this paper we study a hybrid scheme where certain system components are simulated (e.g. using instruction set simulators), whereas others are analyzed using a formal technique called Real-Time Calculus (RTC). The main novelty of our approach stems from our use of this hybrid technique even for multiple tasks mapped onto a single processing element. In contrast to this, previous approaches relied on either full simulation or RTC-based analysis for an entire architectural component (e.g. a processor or a bus). The techniques we develop in this paper therefore allow for both intra- and inter-processor hybrid performance modeling and show how the different analysis results can be combined to efficiently obtain tight performance estimates for complex MPSoC architectures. We demonstrate the usefulness of this approach using an MPEG-2 decoder application that is partitioned and mapped onto two processing elements connected by FIFO buffers.

#*Distributed and low-power synchronization architecture for embedded multiprocessors.
#@Chenjie Yu,Peter Petrov
#t2008
#cCODES+ISSS
#index106213
#%141384
#%77719
#%77468
#%77668
#%252868
#%234418
#%141382
#%499311
#%1008306
#!In this paper we present a framework for a distributed and very low-cost implementation of synchronization controllers and protocols for embedded multiprocessors. The proposed architecture effectively implements the queued-lock semantics in a completely distributed way. The proposed approach to synchronization implementation not only completely eliminates the overwhelming bus contention traffic when multiple cores compete for a synchronization variable, but also achieves very high energy efficiency as the local synchronization controller can efficiently determine, without any bus transactions or local cache spinning, the exact timing of when the lock is made available to the local processor. Application-specific information regarding synchronization variables in the local task is exploited in implementing the distributed synchronization protocol. The local synchronization controllers enable the system software or the thread library to implement various low-power policies, such as disabling the cache accesses or even completely powering down the local processor while waiting for a synchronization variable.

#*Storage requirement estimation for data intensive applications with partially fixed execution ordering.
#@Per Gunnar Kjeldsberg,Francky Catthoor,Einar J. Aas
#t2000
#cCODES
#index106214
#%134482
#%1135020
#%105980
#%132822
#%134162
#!In this paper, we propose a novel storage requirement estimation methodology for use in the early system design phases when the data transfer ordering is only partly fixed. At that stage, none of the existing estimation tools are adequate, as they either assume a fully specified execution order or ignore it completely. Using a representative application demonstrator, we show how our technique can effectively guide the designer to achieve a transformed specification with low storage requirement.

#*A study of CodePack: optimizing embedded code space.
#@Avishay Orpaz,Shlomo Weiss
#t2002
#cCODES
#index106215
#%146496
#%1501640
#%805863
#%771849
#%1074275
#%542562
#%499295
#%499520
#%1117838
#%1135330
#%499323
#!CodePack is a code compression system used by IBM in its PowerPC family of embedded processors. CodePack combines high compression capability along with fast and simple decoding hardware. IBM did not release much information about the design of the system and the influence of various design parameters on its performance. In our work we will present the system and its design parameters and investigate how each affects its performance on the compression rate and decoder complexity. We also present a novel efficient algorithm to optimize the class structure of the system.

#*PACE: A Dynamic Programming Algorithm for Hardware/Software Partitioning.
#@Peter Voigt Knudsen,Jan Madsen
#t1996
#cCODES
#index106216
#%858044
#%106135
#%193943
#%106188
#%193972
#!This paper presents the PACE partitioning algorithm which is used in the LYCOS co-synthesis system for partitioning control/dataflow graphs into hardware- and software parts. The algorithm is a dynamic programming algorithm which solves both the problem of minimizing system execution time with a hardware area constraint and the problem of minimizing hardware area with a system execution time constraint. The target architecture consists of a single microprocessor and a single hardware chip (ASIC, FPGA, etc.) which are connected by a communication channel. The algorithm incorporates a realistic communication model and thus attempts to minimize communication overhead. The time-complexity of the algorithm is O(n x n x A) and the space-complexity is O(n x A) where A is the total area of the hardware chip and n the number of code fragments which may be placed in either hardware or software.

#*Communication Synthesis for Embedded Systems with Global Considerations.
#@Ross B. Ortega,Gaetano Borriello
#t1997
#cCODES
#index106217
#%281937
#%281938
#%283380
#!Designers of distributed embedded systems require communication synthesis to more effectively explore the design space. Communication synthesis creates or instantiates the necessary software and hardware required to allow system components to exchange data. This work examines the problem of mapping a high-level specification to an arbitrary, but fixed architecture that uses particular bus protocols for interprocessor communication. The approach detailed in this paper illustrates that global considerations are necessary to achieve a correct implementation. A communication model is presented that allows for easy retargeting to different bus topologies and protocols. The effectiveness of this approach is demonstrated by mapping a high-level specification to different architectures.

#*Communication estimation for hardware/software codesign.
#@Peter Voigt Knudsen,Jan Madsen
#t1998
#cCODES
#index106218
#%450692
#%450647
#%133368

#*Increasing on-chip memory space utilization for embedded chip multiprocessors through data compression.
#@Ozcan Ozturk,Mahmut T. Kandemir,Mary Jane Irwin
#t2005
#cCODES+ISSS
#index106219
#%144052
#%1080211
#%297827
#%141311
#%116
#%132191
#%450593
#%142438
#%132610
#%53705
#%133429
#!Minimizing the number of off-chip memory references is very important in chip multiprocessors from both the performance and power perspectives. To achieve this the distance between successive reuses of the same data block must be reduced. However, this may not be possible in many cases due to data dependences between computations assigned to different processors. This paper focuses on software-managed on-chip memory space utilization for embedded chip multiprocessors and proposes a compression-based approach to reduce the memory space occupied by data blocks with large inter-processor reuse distances. The proposed approach has two major components: a compiler and an ILP (integer linear programming) solver. The compiler's job is to analyze the application code and extract information on data access patterns. This access pattern information is then passed to our ILP solver, which determines the data blocks to compress/decompress and the times (the program points) at which to compress/decompress them. We tested the effectiveness of this ILP based approach using access patterns extracted by our compiler from application codes. Our experimental results reveal that the proposed approach is very effective in reducing power consumption. Moreover, it leads to a lower energy consumption than an alternate scheme evaluated in our experiments for all the test cases studied.

#*Graph based communication analysis for hardware/software codesign.
#@Peter Voigt Knudsen,Jan Madsen
#t1999
#cCODES
#index106220
#%132358
#%450524
#%450687

#*Multi-objective design space exploration using genetic algorithms.
#@Maurizio Palesi,Tony Givargis
#t2002
#cCODES
#index106221
#%499007
#%142061
#%282164
#%1008391
#%77503
#%133920
#%1135015
#!In this work, we provide a technique for efficiently exploring a parameterized system-on-a-chip (SoC) architecture to find all Pareto-optimal configurations in a multi-objective design space. Globally, our approach uses a parameter dependency model of our target parameterized SoC architecture to extensively prune non-optimal sub-spaces. Locally, our approach applies Genetic Algorithms (GAs) to discover Pareto-optimal configurations within the remaining design points. The computed Pareto-optimal configurations will represent the range of performance (e.g., timing and power) tradeoffs that are obtainable by adjusting parameter values for a fixed application that is mapped on the parameterized SoC architecture. We have successfully applied our technique to explore Pareto-optimal configurations for a number of applications mapped on a parameterized SoC architecture.

#*A prototyping environment for hardware/software codesign in the COBRA project.
#@Gernot Koch,Udo Kebschull,Wolfgang Rosenstiel
#t1994
#cCODES
#index106222
#%858044
#%614078
#!We present a prototyping environment with special benefit for hardware/software codesign which we use as target architecture in the COBRA project. This architecture is very flexible, easy extensible, and provides a high gate complexity. It supports standard processor integration as well as processor emulation.

#*A system-level methodology for fully compensating process variability impact of memory organizations in periodic applications.
#@Antonis Papanikolaou,F. Lobmaier,Hua Wang,Miguel Miranda,Francky Catthoor
#t2005
#cCODES+ISSS
#index106223
#%134180
#%436574
#%805592
#%131503
#%807968
#%807974
#%805900
#%141320
#!Process variability is an emerging problem that is becoming worse with each new technology node. Its impact on the performance and energy of memory organizations is severe and degrades the system-level parametric yield. In this paper we propose a broadly applicable system-level technique that can guarantee parametric yield on the memory organization and which minimizes the energy overhead associated to variability in the conventional design process. It is based on offering configuration capabilities at the memory-level and exploiting them at the system-level. This technique can decrease by up to a factor of 5 the energy overhead that is introduced by state-of-the-art process variability compensation techniques, including statistical timing analysis. In this way we obtain results close to the ideal nominal design again.

#*A modular simulation framework for architectural exploration of on-chip interconnection networks.
#@Tim Kogel,Malte Doerper,Andreas Wieferink,Rainer Leupers,Gerd Ascheid,Heinrich Meyr,Serge Goossens
#t2003
#cCODES+ISSS
#index106224
#%805701
#%141996
#%131624
#%1122127
#%450524
#%133707
#%132380
#%450514
#%858394
#%805785
#%143375
#%142668
#%133849
#%132636
#%141363
#%645445
#%418773
#!Ever increasing complexity and heterogeneity of SoC platforms require diversified on-chip communication schemes beyond the currently omnipresent shared bus architectures. To prevent time consuming design changes late in the design flow, we propose the early exploration of the on-chip communication architecture to meet performance and cost requirements. Based on SystemC 2.0.1 we have defined a modular exploration framework, which is able to capture the effect on performance for different on-chip networks like dedicated point-to-point, shared bus, and crossbar topologies. Monitoring of performance parameters like utilization, latency and throughput drives the mapping of the inter-module traffic to an efficient communication architecture. The effectiveness of our approach is demonstrated by the exemplary design of a high performance Network Processing Unit (NPU), which is compared against a commercial NPU device.

#*A low-cost memory architecture with NAND XIP for mobile embedded systems.
#@Chanik Park,Jaeyu Seo,Sunghwan Bae,Hyojun Kim,Shinhan Kim,Bumsoo Kim
#t2003
#cCODES+ISSS
#index106225
#%418978
#%1128731
#%53602
#%563784
#%252948
#!NAND flash memory has become an indispensable component in mobile embedded systems because of its versatile features such as non-volatility, solid-state reliability, low cost and high density. Even though NAND flash memory is gaining popularity as data storage, it can be also exploited as code memory for XIP (execute-in-place). In this paper, we present a new memory architecture which incorporates NAND flash memory into an existing memory hierarchy for code execution. The usefulness of the proposed approach is demonstrated with real embedded workloads on a real prototyping board.

#*Hardware support for real-time operating systems.
#@Paul Kohout,Brinda Ganesh,Bruce L. Jacob
#t2003
#cCODES+ISSS
#index106226
#%131974
#%77492
#%499311
#%858347
#%2579
#!The growing complexity of embedded applications and pressure on time-to-market has resulted in the increasing use of embedded real-time operating systems. Unfortunately, RTOSes can introduce a significant performance degradation. This paper presents the Real-Time Task Manager (RTM)--a processor extension that minimizes the performance drawbacks associated with RTOSes. The RTM accomplishes this by supporting, in hardware, a few of the common RTOS operations that are performance bottlenecks: task scheduling, time management, and event management. By exploiting the inherent parallelism of these operations, the RTM completes them in constant time, thereby significantly reducing RTOS overhead. It decreases both the processor time used by the RTOS and the maximum response time by an order of magnitude.

#*Fast exploration of bus-based on-chip communication architectures.
#@Sudeep Pasricha,Nikil D. Dutt,Mohamed Ben-Romdhane
#t2004
#cCODES+ISSS
#index106227
#!As a result of improvements in process technology, more and more components are being integrated into a single System-on-Chip (SoC) design. Communication between these components is increasingly dominating critical system paths and frequently becomes the source of performance bottlenecks. It therefore becomes extremely important for designers to explore the communication space early in the design flow. Traditionally, pin-accurate Bus Cycle Accurate (PA-BCA) models were used for exploring the communication space. To speed up simulation, transaction based Bus Cycle Accurate (T-BCA) models have been proposed, which borrow concepts found in the Transaction Level Modeling (TLM) domain. More recently, the Cycle Count Accurate at Transaction Boundaries (CCATB) modeling abstraction was introduced for fast communication space exploration. In this paper, we describe the mechanisms that produce the speedup in CCATB models and demonstrate the effectiveness of the CCATB exploration approach with the aid of a case study involving an AMBA 2.0 based SoC subsystem used in the multimedia application domain. We also analyze how the achieved simulation speedup scales with design complexity and show that SoC designs modeled at the CCATB level simulate 120% faster than PA-BCA and 67% faster than T-BCA models on average.

#*A fast parallel reed-solomon decoder on a reconfigurable architecture.
#@Arezou Koohi,Nader Bagherzadeh,Chengzi Pan
#t2003
#cCODES+ISSS
#index106228
#%499279
#%418427
#%142444
#%77626
#%499427
#%1008827
#%808027
#%142698
#%252943
#!This paper presents a software implementation of a very fast parallel Reed-Solomon decoder on the second generation of MorphoSys reconfigurable computation platform, which is targeting on streamed applications such as multimedia and DSP. Numerous modifications of the first-generation of the architecture have made a scalable computation and communication intensive architecture capable of extracting parallelisms of fine grain in instruction level. Many algorithms and the whole Digital Video Broadcasting base-band receiver as well, have been mapped onto the second architecture with impressing performance. The mapping of a Reed-Solomon decoder proposed in this paper highly parallelizes all of its sub-algorithms, including Syndrome Computation, Berlekamp Algorithm, Chein Search, and Error Value Computation, in a SIMD fashion. The mapping is tested on a cycle-accurate simulator, "Mulate", and the performance is encouragingly better than other architectures. The decoding speed of the RS (255,239,16) decoder using two different methods of GF multiplication can be 1.319Gbps and 2.534Gbps, respectively. Furthermore, since there is no functionality specifically tailored to Reed-Solomon decoder, the result has demonstrated the capability of MorphoSys architecture to extracting Instruction Level Parallelism from streamed applications.

#*Modeling reactive systems in Java.
#@Claudio Passerone,Roberto Passerone,Claudio Sansoè,Jonathan Martin,Alberto L. Sangiovanni-Vincentelli,Rick McGeer
#t1998
#cCODES
#index106229
#%220990

#*Detecting overflow detection.
#@Vladimir Kotlyar,Mayan Moudgill
#t2004
#cCODES+ISSS
#index106230
#!Fixed-point saturating arithmetic is widely used in media and digital signal processing applications. A number of processor architectures provide instructions that implement saturating operations. However, standard high-level languages, such as ANSI C, provide no direct support for saturating arithmetic. Applications written in standard languages have to implement saturating operations in terms of basic twoýs complement operations. In order to provide fast execution of such programs it is important to have an optimizing compiler automatically detect and convert appropriate code fragments to hardware instructions. We present a set of techniques for automatic recognition of saturating arithmetic operations. We show that in most cases the recognition problem is simply one of Boolean circuit equivalence. Given the expense of solving circuit equivalence, we develop a set of practical approximations based on abstract interpretation. Experiments show that our techniques, while reliably recognizing saturating arithmetic, have small compile-time overhead. We also demonstrate that our approach is not limited to saturating arithmetic, but is directly applicable to recognizing other idioms, such as add-with-carry and absolute value.

#*Programmers' views of SoCs.
#@JoAnn M. Paul
#t2003
#cCODES+ISSS
#index106231
#%133444
#%105977
#%142731
#%833088
#%857941
#%805785
#%141599
#%131914
#!System-on-chip (SoC) designs have the potential to change the way we organize computation. This potential has gone unrealized. Future SoCs will have multiple heterogeneous processing elements, most likely organized around an on-chip network. Thus, SoCs are increasingly modeled as systems in the large. But a chip also has a fixed set of programmable hardware elements that are much more closely coupled than for systems in the large. New application types will require the chip to be considered programmable along with the individual processing elements on the chip. New programmers' views of SoCs are required to capture this new design space. A set of primitives for next generation design languages that support the development of new programmers' views of SoCs is motivated.

#*A novel codesign approach based on distributed virtual machines.
#@Christian Kreiner,Christian Steger,Egon Teiniker,Reinhold Weiss
#t2002
#cCODES
#index106232
#%645934
#%106168
#%160981
#!This paper describes a hardware/software codesign approach for the design of embedded systems based on digital signal processors and FPGAs. Our approach is based on distributed virtual machines for simulation and verification of the application on a Linux cluster and for running the application on different target architectures (DSPs, FPGAs) as well. The main focus is the description of the virtual machine, which was designed to make DSP applications portable across different platforms while maintaining optimal code.

#*The design context of concurrent computation systems.
#@JoAnn M. Paul,Christopher M. Eatedali,Donald E. Thomas
#t2002
#cCODES
#index106233
#%142731
#%106321
#%450638
#%106237
#%133010
#%131961
#%833088
#!Design for performance-optimization of programmable, semicustom SoCs requires the ability to model and optimize the behavior of the system as a whole. Neither the hardware-testbench style nor the software-benchmark style is adequate to capture completely the design interactions required in concurrent software-on-hardware systems. We use a formal relationship between a computer system design content and its external context to motivate the need to consider a more effective modeling framework to which concurrent software-on-hardware computer systems are designed.

#*Memory system design space exploration for low-power, real-time speech recognition.
#@Rajeev Krishna,Scott A. Mahlke,Todd M. Austin
#t2004
#cCODES+ISSS
#index106234
#!The recent proliferation of computing technology has generated new interest natural I/O interface technologies such as speech recognition. Unfortunately, the computational and memory demands of such applications currently prohibit their use on low-power portable devices in anything more than their simplest forms. Previous work has demonstrated that the thread level concurrency inherent in this application domain can be used to dramatically improve performance with minimal impact on overall system energy consumption, but that such benefits are severely constrained by memory system bandwidth. This work presents a design space exploration of potential memory system architectures. A range of low-power memory organizations are considered, from conventional caching to more advanced system-on-chip implementations. We find that, given architectures able to exploit concurrency in this domain, large L2 based cache hierarchies and high bandwidth memory systems employing data stream partitioning and on-chip embedded DRAM and ROM technologies can provide much of the performance of idealized memory systems without violating the power constraints of the low-power domain.

#*Embedded Architecture Co-Synthesis and System Integration.
#@Bill Lin,Steven Vercauteren,Hugo De Man
#t1996
#cCODES
#index106235
#%450666
#%858044
#%858146
#%2595
#%106162
#%132730
#%282641
#%1135026

#*The design of a smart imaging core for automotive and consumer applications: a case study.
#@Wido Kruijtzer,Winfried Gehrke,Víctor Reyes,Ghiath Alkadi,Thomas Hinz,Jorn Jöchalsky,Bruno Steux
#t2005
#cCODES+ISSS
#index106236
#%282283
#%858421
#%161033
#%106351
#%106094
#!This paper describes the design of a low-cost, low-power smart imaging core that can be embedded in cameras. The core integrates an ARM 9 processor, a camera interface and two specific hardware blocks for image processing: a smart imaging coprocessor and an enhanced motion estimator. Both coprocessors have been designed using high-level synthesis tools taking the C programming language as a starting point. The resulting RTL code of each coprocessor has been synthesized and verified on an FPGA board. Two automotive and two mobile smart imaging applications are mapped onto the resulting smart imaging core. This mapping process of the original C++ applications onto the smart imaging core is also presented in this paper.

#*Frequency interleaving as a codesign scheduling paradigm.
#@JoAnn M. Paul,Simon N. Peffers,Donald E. Thomas
#t2000
#cCODES
#index106237
#%133439
#%979731
#%106009
#%793964
#%132380
#%833088
#%106320
#!Frequency interleaving is introduced as a means of conceptualizing and co-scheduling hardware and software behaviors so that software models with conceptually unbounded state and execution time are resolved with hardware resources. The novel mechanisms that result in frequency interleaving are a shared memory foundation for all system modeling (from gates to software-intensive subsystems) and de-coupled, but interrelated time- and state-interleaved scheduling domains. The result for system modeling is greater accommodation of software as a configuration paradigm that loads system resources, a greater accommodation of shared memory modeling, and a greater representation of software schedulers as a system architectural abstraction. The results for system co-simulation are a lessening of the dependence on discrete event simulation as a means of merging physical and non-physical models of computation, and a lessening of the need to partition a system as computation and communication too early in the design. We include an example demonstrating its implementation.

#*An ASIP design methodology for embedded systems.
#@Kayhan Küçükçakar
#t1999
#cCODES
#index106238
#%281684
#%282317
#%858220
#%282484

#*Benchmark-based design strategies for single chip heterogeneous multiprocessors.
#@JoAnn M. Paul,Donald E. Thomas,Alex Bobrek
#t2004
#cCODES+ISSS
#index106239
#!Single chip heterogeneous multiprocessors are arising to meet the computational demands of portable and handheld devices. These computing systems are not fully custom designs traditionally targeted by the Design Automation (DA) community, general purpose designs traditionally targeted by the Computer Architecture (CA) community, nor pure embedded designs traditionally targeted by the real-time (RT) community. An entirely new design philosophy will be needed for this hybrid class of computing. The programming of the device will be drawn from a narrower set of applications with execution that persists in the system over a longer period of time than for general purpose programming. But the devices will still be programmable, not only at the level of the individual processing element, but across multiple processing elements and even the entire chip. The design of other programmable single chip computers has enjoyed an era where the design trade-offs could be captured in simulators such as SimpleScaler and performance could be evaluated to the SPEC benchmarks. Motivated by this, we describe new benchmark-based design strategies for single chip heterogeneous multiprocessors. We include an example and results.

#*Highly flexible multi-mode system synthesis.
#@Vinu Vijay Kumar,John Lach
#t2005
#cCODES+ISSS
#index106240
#%132644
#%215080
#%286132
#%132697
#%141617
#%283404
#%132436
#%214259
#%194103
#!Multi-mode systems have emerged as an area- and power-efficient approach to implementing multiple time-wise mutually exclusive algorithms and applications in a single hardware space. These systems have limited flexibility and temporal separation between modes is achieved by changing only the dataflow between components. This paper presents a synthesis methodology for integrating flexible components and controllers into primarily fixed logic multi-mode systems thereby increasing their overall flexibility and efficiency. The components are built using a technique called small-scale reconfigurability that provides the necessary flexibility without the penalties associated with general-purpose reconfigurable logic. The reconfiguration latency is small enabling both inter-mode and intra-mode reconfiguration of components. Datapath and controller area and power consumption are reduced beyond what is provided in current multi-mode systems using this methodology, without sacrificing performance. The results show an average 7% reduction in datapath component area, 26% reduction in register area, 36% reduction in interconnect MUX cost, and a 68% reduction in the number of controller signals for a set of benchmark 32-bit signal processing applications. There is also an average 38% increase in component utilization.

#*Parallel programming models for a multi-processor SoC platform applied to high-speed traffic management.
#@Pierre G. Paulin,Chuck Pilkington,Michel Langevin,Essaid Bensoudane,Gabriela Nicolescu
#t2004
#cCODES+ISSS
#index106241
#!In this paper, we describe the MultiFlex multi-processor SoC programming environment, with focus on two programming models: a distributed system object component (DSOC) message passing model, and a symmetrical multi-processing (SMP) model using shared memory. The MultiFlex tools map these models onto the StepNP multi-processor SoC platform, while making use of harware accelerators for message passing and task scheduling. We present the results of mapping an Internet traffic management application, running at 2.5Gb/s.

#*A Codesign Environment Supporting Hardware/Software Modeling at Different Levels of Detail.
#@Sanjaya Kumar,Fred Rose
#t1997
#cCODES
#index106242
#%106283
#%361968
#%1008314
#%447324
#!Hybrid modeling is a technique that integrates performance and behavioral models within a common simulation. This approach allows behavioral components, containing mixtures of hardware and software, to be evaluated within the context of the system being developed. Hybrid interfaces are required to integrate the behavioral models with the performance models. This paper presents Honeywell's VHDL-based approach to codesign using hybrid modeling. The structure of the hybrid interface is described, and a hybrid interface for a processor model is presented. A four processor Myrinet example is provided to illustrate hardware/software modeling at different levels of detail. We are evaluating our methodology using an internal application.

#*Dynamic phase analysis for cycle-close trace generation.
#@Cristiano Pereira,Jeremy Lau,Brad Calder,Rajesh K. Gupta
#t2005
#cCODES+ISSS
#index106243
#%133591
#%133920
#%419387
#%597692
#%133297
#%53716
#%142834
#%86597
#%252854
#%282972
#!For embedded system development, several companies provide cross-platform development tools to aid in debugging, prototyping and optimization of programs. These are full system emulation systems that can emulate the final binary to be run on the real board, its operating system and devices. Many of these emulation systems do not provide cycle level information due to the time consuming nature of cycle accurate simulation.In this paper we propose a method to provide Cycle-Close Traces of cycle-level statistics for the complete execution of the program in orders of magnitude less time than performing full cycle accurate simulation, with an average error of 3.2%. Our approach uses dynamic phase analysis to generate targeted cycle-close simulation samples. Detailed simulation results for these samples are used to produce fast cycle-close traces during a program's execution, so the user can also watch, pause and debug the currently executing code and its corresponding architecture performance characteristics at any point during execution.

#*Power analysis of system-level on-chip communication architectures.
#@Kanishka Lahiri,Anand Raghunathan
#t2004
#cCODES+ISSS
#index106244
#!For complex System-on-chips (SoCs) fabricated in nanometer technologies, the system-level on-chip communication architecture is emerging as a significant source of power consumption. Managing and optimizing this important component of SoC power requires a detailed understanding of the characteristics of its power consumption. Various power estimation and low-power design techniques have been proposed for the global interconnects that form part of SoC communication architectures (e.g., low-swing buses, bus encoding, etc). While effective, they only address a limited part of communication architecture power consumption. A state-of-the-art communication architecture, viewed in its entirety, is quite complex, comprising several components, such as bus interfaces, arbiters, bridges, decoders, and multiplexers, in addition to the global bus lines. Relatively little research has focused on analyzing and comparing the power consumed by different components of the communication architecture. In this work, we present a systematic evaluation and analysis of the power consumed by a state-of-the-art communication architecture (the AMBA on-chip bus), using a commercial design flow. We focus on developing a quantitative understanding of the relative contributions of different communication architecture components to its power consumption, and the factors on which they depend. We decompose the communication architecture power into power consumed by logic components (such as arbiters, decoders, bus bridges), global bus lines (that carry address, data, and control information), and bus interfaces. We also perform studies that analyze the impact of varying application traffic characteristics, and varying SoC complexity, on communication architecture power. Based on our analyses, we evaluate different techniques for reducing the power consumed by the on-chip communication architecture, and compare their effectiveness in achieving power savings at the system level. In addition to quantitatively reinforcing the view that on-chip communication is an important target for system-level power optimization, our work demonstrates (i) the importance of considering the communication architecture in its entirety, and (ii) the opportunities that exist for power reduction through careful communication architecture design.

#*Towards effective embedded processors in codesigns: customizable partitioned caches.
#@Peter Petrov,Alex Orailoglu
#t2001
#cCODES
#index106245
#%419334
#%499007
#%360205
#%132358
#%53705
#%9835
#!This paper explores an application-specific customization technique for the data cache, one of the foremost area/power consuming and performance determining microarchitectural features of modern embedded processors. The automated methodology for customizing the processor microarchitecture that we propose results in increased performance, reduced power consumption and improved determinism of critical system parts while the fixed design ensures processor standardization. The resulting improvements help to enlarge the significant role of embedded processors in modern hardware/software codesign techniques by leading to increased processor utilization and reduced hardware cost. A novel methodology for static analysis and a field-reprogrammable implementation of a customizable cache controller that implements a partitioned cache structure is proposed. The simulation results show significant decrease of miss ratio compared to traditional cache organizations.

#*Fast system-level power profiling for battery-efficient system design.
#@Kanishka Lahiri,Anand Raghunathan,Sujit Dey
#t2002
#cCODES
#index106246
#%141312
#%645716
#%283294
#%436814
#%106085
#%52286
#%131937
#%132715
#%132274
#%133920
#%142312
#!An increasing disparity between the energy requirements of portable electronic devices and available buttry capacities is driving the development of new design methodologies for battery-efficient systems. A crucial requirement for battery efficient system design is to be able to efficiently and accurately estimate battery life for candidate system architectures. Recently, efficient techniques have been developed to estimate battery life under given profiles of system power consumption over time. However, techniques for generating the power profiles themselves are either too cumbersome for system level exploration, or too inaccurate for battery life estimation.In this paper, we present a new methodology for efficiently and accurately generating power profiles for different system-level architectures. The designer can specify the manner in which (i) system tasks are mapped to a set of available implementations, and (ii) system communications are mapped to a specified communication architecture. For a given architecture, a power profile is automatically generated by analyzing an abstract representation of the system execution traces, while taking into account the selected implementations of the system's computations and communications.Experiments conducted on the design of an IEEE 802.11 MAC processor indicate that the power profiling approach offers run times that are several orders of magnitude lower than a simulation based power profiling technique, while sustaining negligible loss of accuracy (average profiling error was observed to be less than 3.4%).

#*Energy frugal tags in reprogrammable I-caches for application-specific embedded processors.
#@Peter Petrov,Alex Orailoglu
#t2002
#cCODES
#index106247
#%436755
#%436814
#%436603
#%437028
#%499268
#%436789
#%859308
#%499311
#!In this paper we present a software-directed customization methodology for minimizing the energy dissipation in the instruction cache, one of the most power consuming microarchitectural components of high-end embedded processors. We target particularly the instruction cache tag operations and show how an exceedingly small number of tag bits, if any, are needed to compute the miss/hit behavior for the most frequently executed application loops, thus minimizing the energy needed to perform the tag reads and comparisons. The proposed methodology exploits the fact that the code layout structure of the program loops can be identified after compile and link, and that it typically resides in a very confined memory location, for which very few bits from the effective address can be utilized as a tag. Subsequently, we present an efficient, programmable implementation to apply the suggested energy minimization technique. The experimental results show a significant decrease in energy dissipation for a set of real-life applications.

#*Automatic test bench generation for simulation-based validation.
#@Marcello Lajolo,Luciano Lavagno,Maurizio Rebaudengo,Matteo Sonza Reorda,Massimo Violante
#t2000
#cCODES
#index106248
#%141686
#%566977
#%282300
#%1167032
#%282035
#%649367
#!In current design practice synthesis tools play a key role, letting designers to concentrate on the specification of the system being designed by carrying out repetitive tasks such as architecture synthesis and technology mapping. However, in the new design flow, validation still remains a challenge: while new technologies based on formal verification are only marginally accepted for large designs, standard techniques based on simulation are beginning to fall behind the increased system complexity. This paper proposes an approach to simulation-based validation, in which an evolutionary algorithm computes useful input sequences to be included in the test bench. The feasibility of the proposed approach is assessed with a preliminary implementation of the proposed algorithm.

#*Aspects of system-level design.
#@Jonas Plantin,Erik Stoy
#t1999
#cCODES
#index106249
#%131795
#%131430
#%858040

#*A compilation-based software estimation scheme for hardware/software co-simulation.
#@Marcello Lajolo,Mihai Lazarescu,Alberto L. Sangiovanni-Vincentelli
#t1999
#cCODES
#index106250
#%134030
#%106134
#%134441
#%133072
#%282088

#*Fast prototyping: a system design flow for fast design, prototyping and efficient IP reuse.
#@François Pogodalla,Richard Hersemeule,Pierre Coulomb
#t1999
#cCODES
#index106251
#%131297
#%193874
#%133243
#%106134
#%106009
#%131426

#*A case study on modeling shared memory access effects during performance analysis of HW/SW systems.
#@Marcello Lajolo,Anand Raghunathan,Sujit Dey,Luciano Lavagno,Alberto L. Sangiovanni-Vincentelli
#t1998
#cCODES
#index106252
#%193849
#%134030
#%131464
#%133702
#%282088
#%133707
#%282049
#%133072

#*Co-design of interleaved memory systems.
#@Hua Lin,Wayne Wolf
#t2000
#cCODES
#index106253
#%1078809
#%1081439
#%1081598
#%343959
#%450698
#%252649
#%418633
#%542461
#%1079918
#%1079630
#!Memory interleaving is a cost-efficient approach to increase bandwidth. Improving data access locality and reducing memory access conflicts are two important aspects to achieve high efficiency for interleaved memory. In this paper, we introduce a design framework that integrates these two optimizations, in order to find out minimal memory banks and channels required in the embedded system under performance restriction. Several important techniques, loop and data layout transformations for data access locality, extracting data streams, conflict cache miss reduction as well as data placement and optimally reordered access for interleaved memories, are incorporated in the design framework. Experiments show that our co-design method results in substantially less hardware requirement compared to the implementations without optimization.

#*A time-predictable system initialization design for huge-capacity flash-memory storage systems.
#@Chin-Hsien Wu
#t2008
#cCODES+ISSS
#index106254
#%1124114
#%568850
#%562795
#%283397
#!The capacity of flash-memory storage systems grows at a speed similar to many other storage systems. In order to properly manage the product cost, vendors face serious challenges in system designs. How to provide an expected system initialization time for huge-capacity flash-memory storage systems has become an important research topic. In this paper, a time-predictable system initialization design is proposed for huge-capacity flash-memory storage systems. The objective of the design is to provide an expected system initialization time based on a coarse-grained flash translation layer. The time-predictable analysis of the design is provided to discuss the relation between the size of main memory and the system initialization time. The system initialization time can be also estimated and predicted by the time-predictable analysis.

#*A case study in computer-aided codesign of embedded controllers.
#@Luciano Lavagno,Massimiliano Chiodo,Paolo Giusto,Attila Jurecska,Harry Hsieh,S. Yee,Alberto L. Sangiovanni-Vincentelli,Kei Suzuki
#t1994
#cCODES
#index106255
#%286764
#%1078390
#!With our codesign system, POLIS, we have specified and implemented a real-life design: a shock absorber controller. Through this experiment, we have shown the possibility of using such a system to design complex applications and to speed up the design cycle dramatically. All aspects of the design process are closely scrutinized including high level language translation and automatic hardware and software synthesis. We analyze different software implementation styles and draw some conclusions about our design process.

#*Exploiting polymorphism in HW design: a case study in the ATM domain.
#@Luigi Pomante
#t2004
#cCODES+ISSS
#index106256
#!The need of raising the level of abstraction and improving reuse in HW design suggests the adoption of an object-oriented (OO) design methodology based on SystemC-Plus (i.e. an enhanced SystemC). Such a methodology, developed during the ODETTE IST project, allows the exploitation of the key features of the OO paradigm (i.e. information hiding, inheritance, and polymorphism) at the behavioral level of description while guaranteeing synthesizability. In this context, the goal of this paper is to highlight advantages and drawbacks derived from the exploitation of polymorphism in the design of an ATM component: the UTOPIA Cells Handler.

#*A novel deadlock avoidance algorithm and its hardware implementation.
#@Jaehwan Lee,Vincent John Mooney III
#t2004
#cCODES+ISSS
#index106257
#!This paper proposes a novel Deadlock Avoidance Algorithm (DAA) and its hardware implementation, the Deadlock Avoidance Unit (DAU), as an Intellectual Property (IP) core that provides a mechanism for very fast and automatic deadlock avoidance in MultiProcessor System-on-a-Chip (MPSoC) with multiple (e.g., 10) processing elements and multiple (e.g., 40) resources. The DAU avoids deadlock by not allowing any grant or request that leads to a deadlock. In case of livelock, the DAU asks one of the processes involved in the livelock to release resource(s) so that the livelock can also be resolved. We simulated two realistic examples that can benefit from the DAU, and demonstrated that the DAU not only avoids deadlock in a few clock cycles but also achieves a 37% speed-up of application execution time over avoiding deadlock in software. Finally, the SoC area overhead due to the DAU is small, under 0.01% in our example.

#*Performance estimation for embedded systems with data and control dependencies.
#@Paul Pop,Petru Eles,Zebo Peng
#t2000
#cCODES
#index106258
#%106070
#%142787
#%141834
#%106264
#%1275423
#%287030
#!In this paper we present an approach to performance estimation for hard real-time systems. We consider architectures consisting of multiple processors. The scheduling policy is based on a preemptive strategy with static priorities. Our model of the system captures both data and control dependencies, and the analysis is able to reduce the pessimism of the estimation by using the knowledge about these dependencies. Extensive experiments as well as a real life example demonstrate the efficiency of our approach.

#*Reconfigurable SoC design with hierarchical FSM and synchronous dataflow model.
#@Sunghyun Lee,Sungjoo Yoo,Kiyoung Choi
#t2002
#cCODES
#index106259
#%203232
#%142444
#%214452
#%214253
#%282058
#%132655
#%106090
#%1081422
#%142648
#!We present a method of runtime configuration scheduling in reconfigurable SoC design. As a model of computation in system representation, we use a popular formal model of computation, hierarchical FSM (HFSM) with synchronous dataflow (SDF) model, in short HFSM-SDF model. In reconfigurable SoC design with the HFSM-SDF model, the problem of configuration scheduling is challenging due to the dynamic behavior of the system such as concurrent execution of state transitions (by AND relation), complex flow (in the HFSM), and complex schedules of SDF actor firing. Thus, compile-time static configuration scheduling may not efficiently hide configuration latency.To resolve the problem, it is necessary to know the exact order of required configurations during runtime and to perform runtime configuration scheduling. To obtain the exact order of configuration, we exploit the inherent property of HFSM-SDF that the execution order of SDF actors can be determined before the execution of state transition of top FSM. After obtaining the order information in a queue called ready configuration queue, we execute the state transition. During the execution, whenever there is new available FPGA resource, a new configuration is selected from the queue and fetched by the runtime configuration scheduler. We applied the method to an MPEG4 decoder design and obtained up to 21.8% improvement in system runtime with a negligible overhead of runtime (1.4%) and memory usage (0.94%).

#*Holistic scheduling and analysis of mixed time/event-triggered distributed embedded systems.
#@Traian Pop,Petru Eles,Zebo Peng
#t2002
#cCODES
#index106260
#%1052947
#%857832
#%141760
#%858040
#%565074
#%1135277
#%1066580
#%1275423
#!This paper deals with specific issues related to the design of distributed embedded systems implemented with mixed, event-triggered and time-triggered task sets, which communicate over bus protocols consisting of both static and dynamic phases. Such systems are emerging as the new standard for automotive applications. We have developed a holistic timing analysis and scheduling approach for this category of systems. We have also identified several new design problems characteristic to such hybrid systems. An example related to bus access optimization in the context of a mixed static/dynamic bus protocol is presented. Experimental results prove the efficiency of such an optimization approach.

#*Code compression as a variable in hardware/software co-design.
#@Haris Lekatsas,Jörg Henkel,Wayne Wolf
#t2000
#cCODES
#index106261
#%49849
#%146496
#%146497
#%890976
#%437203
#%450620
#%499520
#%499321
#%132912
#%436551
#%132274
#!We present a new way to practice and view handware/software co-design: rather than raising the level of abstraction in order to exploit the highest possible degree of optimization, we use code compression i.e. we practice co-design at the bit-level. Through our novel architecture combined with our compression methodology this results in optimization of all major design goals/constraints. In particular, we present a compression methodology that deploys what we call a &ldquo;post-cache architecture&rdquo; (i.e. the detached decompression unit is located between the CPU and the instruction cache). We present a design methodology that allows the designer to control parameters like speed, power, and area through the choice of compression parameters. In addition we show that our compression methodology (using a Markov Model) is more efficient than the widely used Huffman compression scheme.

#*Design optimization of mixed time/event-triggered distributed embedded systems.
#@Traian Pop,Petru Eles,Zebo Peng
#t2003
#cCODES+ISSS
#index106262
#%142787
#%1052947
#%1066580
#%858040
#%1135277
#%141760
#!Distributed embedded systems implemented with mixed, event-triggered and time-triggered task sets, which communicate over bus protocols consisting of both static and dynamic phases, are emerging as the new standard in application areas such as automotive electronics. In a previous paper, we have developed a holistic timing analysis and scheduling approach for this category of systems. Based on this result, in the present paper, new design problems are solved, which we identified as characteristic for such hybrid systems: partitioning of the system functionality into time-triggered and event-triggered domains and the optimization of parameters corresponding to the communication protocol. We addressed both problems in the context of a heuristic which performs mapping and scheduling of the system functionality. We demonstrated the efficiency of the proposed technique with extensive experiments.

#*Spatial division multiplexing: a novel approach for guaranteed throughput on NoCs.
#@Anthony Leroy,Paul Marchal,Adelina Shickova,Francky Catthoor,Frédéric Robert,Diederik Verkest
#t2005
#cCODES+ISSS
#index106263
#%141996
#%805785
#%142871
#%131914
#%282620
#%142153
#%142537
#!To ensure low power consumption while maintaining flexibility and performance, future Systems-on-Chip (SoC) will combine several types of processor cores and data memory units of widely different sizes. To interconnect the IPs of these heterogeneous platforms, Networks-on-Chip (NoC) have been proposed as an efficient and scalable alternative to shared buses. NoCs can provide throughput and latency guarantees by establishing virtual circuits between source and destination. State-of-the-art NoCs currently exploit Time-Division Multiplexing (TDM) to share network resources among virtual circuits, but this typically results in high network area and energy overhead with long circuit set-up time.We propose an alternative solution based on Spatial Division Multiplexing (SDM). This paper describes our first design of an SDM-based network, discusses design alternatives for network implementation and shows why SDM should be better adapted to NoCs than TDM for a limited number of circuits.Our case study clearly illustrates the advantages of our technique over TDM in terms of energy consumption, area overhead, and flexibility. SDM thus deserves to be explored in more depth, and in particular in combination with TDM in a hybrid scheme.

#*Scheduling with optimized communication for time-triggered embedded systems.
#@Paul Pop,Petru Eles,Zebo Peng
#t1999
#cCODES
#index106264
#%106070
#%131783
#%141834
#%806987
#%450544
#%1126042

#*Towards a new standard for system-level design.
#@Stan Y. Liao
#t2000
#cCODES
#index106265
#%219363
#%858044
#%132955
#%2346
#%52896
#%134281
#!Huge new design challenges for system-on-chip (SoC) are the result of decreasing time-to-market coupled with rapidly increasing gate counts and embedded software representing 50-90 percent of the functionality. The exchange of system-level intellectual property (IP) models for creating executable specifications has become a key strategic element for efficient system-to-silicon design flows. Because C and C++ are the dominant languages used by chip architects, systems engineers and software engineers today, we believe that a C-based approach to hardware modeling is necessary. This will enable co-design, providing a more natural solution to partitioning functionality between hardware and software. In this paper we present the design of SystemC, a C++ class library that provides the necessary features for modeling design hierarchy, concurrency, and reactivity in hardware. We will also describe experiences of using SystemC 1) for the co-verification of 8051 processor with a bus-functional model and 2) for the modeling and simulation of an MPEG-2 video decoder.

#*Minimizing system modification in an incremental design approach.
#@Paul Pop,Petru Eles,Traian Pop,Zebo Peng
#t2001
#cCODES
#index106266
#%106070
#%283027
#%806987
#%282905
#%858040
#%133569
#%1135277
#!In this paper we present an approach to mapping and scheduling of distributed embedded systems for hard real-time applications, aiming at minimizing system modification cost. We consider an incremental design process that starts from an already existing system running a set of applications. We are interested to implement new functionality so that the already running applications are disturbed as little as possible and there is a good chance that, later, new functionality can easily be added to the resulted system. The mapping and scheduling problem are considered in the context of a realistic communication model based on a TDMA protocol.

#*High-level synthesis for large bit-width multipliers on FPGAs: a case study.
#@Gang Quan,James P. Davis,Siddhaveerasharan Devarkal,Duncan A. Buell
#t2005
#cCODES+ISSS
#index106267
#%203280
#%13374
#%133948
#%142610
#%450519
#%832454
#%542847
#%282058
#%120244
#%131518
#!In this paper, we present the analysis, design and implementation of an estimator to realize large bit width unsigned integer multiplier units. Larger multiplier units are required for cryptography and error correction circuits for more secure and reliable transmissions over highly insecure and/or noisy channels in networking and multimedia applications. The design space for these circuits is very large when integer multiplication on large operands is carried out hierarchically. In this paper, we explore automated synthesis of high bit-width unsigned integer multiplier circuits by defining and validating an estimator function used in search and analysis of the design space of such circuits. We focus on analysis of a hybrid hierarchical multiplier scheme that combines the throughput advantages of parallel multipliers and the resource cost-effectiveness of serial ones. We present an analytical model that rapidly predicts timing and resource usage for selected model candidates. We evaluate the estimator model in the design of a practical application, a 256-bit elliptic curve adder implemented on a Xilinx FPGA fabric. We show that our estimator allows implementation of fast, efficient circuits, where resultant designs provide order-of-magnitude performance improvements when compared with that of software implementations on a high performance computing platform.

#*Dual-pipeline heterogeneous ASIP design.
#@Swarnalatha Radhakrishnan,Hui Guo,Sri Parameswaran
#t2004
#cCODES+ISSS
#index106268
#!In this paper we demonstrate the feasibility of a dual pipeline Application Specific Instruction Set Processor. We take a C program and create a target instruction set by compiling to a basic instruction set, from which some instructions are merged, while others discarded. Based on the target instruction set, parallelism of the application program is analyzed and two unique instruction sets are generated for a heterogeneous dual-pipeline processor. The dual pipe processor is created by making two unique ASIPs (VHDL descriptions) utilizing the ASIP-Meister Tool Suite, and fusing the two VHDL descriptions to construct a dual pipeline processor. Our results show that in comparison to the single pipeline Application Specific Instruction Set Processor, the performance improves by 27.6% and switching activity reduces by 6.1% for a number of benchmarks. These improvements come at the cost of increased area which for benchmarks considered is 16.7% on average.

#*Development of an optimizing compiler for a Fujitsu fixed-point digital signal processor.
#@Sreeranga P. Rajan,Masahiro Fujita,Ashok Sudarsanam,Sharad Malik
#t1999
#cCODES
#index106269
#%450468
#%1123307
#%1008179

#*Hardware-software bipartitioning for dynamically reconfigurable systems.
#@Daler N. Rakhmatov,Sarma B. K. Vrudhula
#t2002
#cCODES
#index106270
#%106325
#%106216
#%282698
#%282058
#%141335
#%1165806
#%282717
#%215073
#%132927
#!The main unique feature of dynamically reconfigurable systems is the ability to time-share the same reconfigurable hardware resources. However, the energy-delay cost associated with reconfiguration must be accounted for during hardware-software partitioning. We propose a method for mapping nodes of an application control flow graph either to software or reconfigurable hardware, explicitly targeting minimization of the energy-delay cost due to both computation and configuration. The addressed problems are energy-delay product minimization, delay-constrained energy minimization, and energy-constrained delay minimization. We show how these problems can be tackled by using network flow techniques, after transforming the original control flow graph into an equivalent network. If there are no constraints, as in the case of the energy-delay product minimization, we are able to generate an optimal solution in polynomial time.

#*Timing-driven HW/SW codesign based on task structuring and process timing simulation.
#@Dinesh Ramanathan,Ali Dasdan,Rajesh K. Gupta
#t1999
#cCODES
#index106271
#%106150
#%1117668
#%131933
#%1128160
#%1117866

#*A low power scheduler using game theory.
#@N. Ranganathan,Ashok K. Murugavel
#t2003
#cCODES+ISSS
#index106272
#%436542
#%450703
#%436665
#%1135436
#%645627
#%646073
#%194895
#%133481
#!In this paper, we describe a new methodology based on game theory for minimizing the average power of a circuit during scheduling in behavioral synthesis. The problem of scheduling in data-path synthesis is formulated as an auction based non-cooperative finite game, for which solutions are developed based on the Nash equilibrium function. Each operation in the data-path is modeled as a player bidding for executing an operation in the given control cycle, with the estimated power consumption as the bid. Also, a combined scheduling and binding algorithm is developed using a similar approach in which the two tasks are modeled together such that the Nash equilibrium function needs to be applied only once to accomplish both the scheduling and binding tasks together. The combined algorithm yields further power reduction due to additional savings during binding. The proposed algorithms yield better power reduction than ILP-based methods with comparable run times and no increase in area overhead.

#*Verification of design decisions in ForSyDe.
#@Tarvo Raudvere,Ingo Sander,Ashish Kumar Singh,Axel Jantsch
#t2003
#cCODES+ISSS
#index106273
#%450669
#%832939
#%133757
#%629098
#%309886
#%142931
#%546106
#%1128272
#%1056494
#%1127449
#!The ForSyDe methodology has been developed for system level design. Starting with a formal specification model that captures the functionality of the system at a high abstraction level, it provides formal design transformation methods for a transparent refinement process of the specification model into an implementation model that is optimized for synthesis. A transformation may be semantic preserving or a design decision. The latter modifies the semantics of the system level description and changes the meaning of the model. The main contribution of this paper is the incorporation of model checking to verify that refined system blocks satisfy the design specification. We illustrate the translation of the ForSyDe code to the SMV language and the verification of local design decisions with a case study of a ForSyDe equalizer model.

#*Interface models.
#@Anders P. Ravn,Jørgen Staunstrup
#t1994
#cCODES
#index106274
#%257438
#!This paper proposes a model for specifying interfaces between concurrently executing modules of a computing system. The model does not prescribe a particular type of communication protocol and is aimed at describing interfaces between both software and hardware modules or a combination of the two. The model describes both functional and timing properties of an interface.

#*An efficient retargetable framework for instruction-set simulation.
#@Mehrdad Reshadi,Nikhil Bansal,Prabhat Mishra,Nikil D. Dutt
#t2003
#cCODES+ISSS
#index106275
#%133249
#%133591
#%142020
#%106047
#%133297
#%132276
#%132318
#%542832
#!Instruction-set architecture (ISA) simulators are an integral part of today's processor and software design process. While increasing complexity of the architectures demands high performance simulation, the increasing variety of available architectures makes retargetability a critical feature of an instruction-set simulator. Retargetability requires generic models while high performance demands target specific customizations. To address these contradictory requirements, we have developed a generic instruction model and a generic decode algorithm that facilitates easy and efficient retargetability of the ISA-simulator for a wide range of processor architectures such as RISC, CISC, VLIW and variable length instruction set processors. The instruction model is used to generate compact and easy to debug instruction descriptions that are very similar to that of architecture manual. These descriptions are used to generate high performance simulators. The generation of the simulator is completely separate from the simulation engine. Hence, we can incorporate any fast simulation technique in our retargetable framework without loosing performance. We illustrate the retargetability of our approach using two popular, yet different realistic architectures: the Sparc and the ARM.

#*A cycle-accurate compilation algorithm for custom pipelined datapaths.
#@Mehrdad Reshadi,Daniel Gajski
#t2005
#cCODES+ISSS
#index106276
#%1493931
#%1494237
#%1496132
#%161083
#%144022
#%131993
#%134417
#%133420
#%450639
#%193936
#%499348
#%282479
#%141627
#%194061
#!Traditional high level synthesis (HLS) techniques generate a datapath and controller for a given behavioral description. The growing wiring cost and delay of today technologies require aggressive optimizations, such as interconnect pipelining, that cannot be done after generating the datapath and without invalidating the schedule. On the other hand, the increasing manufacturing complexities demand approaches that favor design for manufacturability (DFM).To address these problems we propose an approach in which the datapath of the architecture is fully allocated before scheduling and binding. We compile a C program directly to the datapath and generate the controller. We can support the entire ANSI C syntax because the datapath can be as complex as the datapath of a processor. Since there is no instruction abstraction in this architecture we call it No-Instruction-Set-Computer (NISC). As the first step towards realization of a NISC-based design flow, we present an algorithm that maps an application on a given datapath by performing scheduling and binding simultaneously. With this algorithm, we achieved up to 70% speedup on a NISC with a datapath similar to that of MIPS, compared to a MIPS gcc compiler. It also efficiently handles different datapath features such as pipelining, forwarding and multi-cycle units.

#*Memory access optimizations in instruction-set simulators.
#@Mehrdad Reshadi,Prabhat Mishra
#t2005
#cCODES+ISSS
#index106277
#%133591
#%597692
#%133297
#%450517
#%53704
#%138427
#%542832
#%53681
#%106275
#!Design of programmable processors and embedded applications requires instruction-set simulators for early exploration and validation of candidate architectures. Interpretive simulators are widely used in embedded systems design. One of the key performance bottlenecks in interpretive simulation is the instruction and data memory access translation between host and target machines. The simulators must maintain and update the status of the simulated processor including memory and register values. A major challenge in the simulation is to efficiently map the target address space to the host address space. This paper presents two optimization techniques that aggressively utilize the spatial locality of the instruction and data accesses in interpretive simulation: signature based address mapping for optimizing general memory accesses; and incremental instruction fetch for optimizing instruction accesses. To demonstrate the utility of this approach we applied these techniques on SimpleScalar simulator, and obtained up to 30% performance improvement. Our techniques complement the recently proposed optimizations (JIT-CCS [1] and IS-CS [2]) and further improve the performance (up to 89%) on ARM7 and Sparc processors.

#*A multicast inter-task communication protocol for embedded multiprocessor systems.
#@Víctor Reyes,Tomás Bautista,Gustavo Marrero Callicó,Antonio Núñez,Wido Kruijtzer
#t2005
#cCODES+ISSS
#index106278
#%132734
#%410657
#%161033
#%143321
#!Recently, a new programming model and platform interface for MPSoC design and integration called TTL (Task Transaction Level) has been developed and advocated as a standard. In this paper, a specific implementation of the TTL interface named ITCP (Inter-Task Communication Protocol) is presented. ITCP is well suited for both hardware and software implementations and supports features such as multitasking and multicast communication. A configurable SystemC model of the ITCP protocol and its integration in a system-level design methodology is disclosed in this work. Moreover, details of a multi-task ITCP software shell implementation for an ARM9 with eCos RTOS are also given in the paper.

#*Area-efficient buffer binding based on a novel two-port FIFO structure.
#@Kyoungseok Rha,Kiyoung Choi
#t2001
#cCODES
#index106279
#%546573
#%114985
#!In this paper, we address the problem of minimizing buffer storage requirement in buffer binding for SDF (Synchronous Dataflow) graphs. First, we propose a new two-port FIFO buffer structure that can be efficiently shared by two producer/consumer pairs. Then we propose a buffer binding algorithm based on this two-port buffer structure for minimizing the buffer size requirement. Experimental results demonstrate 9.8%~37.8% improvement in buffer requirement compared to the conventional approaches.

#*Overhead effects in real-time preemptive schedules.
#@David L. Rhodes,Wayne Wolf
#t1999
#cCODES
#index106280
#%1127638
#%106020
#%564655

#*Efficient mapping of hierarchical trees on coarse-grain reconfigurable architectures.
#@Fredy Rivera,Marcos Sanchez-Elez,Milagros Fernández,Román Hermida,Nader Bagherzadeh
#t2004
#cCODES+ISSS
#index106281
#!Reconfigurable architectures have become increasingly important in recent years. In this paper we present an approach to the problem of executing 3D graphics interactive applications onto these architectures. The hierarchical trees are usually implemented to reduce the data processed, thereby diminishing the execution time. We have developed a mapping scheme that parallelizes the tree execution onto a SIMD reconfigurable architecture. This mapping scheme considerably reduces the time penalty caused by the possibility of executing different tree nodes in SIMD fashion. We have developed a technique that achieves an efficient hierarchical tree execution taking decisions at execution time. It also promotes the possibility of data coherence in order to reduce the execution time. The experimental results show high performance and efficient resource utilization on tested applications.

#*Comparing two testbench methods for hierarchical functional verification of a bluetooth baseband adaptor.
#@Edgar L. Romero,Marius Strum,Wang Jiang Chau
#t2005
#cCODES+ISSS
#index106282
#%133141
#%858576
#%573925
#!The continuous improvement on the design methodologies and processes has made possible the creation of huge and very complex digital systems. Design verification is one of the main tasks in the design flow, aiming to certify the system functionality has been accomplished accordingly to the specification. A simulation based technique known as functional verification has been followed by the industry. In recent years, several articles in functional verification have been presented, focusing either on specific design verification experiments or on methods to improve and accelerate coverage reaching. In the first category, the majority of the papers are aimed to processors verification, while communication systems experiences were not such commonly reported. In the second category, different authors have proposed methodologies, which need an extensive and complex work by the verification engineer on tuning the acceleration algorithms to the specific design. In the present paper, we present a functional verification methodology applied to a Bluetooth Baseband adaptor core, described in SystemC RTL. Two techniques are considered, one following the traditional framework of applying random stimuli and checking functional coverage aspects; in the second one, a simple acceleration procedure, based on redundant stimuli filtering, is included. For both solutions, a hierarchical approach is adopted. We present several results comparing both solutions, showing the gain obtained in using the acceleration technique. Additionally, we show how results on a real testbench application environment correlate to the hierarchical verification approach taken.

#*A Model for the Coanalysis of Hardware and Software Architectures.
#@Fred Rose,Todd Carpenter,Sanjaya Kumar,John Shackleton,Todd Steeves Honeywell
#t1996
#cCODES
#index106283
#%1128036
#%134548
#%858145
#%858146
#%858044
#%106188
#!Successful multiprocessor system design for complex real-time embedded applications requires powerful and comprehensive, yet cost-effective, productive, and maintain able modeling. The multi-disciplinary, VHDL-based modeling library developed by the Honeywell Technology Center places heavy emphasis on multiprocessing and distributed communications. These models focus on detailed hardware performance analysis along with multiple abstraction levels for software representation and evaluation. This paper will detail the processor model which provides the key element for the coanalysis of hardware and software system architectures.

#*Program slicing for codesign.
#@Jeffry T. Russell
#t2002
#cCODES
#index106284
#%530285
#%364202
#%553039
#%362144
#%601175
#%996514
#%530360
#%450911
#%601273
#%363152
#!Program slicing is a software analysis technique that computes the set of operations in a program that may affect the computation at a particular operation. Interprocedural slicing techniques have separately addressed concurrent programs and hardware description languages. However, application of slicing to codesign of embedded systems requires dependence analysis across the hardware-software interface.We extend program slicing for a codesign environment. Hardware-software interactions common in component-based systems are mapped to previously introduced dependences, including the interference and signal dependences. We introduce a novel access dependence that models a memory access side effect that results in activation of a process. A slicing algorithm that incorporates this variety of dependences is described.

#*Design of multi-tasking coprocessor control for Eclipse.
#@Martijn J. Rutten,Jos T. J. van Eijndhoven,Evert-Jan D. Pol
#t2002
#cCODES
#index106285
#%858022
#%410657
#%174511
#%134163
#%450596
#!Eclipse defines a heterogeneous multiprocessor architecture template for data-dependent stream processing. Intended as a scalable and flexible subsystem of forthcoming media-processing systems-on-a-chip, Eclipse combines application configuration flexibility with the efficiency of function-specific hardware, or coprocessors. To facilitate reuse, Eclipse separates coprocessor functionality from generic support that addresses multi-tasking, inter-task synchronization, and data transport. Five interface primitives accomplish this separation. The interface facilitates the design of coprocessors that require complex control to handle data-dependent I/O, saving/restoring task state upon task switches, and pipelined processing. This paper presents how this interface enables the design of such reusable yet cost-effective coprocessors.

#*Instruction-level power estimation for embedded VLIW cores.
#@Mariagiovanna Sami,Donatella Sciuto,Cristina Silvano,Vittorio Zaccaria
#t2000
#cCODES
#index106286
#%283294
#%1135095
#!In this paper, a power estimation methodology operating at the instruction-level is proposed. The methodology is tightly related to the characteristics of the system architecture, mainly in terms of one or more target processors, the memory sub-system, the system-level buses and the coprocessors. In this system-level framework, our main goal is to define a power model for CPU cores at the instruction-level. First, the proposed power model deals with a general five-stage pipeline processor architecture, then, the model is extended to VLIW processors. The derivation of a VLIW instruction-level power model results to be intractable from the point of view of spatial complexity (which grows exponentially w.r.t. the number of possible operations in the ISA). In order to tackle this complexity, a new kind of simplification, based on the original concept of separability of processor functional units, is introduced. The proposed system-level methodology is the first step toward a more general framework to support the design of power-oriented applications through hardware/software co-design.1

#*System synthesis utilizing a layered functional model.
#@Ingo Sander,Axel Jantsch
#t1999
#cCODES
#index106287
#%309886
#%645957
#%833088

#*Service dependency graph: an efficient model for hardware/software interfaces modeling and generation for SoC design.
#@Adriano Sarmento,Lobna Kriaa,Arnaud Grasset,Mohamed-Wassim Youssef,Aimen Bouchhima,Frédéric Rousseau,Wander O. Cesário,Ahmed Amine Jerraya
#t2005
#cCODES+ISSS
#index106288
#%131216
#%131540
#%134163
#%131624
#%858394
#%141917
#%106094
#!Complex systems-on-chip are designed by interconnecting pre-designed hardware (HW) and software (SW) components. During the design cycle, a global model of the SoC may be composed of HW and SW models at different abstraction levels. Designing HW/SW interfaces to interconnect SoC components is a source of design bottlenecks. This paper describes a service-based model enabling systematic design and co-simulation of HW/SW interfaces for SoC design. This model, called Service dependency graph (SDG) allows modeling of complex and application-specific interfaces. We present also a model generator that can automatically build HW/SW interfaces based on service and resource requirements described by the SDG. This approach has been applied successfully on the design of an MPEG-4 encoder. Additionally the SDG seems to be an excellent intermediate representation for the design automation of HW/SW interfaces.

#*Metrics for design space exploration of heterogeneous multiprocessor embedded systems.
#@Donatella Sciuto,Fabio Salice,Luigi Pomante,William Fornaciari
#t2002
#cCODES
#index106289
#%233860
#%225128
#%546090
#%106188
#%141594
#%361767
#%1117741
#!This paper considers the problem of designing heterogeneous multiprocessor embedded systems. The focus is on a step of the design flow: the definition of innovative metrics for the analysis of the system specification to statically identify the most suitable processing elements class for each system functionality. Experimental results are also included, to show the applicability and effectiveness of the proposed methodology.

#*Hardware support for real-time embedded multiprocessor system-on-a-chip memory management.
#@Mohamed Shalan,Vincent John Mooney III
#t2002
#cCODES
#index106290
#%807001
#%1078531
#%161051
#%77604
#%1117914
#%465215
#%927107
#!The aggressive evolution of the semiconductor industry --- smaller process geometries, higher densities, and greater chip complexity --- has provided design engineers the means to create complex high-performance Systems-on-a-Chip (SoC) designs. Such SoC designs typically have more than one processor and huge memory, all on the same chip. Dealing with the global on- chip memory allocation/de-allocation in a dynamic yet deterministic way is an important issue for the upcoming billion transistor multiprocessor SoC designs. To achieve this, we propose a memory management hierarchy we call Two-Level Memory Management. To implement this memory management scheme --- which presents a paradigm shift in the way designers look at on-chip dynamic memory allocation --- we present a System-on-a-Chip Dynamic Memory Management Unit (SoCDMMU) for allocation of the global on-chip memory, which we refer to as Level Two memory management (Level One is the operating system management of memory allocated to a particular on-chip Processing Element). In this way, processing elements (heterogeneous or non-heterogeneous hardware or software) in an SoC can request and be granted portions of the global memory in a fast and deterministic time (for an example of a four processing element SoC, the dynamic memory allocation of the global on-chip memory takes sixteen cycles per allocation/deallocation in the worst case). In this paper, we show how to modify an existing Real-Time Operating System (RTOS) to support the new proposed SoCDMMU. Our example shows a multiprocessor SoC that utilizes the SoCDMMU has 440% overall speedup of the application transition time over fully shared memory that does not utilize the SoCDMMU.

#*Novel architecture for loop acceleration: a case study.
#@Seng Lin Shee,Sri Parameswaran,Newton Cheung
#t2005
#cCODES+ISSS
#index106291
#%133988
#%499421
#%499311
#%450541
#%858044
#%805601
#%281912
#%645747
#%645223
#%252953
#%203228
#!In this paper, we show a novel approach to accelerate loops by tightly coupling a coprocessor to an ASIP. Latency hiding is used to exploit the parallelism available in this architecture. To illustrate the advantages of this approach, we investigate a JPEG encoding algorithm and accelerate one of its loop by implementing it in a coprocessor. We contrast the acceleration by implementing the critical segment as two different coprocessors and a set of customized instructions. The two different coprocessor approaches are: a high-level synthesis (HLS) approach; and a custom coprocessor approach. The HLS approach provides a faster method of generating coprocessors. We show that a loop performance improvement of 2.57x is achieved using the custom coprocessor approach, compared to 1.58x for the HLS approach and 1.33x for the customized instruction approach compared with just the main processor. Respective energy savings within the loop are 57%, 28% and 19%.

#*Fully Parallel Hardware/Software Codesign for Multi-Dimensional DSP Applications.
#@Michael Sheliga,Nelson L. Passos,Edwin Hsing-Mean Sha
#t1996
#cCODES
#index106292
#%131685
#%1124872
#%132288
#%858146
#%344027
#%133574
#%1126004
#!The design of multi-dimensional systems using hardware/software codesign allows a significant improvement in the development cycle. This paper presents a technique that enables a design to have arbitrarily high throughput by using multi-dimensional retiming techniques while adjusting the composition of hardware and multiple software elements in order to satisfy the area requirements. A multi-dimensional graph representing the problem is transformed and scheduled such that all nodes are executed in a fully parallel way. The techniques presented are applicable to any problem which can be represented as a multi-dimensional data flow graph. Results are shown which illustrate the efficiency of the system as well as the savings achieved.


#*Enforcing Schedulability of Multi-Task Systems by Hardware-Software Codesign.
#@Youngsoo Shin,Kiyoung Choi
#t1997
#cCODES
#index106293
#%450556
#%283136
#%808040
#%1081894
#%1128557
#%1127638
#!This paper deals with the problem of hardware-software codesign of hard real-time systems. For a given task set, we perform an exact schedulability test to determine whether the task set is schedulable or not. When there is a task that cannot meet the deadline, we compute the amount of time by which the deadline is missed. Then we determine which tasks should reduce their execution time to compensate that amount of time deviation. The reduction of execution time is achieved by implementing parts of the tasks with hardware. With this approach, we can systematically design a hard real-time system which is infeasible with all software implementation. Preliminary experimental results are given to demonstrate the effectiveness of our approach.

#*Automatic network generation for system-on-chip communication design.
#@Dongwan Shin,Andreas Gerstlauer,Rainer Dömer,Daniel D. Gajski
#t2005
#cCODES+ISSS
#index106294
#%131216
#%283380
#%131624
#%282905
#%282563
#%805785
#%141663
#%141925
#%133010
#%141915
#%645749
#%52280
#!With growing system complexities, system-level communication design is becoming increasingly important and advanced, network-oriented communication architectures become necessary. In this paper, we extend previous work on automatic communication refinement to support non-traditional, network-oriented architectures beyond a single bus. From an abstract description of the desired communication channels, the refinement tools automatically generate executable models and implementations of the system communication at various levels of abstraction. Experimental results show that significant productivity gains can be achieved, demonstrating the effectiveness of the approach for rapid, early communication design space exploration.

#*Power-aware communication optimization for networks-on-chips with voltage scalable links.
#@Dongkun Shin,Jihong Kim
#t2004
#cCODES+ISSS
#index106295
#!Networks-on-Chip (NOC) is emerging as a practical development platform for future systems-on-chip products. We propose an energy-efficient static algorithm which optimizes the energy consumption of task communications in NoCs with voltage scalable links. In order to find optimal link speeds, the proposed algorithm (based on a genetic formulation) globally explores the design space of NOC-based systems, including task assignment, tile mapping, routing path allocation, task scheduling and link speed assignment. Experimental results show that the proposed design technique can reduce energy consumption by 28% on average compared with existing techniques.

#*A novel parallel deadlock detection algorithm and architecture.
#@Pun H. Shiu,Yudong Tan,Vincent John Mooney III
#t2001
#cCODES
#index106296
#%286379
#!A novel deadlock detection algorithm and its hardware implementation are presented in this paper. The hardware deadlock detection algorithm has a run time complexity of &Ogr;hw (min(m,n)), where m and n are the number of processors and resources, respectively. Previous algorithms based on a Resource Allocation Graph have &Ogr;sw (m &times; n) run time complexity for the worst case. We simulate a realistic example in which the hardware deadlock detection unit is applied, and demonstrate that the hardware implementation of the novel deadlock detection algorithm reduces deadlock detection time by 99.5%. Furthermore, in a realistic example, total execution time is reduced by 68.9%.

#*Retargetable compilation for low power.
#@Wen-Tsong Shiue
#t2001
#cCODES
#index106297
#%1135095
#%131677
#%1123307
#!Most research to date on energy minimization in DSP processors has focuses on hardware solution. This paper examines the software-based factors affecting performance and energy consumption for architecture-aware compilation. In this paper, we focus on providing support for one architectural feature of DSPs that makes code generation difficult, namely the use of multiple data memory banks. This feature increases memory bandwidth by permitting multiple data memory accesses to occur in parallel when the referenced variables belong to different data memory banks and the registers involved conform to a strict set of conditions. We present novel instruction scheduling algorithms that attempt to maximize the performance, minimize the energy, and therefore, maximize the benefit of this architectural feature. Experimental results demonstrate that our algorithms generate high performance, low energy codes for the DPS architectural features with multiple data memory banks. Our algorithm led to improvements in performance and energy consumption of 48.3% and 66.6% respectively in our benchmark examples.

#*Operation tables for scheduling in the presence of incomplete bypassing.
#@Aviral Shrivastava,Eugene Earlie,Nikil D. Dutt,Alexandru Nicolau
#t2004
#cCODES+ISSS
#index106298
#!Register bypassing is a powerful and widely used feature in modern processors to eliminate certain data hazards. Although complete bypassing is ideal for performance, bypassing has significant impact on cycle time, area, and power consumption of the processor. Due to the strict constraints on performance, cost and power consumption in embedded processors, architects need to evaluate and implement incomplete register bypassing mechanisms. However traditional data hazard detection and/or avoidance techniques used in retargetable schedulers break down in the presence of incomplete bypassing. In this paper, we present the concept of Operation Tables, which can be used to detect data hazards, even in the presence of incomplete bypassing. Furthermore our technique integrates the detection of both data, as well as resource hazards, and can be easily employed in a compiler to generate better schedules. Our experimental results on the popular Intel XScale embedded processor platform show that even with a simple intra-basic block scheduling technique, we achieve upto 20% performance improvement over fully optimized GCC generated code on embedded applications from the MiBench suite.

#*Aggregating processor free time for energy reduction.
#@Aviral Shrivastava,Eugene Earlie,Nikil D. Dutt,Alexandru Nicolau
#t2005
#cCODES+ISSS
#index106299
#%132273
#%833164
#%483610
#!Even after carefully tuning the memory characteristics to the application properties and the processor speed, during the execution of real applications there are times when the processor stalls, waiting for data from the memory. Processor stall can be used to increase the throughput by temporarily switching to a different thread of execution, or reduce the power and energy consumption by temporarily switching the processor to low-power mode. However, any such technique has a performance overhead in terms of switching time. Even though over the execution of an application the processor is stalled for a considerable amount of time, each stall duration is too small to profitably perform any state switch. In this paper, we present code transformations to aggregate processor free time. Our experiments on the Intel XScale and Stream kernels show that up to 50,000 processor cycles can be aggregated, and used to profitably switch the processor to low-power mode. We further show that our code transformations can switch the processor to low-power mode for up to 75% of kernel runtime, achieving up to 18% of processor energy savings on multimedia applications. Our technique requires minimal architectural modifications and incurs negligible ( < 1%) performance loss.

#*Worst-case performance analysis of parallel, communicating software processes.
#@Axel Siebenborn,Oliver Bringmann,Wolfgang Rosenstiel
#t2002
#cCODES
#index106300
#%450521
#%282049
#%142062
#%132619
#!In this paper we present a method to perform static timing analysis of SystemC models, that describe parallel, communicating software processes. The paper combines a worst-case execution time (WCET) analysis with an analysis of the communication behavior. The communication analysis allows the detection of points, where the program flow of two or more concurrent processes are synchronized. This knowledge allows the determination of the worst-case response time (WCRT). The method does not rely on restrictions on the system design to prevent deadlocks or data loss. Furthermore possible deadlocks and data loss can be detected during the analysis.

#*Wireless protocols design: challenges and opportunities.
#@Julio Leao da Silva Jr.,Marco Sgroi,Fernando De Bernardinis,Suet-Fei Li,Alberto L. Sangiovanni-Vincentelli,Jan M. Rabaey
#t2000
#cCODES
#index106301
#%858472
#!Modern wireless communication systems require the deployment of increasingly complex protocols that satisfy tight requirements at low implementation cost, especially in terms of size and power consumption. Most protocol design methodologies currently in use are inadequate, either because they do not rely upon formal techniques and therefore do not guarantee correctness, or because they do not provide sufficient support for performance analysis and design exploration and therefore often lead to sub-optimal implementations. Therefore, we use a refinement-based formal methodology that relies upon the orthogonalization of function and architecture design and emphasizes the use of formal models to ensure correctness and reduce design time. In this paper we present a case study, the Intercom, consisting of a network of mobile terminals supporting voice communication among end users. We use this case study to validate the methodology and identify directions of further research.

#*Generating mixing hardware/software systems from SDL specifications.
#@Frank Slomka,Matthias Dörfel,Ralf Münzenberger
#t2001
#cCODES
#index106302
#%86939
#%247840
#%450607
#%197029
#%281766
#%106064
#%106009
#%858534
#%562570
#%562720
#!A new approach for the translation of SDL specifications to a mixed hardware/software system is presented. Based on the computational model of communicating extended finite state machines (EFSM) the control flow is separated from data flow of the SDL process. Hence for the first time it is possible to generate a mixed hardware/software implementation of an SDL process. This technique also reduces the complexity for high-level and register-transfer synthesis tools for the hardware parts of the system. The advantage of this methodology is shown by a design example of a wireless communication chip.

#*Schedulability analysis of heterogeneous systems for performance message sequence chart.
#@Frank Slomka,Jürgen Zant,Lennard Lambert
#t1998
#cCODES
#index106303
#%106054
#%106293
#%1275328

#*Fast processor core selection for WLAN modem using mappability estimation.
#@Juha-Pekka Soininen,Jari Kreku,Yang Qu,Martti Forsell
#t2002
#cCODES
#index106304
#%805630
#%858040
#%143045
#%1135035
#%134030
#%52282
#%141594
#!Mappability metric and a novel method for evaluating the goodness of processor core and algorithm combinations are introduced. The new mappability concept is an addition to performance and cost metrics used in existing codesign and system synthesis approaches. The mappability estimation is based on the analysis of the correlation or similarity of algorithm and core architecture characteristics. It allows fast design space exploration of core architectures and mappings with little modeling effort. The method is demonstrated by analyzing suitable processor core architectures for baseband algorithms of the WLAN modem. 140400 architecture-algorithm pairs were analyzed in total and the estimated results were similar to the results of more detailed evaluations. The method is not, however, limited to the WLAN modem, but is applicable for digital signal processing in general.

#*Deriving process networks from weakly dynamic applications in system-level design.
#@Todor Stefanov,Ed F. Deprettere
#t2003
#cCODES+ISSS
#index106305
#%106203
#%132734
#%106352
#%450530
#%282599
#%77
#!We present an approach to the automatic derivation of executable Process Network specifications from Weakly Dynamic Applications. We introduce the notions of Dynamic Single Assignment Code, Approximated Dependence Graph, and Linearly Bounded Sets to model and capture weakly dynamic (data-dependent) behavior of applications at the task-level of abstraction. Process Networks are simple parallel processing models that match the emerging multi-processor architectures in the sense that the mapping of Process Network specifications of applications onto multi-processor architectures can be done in a systematic and transparent way.

#*Algorithmic transformation techniques for efficient exploration of alternative application instances.
#@Todor Stefanov,Bart Kienhuis,Ed F. Deprettere
#t2002
#cCODES
#index106306
#%548262
#%106201
#%106203
#%282599
#%1165826
#%2346
#!Following the Y-chart paradigm for designing a system, an application and an architecture are modeled separately and mapped onto each other in an explicit design step. Next, a performance analysis for alternative application instances, architecture instances and mappings has to be done, thereby exploring the design space of the target system. Deriving alternative application instances is not trivially done. Nevertheless, many instances of a single application exist that are worth to be derived for exploration. In this paper, we present algorithmic transformation techniques for systematic and fast generation of alternative application instances that express task-level concurrency hidden in an application in some degree of explicitness. These techniques help a system designer to speedup significantly the design space exploration process.

#*Hardware/software partitioning of software binaries: a case study of H.264 decode.
#@Greg Stitt,Frank Vahid,Gordon McGregor,Brian Einloth
#t2005
#cCODES+ISSS
#index106307
#%283199
#%133988
#%132357
#%1111792
#%143078
#%203491
#%106053
#!We describe results of a case study whose intent was to determine whether new techniques for hardware/software partitioning of an application's binary are competitive with partitioning at the C source code level. While such competitiveness has been shown previously for standard benchmark suites involving smaller or unoptimized applications, the case study instead focuses on a complete 16,000-line highly-optimized commercial-grade application, namely an H.264 video decoder. The several month study revealed that binary partitioning was indeed competitive, achieving nearly identical 2.5x speedups as source level partitioning, compared to a standard microprocessor. Furthermore, the study revealed that several simple C-level coding modifications, including pass by value-return, function specialization, algorithmic specialization, hardware-targeted reimplementation, global array elimination, hoisting and sinking of error code, and conversion to explicit control flow, could lead to improved application speedups approaching 7x for both source level and binary level partitioning.

#*Scheduling hardware/software systems using symbolic techniques.
#@Karsten Strehl,Lothar Thiele,Dirk Ziegenbein,Rolf Ernst,Jürgen Teich
#t1999
#cCODES
#index106308
#%1078390
#%281960
#%282243
#%283204
#%143084
#%106380
#%283499

#*Flexible modeling environment for embedded systems design.
#@Shailesh Sutarwala,Pierre G. Paulin
#t1994
#cCODES
#index106309
#%86959
#%1166089
#%499322
#!The integration of hardware and software is perhaps the most important issue of embedded systems design. The software content of these systems is increasing in complexity which makes the code verification an important issue. Moreover, If the software development is to proceed in parallel with the hardware design, a simulation model representing the hardware behavior is needed. In this paper we describe a strategy for modeling the behavior of instruction set processors. The proposed strategy allows for retargetability and cycle true simulation with practically acceptable speed. The approach allows for very flexible timing annotations so that complex instruction sets with data dependant or addressing mode dependant timing can be modeled. The cycle true behavior allows the model to be embedded into its environment so that the system operation can be verified. The approach is seen as an improvement over a stand alone, hard-coded models since being retargetable, it requires a fraction of the development time.

#*A HW/SW co-design environment for multi-media equipments development using inverse problem.
#@Fumio Suzuki,Hisao Koizumi,M. Hiramine,K. Yamamoto,Hiroto Yasuura,K. Okino
#t1997
#cCODES
#index106310
#!Multimedia equipment development must provide functions that are adjusted to human sensibilities. Realization of such functions depends on how the three transfer levels of perception, recognition and susceptibility are handled. In this paper, we deal with perception by employing an inverse problem to characterize the system and correctly reproduce signals. To accommodate recognition and susceptibility, we propose an optimization method in which results are compared repeatedly with a model of human recognition characteristics. With respect to system response, numerical models, filter design, playback, evaluation, cost and performance estimates when implemented as semiconductor circuits, and generation of a netlist for semiconductor production, we propose an environment for hardware/software (HW/SW) co-design and development based on four steps which make possible comprehensive, systematic development and design, from the conceptual stage through to production. A procedure for solving the inverse problem is incorporated in the four areas of this environment, which are interconnected and efficiently linked to the development process, so that the overall development cycle can be shortened. This proposal was applied to the development of a television receiver and audio circuitry, and its effectiveness was confirmed.

#*Pruning-based energy-optimal device scheduling for hard real-time systems.
#@Vishnu Swaminathan,Krishnendu Chakrabarty
#t2002
#cCODES
#index106311
#%281951
#%282355
#%282376
#%645479
#%282718
#%436890
#%132986
#%613276
#%133636
#%283137
#%283160
#%52905
#%106312
#!Dynamic Power Management (DPM) provides a simple, elegant and flexible method for reducing energy consumption in embedded real-time systems. However, I/O-centric DPM techniques have been studied largely for non-real-time environments. We present an offline device scheduling technique for real-time systems that generates an energy-optimal device schedule for a given task set while guaranteeing that all real-time deadlines are met. Our method takes as inputs a task set and a device-usage list for each task, and it schedules the tasks such that the energy consumed by the set of I/O devices is minimized. We compare our algorithm to an exhaustive enumeration method and show that the proposed algorithm is very efficient in terms of memory usage and computation time. We also present case studies to show that I/O-centric DPM methods can result in significant energy savings.

#*Dynamic I/O power management for hard real-time systems.
#@Vishnu Swaminathan,Krishnendu Chakrabarty,S. Sitharama Iyengar
#t2001
#cCODES
#index106312
#%436890
#%106138
#%282292
#%282355
#%52905
#!Power consumption is an important design parameter for embedded and portable systems. Software-controlled (or dynamic) power management (DPM) has recently emerged as an attractive alternative to inflexible hardware solutions. DPM for hard real-time systems has received relatively little attention. In particular, energy-driven I/O device scheduling for real-time systems has not been considered before. We present the first online DPM algorithm, which we call Low Energy Device Scheduler (LEDES), for hard real-time systems. LEDES takes as inputs a predetermined task schedule and a device-usage list for each task and it generates a sequence of sleep/working states for each device. It guarantees that real-time constraints are not violated and it also minimizes the energy consumed by the I/O devices used by the task set. LEDES is energy-optimal under the constraint that the start times of the tasks are fixed. We present a case study to show that LEDES can reduce energy consumption by almost 50%.

#*Grand challenges in embedded systems.
#@Janos Sztipanovits,C. John Glossner,Trevor N. Mudge,Chris Rowen,Alberto L. Sangiovanni-Vincentelli,Wayne Wolf,Feng Zhao
#t2005
#cCODES+ISSS
#index106313
#!Among the many directions of IT, the most pervasive is the fusion of information processing with physical processes - called embedded computing. It is the basic engine of innovation and source of competitiveness for broad range of industrial sectors from automotive to telecommunications and from aerospace to manufacturing. Embedded computing transforms products, creates new markets and disrupts the status quo. Embedded computing is rapidly taking over the role of being the universal system integrator for physical systems.Prominent leaders of industrial and academic R&D organizations will discuss the consistency between present and future application challenges as seen by industry and dominating research challenges as conceived by academia.

#*A constructive algorithm for memory-aware task assignment and scheduling.
#@Radoslaw Szymanek,Krzysztof Kuchcinski
#t2001
#cCODES
#index106314
#%1493486
#%106214
#%106149
#%142290
#%1166072
#%450531
#%106020
#%450544
#!This paper presents a constructive algorithm for memory-aware task assignment and scheduling, which is a part of the prototype system MATAS. The algorithm is well suited for image and video processing applications which have hard memory constraints as well as constraints on cost, execution time, and resource usage. Our algorithm takes into account code and data memory constraints together with the other constraints. It can create pipelined implementations. The algorithm finds a task assignment, a schedule, and data and code memory placement in memory. Infeasible solutions caused by memory fragmentation are avoided. The experiments show that our memory-aware algorithm reduces memory utilization comparing to greedy scheduling algorithm which has time minimization objective. Moreover, memory-aware algorithm is able to find task assignment and schedule when time minimization algorithm fails. MATAS can create pipelined implementations, therefore the design throughput is increased.

#*Task response time optimization using cost-based operation motion.
#@Bassam Tabbara,Abdallah Tabbara,Alberto L. Sangiovanni-Vincentelli
#t2000
#cCODES
#index106315
#%77
#%588561
#%1123551
#%1123660
#%774398
#%542890
#!We present a technique for task response time improvement based on the concept of code motion from the software domain. Relaxed Operation Motion (ROM) is a simple yet powerful approach for performing safe and useful operation motion from heavily executed portions of a design task to less visited segments. We introduce here our algorithm, how it differs from other code motion approaches, and its application to the embedded systems domain. Results of our investigation indicate that cost-guided operation motion has the potential to improve task response time significantly.

#*An evolutionary approach to system-level synthesis.
#@Jürgen Teich,Tobias Blickle,Lothar Thiele
#t1997
#cCODES
#index106316
#%106003
#%858044
#%1135005
#%134133
#!Considers system-level synthesis as the problem of optimally mapping a task-level specification onto a heterogeneous hardware/software architecture. This problem requires: (1) the selection of the architecture (allocation), including general-purpose and dedicated processors, ASICs, buses and memories; (2) the mapping of the algorithm onto the selected architecture in space (binding) and time (scheduling); and (3) the design space exploration, with the goal of finding a set of implementations that satisfy a number of constraints on cost and performance. In this paper, a new graph-based mapping model is introduced to specify the task of system-level synthesis as an optimization problem. An evolutionary algorithm is adapted to solve this problem and is applied to explore the design space of video-codec implementations.

#*3D exploration of software schedules for DSP algorithms.
#@Jürgen Teich,Eckart Zitzler,Shuvra S. Bhattacharyya
#t1999
#cCODES
#index106317
#%1165676
#%550369

#*Improving superword level parallelism support in modern compilers.
#@Christian Tenllado,Luis Piñuel,Manuel Prieto,Francisco Tirado,Francky Catthoor
#t2005
#cCODES+ISSS
#index106318
#%542704
#%9847
#%1125196
#%808259
#%252743
#!Multimedia vector instruction sets are becoming ubiquitous in most of the embedded systems used for multimedia, networking and communications. However, current compiler technology do not allow for an efficient exploitation of the inherent data parallelism available in many signal processing and multimedia applications. In this paper, we have explored the automatic vectorization of embedded applications. In particular, we have focused on algorithms in which the same computations are applied over a set of signals that are being processed simultaneously. Usually this set of signals is represented as a 2D array in which each row is an input signal that has to be filtered in some way. A motivating example, inspired by VoIP processing, illustrates that state-of-the-art vectorizing compilers inefficiently exploit the data parallelism inherent to this kind of applications. One of the main reasons behind this, is that they present inner loops that carry all the dependencies and external loops with strided memory accesses.We propose a modification of the Superword Level Parallelism (SLP) compiler, proposed in [9], that tries to overcome these problems. Experimental results show that our approach clearly outperforms commercial compilers.

#*CASTLE: an interactive environment for HW-SW Co-Design.
#@Markus Theißinger,Paul Stravers,Holger Veit
#t1994
#cCODES
#index106319
#%1074561
#%858044
#%132209
#!We introduce CASTLE, a design environment for embedded systems. Starting from an algorithmic specification in C++/VHDL, CASTLE helps a designer to quickly find a suitable, cost-effective implementation of his system. The designer manually partitions the algorithmic specification into hardware and software components and refines the hardware architecture step by step. CASTLE provides immediate feed-back by displaying the feasibility and consequences of each partitioning decision. After partitioning, CASTLE automatically outputs the hardware and software components as VHDL and C++ programs. These can then be simulated to validate the design partitioning. Highlights of the CASTLE design environment include support for product maintenance, arbitrary hardware architectures and full design control by the designer.

#*Peer-based multithreaded executable co-specification.
#@Donald E. Thomas,JoAnn M. Paul,Simon N. Peffers,Sandra J. Weber
#t1999
#cCODES
#index106320
#%131250
#%132380
#%133546
#%1129462
#%106348

#*Modeling and evaluation of hardware/software designs.
#@Neal K. Tibrewala,JoAnn M. Paul,Donald E. Thomas
#t2001
#cCODES
#index106321
#%775896
#%133439
#%106237
#%282537
#%282905
#%833088
#%106009
#!We introduce the foundation of a system modeling environment targeted at capturing the anticipated interactions of hardware and software behaviors &mdash; not just their co-execution. Key to our approach is the separation of external and internal design testbenches. We use a frequency interleaved scheduling foundation ideally suited to our approach because it allows unrestricted hardware and software modeling, a mix of untimed and timed software, and a layered approach using software schedulers and protocols to resolve software to resource time budgets. We illustrate our approach by discussing how architectural corner cases that arise due to interacting hardware and software behaviors can be a meaningful digital modeling concept. In addition to characterizing the response of a system when viewed as a black box, we characterize the response of the design to anticipated design changes. We include examples and simulation results.

#*Program path analysis to bound cache-related preemption delay in preemptive real-time systems.
#@Hiroyuki Tomiyama,Nikil D. Dutt
#t2000
#cCODES
#index106322
#%563767
#%565275
#%565329
#%450627
#%1053194
#!Unpredictable behavior of cache memory males it difficult to statically analyze the worst-case performance of real-time systems. This problem is exacerbated in case of preemptive multitask systems due to intertask cache in terference, called Cache-Related Preemption Delay (CRPD). This paper proposes an approach to analysis of the tight upper bound on CRPD which a task might impose on lower-priority tasks. Our method determines the program execution path of the task which requires the maximum number of cache blocks using an integer linear programming technique. Experimental results show that our approach provides up to 69% tighter bounds on CRPD than a previous approach.

#*Optimal acyclic fine-grain scheduling with cache effects for embedded and real time systems.
#@Sid Ahmed Ali Touati
#t2001
#cCODES
#index106323
#%2354
#%81336
#%132151
#!To sustain the increases in processor performance, embedded and real-time systems need to find the best total schedule time when compiling their application. The optimal acyclic scheduling problem is a classical challenge which has been formulated using integer programming in lot of works. In this paper, we give a new formulation of acyclic instruction scheduling problem under registers and resources constraints in multiple instructions issuing processors with cache effects. Given a direct acyclic graph G = (V, E), the complexity of our integer linear programming model is bounded by &Ogr;(&brvbar;V&brvbar;2) variables and &Ogr;(&brvbar;E&brvbar;+&brvbar;V&brvbar;2) constraints. This complexity is better than the complexity of the existing techniques which includes a worst total schedule time factor.

#*Facilitating reuse in hardware models with enhanced type inference.
#@Manish Vachharajani,Neil Vachharajani,Sharad Malik,David I. August
#t2004
#cCODES+ISSS
#index106324
#!High-level hardware modeling is an essential, yet time-consuming, part of system design. However, effective component-based reuse in hardware modeling languages can reduce model construction time and enable the exploration of more design alternatives, leading to better designs. While component overloading and parametric polymorphism are critical for effective component-base reuse, no existing modeling language supports both. The lack of these features creates overhead for designers that discourages reuse, negating any benefits of reuse. This paper presents a type system which supports both component overloading and parametric polymorphism. It proves that performing type inference for any such system is NP-complete and presents a heuristic that works efficiently in practice. The result is a type system and type inference algorithm that can encourage reuse, reduce design specification time, and lead to better designs.

#*Modifying Min-Cut for Hardware and Software Functional Partitioning.
#@Frank Vahid
#t1997
#cCODES
#index106325
#%1495747
#%106124
#%1497931
#%106035
#%805564
#%858044
#%858146
#%193991
#%106188
#%450477
#%106216
#%450690
#%450655
#%1134995
#%106327
#%1081705
#!The Kernighan/Lin heuristic, also known as min-cut, has been extended very successfully for circuit partitioning over several decades. Those extensions customized the heuristic and its associated data structure to rapidly compute the minimum-cut metric required during circuit partitioning; thus, those extensions are not applicable to problems requiring other metrics. In this paper, we extend the heuristic for functional partitioning in a manner applicable to the codesign problem of hardware/software partitioning as well as to hardware/hardware partitioning. The extension customizes the heuristic and data structure to rapidly compute execution-time and communication metrics, crucial to hardware and software partitioning, and leads to near-linear time-complexity and excellent results. Our experiments demonstrate extremely fast execution times (just a few seconds) with results matched only by the much slower simulated annealing heuristic, meaning that the extended Kernighan/Lin heuristic will likely prove hard to beat for hardware and software functional partitioning.

#*The case for a configure-and-execute paradigm.
#@Frank Vahid,Tony Givargis
#t1999
#cCODES
#index106326
#%203232
#%857858
#%132055
#%858150
#%858221
#%807619

#*Towards a Model for Hardware and Software Functional Partitioning.
#@Frank Vahid,Thuy Dm Le
#t1996
#cCODES
#index106327
#%1495747
#%858044
#%106188
#%193972
#%193991
#%858146
#%134133
#%805564
#%132791
#%106002
#%858582
#%450655
#%1134995
#!We describe a model that supports the functional partitioning of a system-level functional specification among hardware and software components. The model includes only the information needed by partitioning, and thus can be communicated freely and generated automatically. Based on characteristics of several real examples, we describe a technique for automatically generating generic model instances, on which partitioning heuristics can be applied and fairly compared. Such comparisons will become increasingly important as research begins to focus on fast yet effective functional partitioning techniques. We describe a set of tools for converting a specification to the model, for generating generic model instances, and for applying and comparing partitioning heuristics, available via ftp. Use of these tools may greatly reduce duplicated efforts among researchers wishing to investigate hardware/software partitioning heuristics.

#*An Object-Oriented Communication Library for Hardware-Software CoDesign.
#@Frank Vahid,Linus Tauro
#t1997
#cCODES
#index106328
#%858582
#%281938
#%134163
#%1135081
#%133370
#!Implementing communication between hardware and software components can be a time-consuming task. Numerous communication protocols are available, differing greatly in their implementation details. Designers must spend much time focusing on those details. Even when libraries are available to encapsulate communication into C or VHDL routines, these routines are not consistent across protocols, making it difficult to switch to other protocols. In this paper, we propose an object-oriented communication library, which provides pre-implemented channel-based send/receive communication primitives, allowing easy implementation and seamless migration across protocols and components.

#*Hardware/software partitioning of embedded system in OCAPI-xl.
#@Geert Vanmeerbeeck,Patrick Schaumont,Serge Vernalde,Marc Engels,Ivo Bolsens
#t2001
#cCODES
#index106329
#%141313
#%133805
#%92
#!The implementation of embedded networked appliances requires a mix of processor cores and HW accelerators on a single chip. When designing such complex and heterogeneous SoCs, the HW / SW partitioning decision needs to be made prior to refining the system description. With OCAPI-xl, we developed a methodology in which the partitioning decision can be made anywhere in the design flow, even just prior to doing code-generation for both HW and SW. This is made possible thanks to a refinable, implementable, architecture independent system description. The OCAPI-xl model was used to develop a stand alone, networked camera, with on-board GIF engine and network layer.

#*Symbolic model checking of Dual Transition Petri Nets.
#@Mauricio Varea,Bashir M. Al-Hashimi,Luis Alejandro Cortés,Petru Eles,Zebo Peng
#t2002
#cCODES
#index106330
#%24939
#%633
#%698
#%1117804
#%132719
#%143187
#!This paper describes the formal verification of the recently introduced Dual Transition Petri Net (DTPN) models [12], using model checking techniques. The methodology presented addresses the symbolic model checking of embedded systems behavioural properties, expressed in either computation tree logics (CTL) or linear temporal logics (LTL). The embedded system specification is given in terms of DTPN models, where elements of the model are captured in a four-module library which implements the behaviour of the model. Key issues in the development of the methodology are the heterogeneity and the nondeterministic nature of the model. This is handled by introducing some modifications in both structure and behaviour of the model, thus reducing the points of nondeterminism. Several features of the methodology are discussed and two examples are given in order to show the validity of the model.

#*SOMA: a tool for synthesizing and optimizing memory accesses in ASICs.
#@Girish Venkataramani,Tiberiu Chelcea,Seth Copen Goldstein,Tobias Bjerregaard
#t2005
#cCODES+ISSS
#index106331
#%234294
#%55089
#%86492
#%134482
#%141931
#%106265
#%450639
#%133843
#%1135393
#%450632
#%134162
#%282459
#%499311
#%55081
#%214690
#%1056858
#%52445
#%105987
#%1117814
#%133018
#%133222
#!Arbitrary memory dependencies and variable latency memory systems are major obstacles to the synthesis of large-scale ASIC systems in high-level synthesis. This paper presents SOMA, a synthesis framework for constructing Memory Access Network (MAN) architectures that inherently enforce memory consistency in the presence of dynamic memory access dependencies. A fundamental bottleneck in any such network is arbitrating between concurrent accesses to a shared memory resource. To alleviate this bottleneck, SOMA uses an application-specific concurrency analysis technique to predict the dynamic memory parallelism profile of the application. This is then used to customize the MAN architecture. Depending on the parallelism profile, the MAN may be optimized for latency, throughput or both. The optimized MAN is automatically synthesized into gate-level structural Verilog using a flexible library of network building blocks. SOMA has been successfully integrated into an automated C-to-hardware synthesis flow, which generates standard cell circuits from unrestricted ANSI-C programs. Post-layout experiments demonstrate that application specific MAN construction significantly improves power and performance.

#*Dynamic overlay of scratchpad memory for energy minimization.
#@Manish Verma,Lars Wehmeyer,Peter Marwedel
#t2004
#cCODES+ISSS
#index106332
#!The memory subsystem accounts for a significant portion of the aggregate energy budget of contemporary embedded systems. Moreover, there exists a large potential for optimizing the energy consumption of the memory subsystem. Consequently, novel memories as well as novel algorithms for their efficient utilization are being designed. Scratchpads are known to perform better than caches in terms of power, performance, area and predictability. However, unlike caches they depend upon software allocation techniques for their utilization. In this paper, we present an allocation technique which analyzes the application and inserts instructions to dynamically copy both code segments and variables onto the scratchpad at runtime. We demonstrate that the problem of dynamically overlaying scratchpad is an extension of the Global Register Allocation problem. The overlay problem is solved optimally using ILP formulation techniques. Our approach improves upon the only previously known allocation technique for statically allocating both variables and code segments onto the scratchpad. Experiments report an average reduction of 34% and 18% in the energy consumption and the runtime of the applications, respectively. A minimal increase in code size is also reported.

#*Extended design reuse trade-offs in hardware-software architecture mapping.
#@Frederik Vermeulen,Francky Catthoor,Diederik Verkest,Hugo De Man
#t2000
#cCODES
#index106333
#%131941
#%106326
#%132601
#%1135007
#%1135094
#%282663
#%193842
#%142703
#%805580
#%1125892
#%9858
#!In the design of embedded systems-on-chip, the success of a product generation depends on the flexibility to accommodate future design changes. This requirement influences the hardware-software partitioning strategy Therefore we propose a novel hardware-software architecture and mapping methodology, which provide new trade-off opportunities for cost-effective component reuse.

#*The TACO protocol processor simulation environment.
#@Seppo Virtanen,Johan Lilius
#t2001
#cCODES
#index106334
#%106265
#!Network hardware design is becoming increasingly challenging because more and more demands are put on network bandwidth and throughput requirements, and on the speed with which new devices can be put on the market. Using current standard techniques (general purpose microprocessors, ASIC's) these goals are difficult to reach simultaneously. One solution to this problem that has recently attracted interest is the design of programmable processors with network-optimized hardware, that is, network or protocol processors. In this paper a simulation framework for a family of TTA protocol processor architectures is proposed. The protocol processors consist of a number of buses with functional units that encapsulate protocol specific operations. The TACO protocol processor simulator is a C++ framework based on SystemC. Functional units are created as C++ classes, which makes it easy to experiment with different configurations of the processor to see its performance.

#*Trade-offs in the design of mixed hardware-software systems-a perspective from industry.
#@Kees A. Vissers
#t1997
#cCODES
#index106335
#!Many systems in the field of consumer electronics devices and computers consist of a hardware platform and of software running on that platform. In the design of these systems many trade-offs have to be made. In the design of the hardware platform trade-offs have to be made between programmable components and dedicated components. The programming of the hardware platform also contains many trade-offs. Here a "software architecture" needs to be developed that spans several layers, using well defined interfaces, e.g. application programming interfaces (APIs). The software contains often device drivers, an operating system, and end-user applications. In embedded systems the end-user can often not program the system directly, e.g. one cannot program the look and feel or contents of the on-screen display of your TV. In practical situations system design is based on many constraints, and seldom starts from scratch. The hardware interface to the system can be given, the models of processors that can be used can be limited, and software interfaces can be required. The trade-offs are in the hardware platform design and in the software design.

#*Implications of Codesign as a Natural Constituent of a Systems Engineering Discipline for Computer Based Systems.
#@Markus Voss,Oliver Hammerschmidt
#t1996
#cCODES
#index106336
#%192345
#%192298
#%106337
#%192165
#%41833
#!Within this paper we argue that Hardware/Software Codesign must first of all be regarded as an important but nevertheless subordinate part of a disciplined procedure of engineering computer based systems in general. Defining so a set of consequences result the discussion of which is this contribution's major concern. In this paper we first present the contents of a discipline of engineering of computer based systems and elaborate on the special meaning of design in general and codesign in particular within that frame. We will then sketch some typical codesign problems arising when defining reusable specifications for basic services to make up a baseline component infrastructure for open systems architectures and present solutions for the special case of measurement, actuation, and control services using the case study of a production cell automation as an example. Last we will comment on some lessons we think can be learned from this discourse.

#*Towards a theory for hardware/software codesign.
#@Markus Voss,Tarek Ben Ismail,Ahmed Amine Jerraya,Karl-Heinz Kapp
#t1994
#cCODES
#index106337
#%192345
#!This paper aims at a theory for hardware/software codesign. We approach this goal by investigating system design according to the allocation principle which is a systems engineering approach to mixed hardware/software systems design. The associated process steps are system-level design including partitioning and communication synthesis by channel mapping and binding. A strengthened system-level design and synthesis process makes codesign with delayed technology dependent partitioning possible. In addition we investigate possibilities for automating these processes by tool support.

#*Design-For-Debug in Hardware/Software Co-Design.
#@Harald P. E. Vranken,M. P. J. Stevens,M. T. M. Segers
#t1997
#cCODES
#index106338
#%806821
#%858067
#%454421
#%1071593
#%456278
#%858619
#%555495
#!The increasing complexity of hardware/software systems is handled effectively by hardware/software codesign methods. However, the debugging of hardware/software systems is still a very troublesome process. This is mainly due to the limited accessibility to the internals of embedded hardware/software systems. Debugging is also hindered by the nature of the design errors encountered during hardware/software debugging.We present a structured design-for-debug strategy to address the problems of hardware/software debugging. Our design-for-debug strategy is an integral part of hardware/software codesign. Furthermore, we re-use the hardware design-for-test facilities to reduce the overhead costs of design-for-debug. Two examples are provided to illustrate our design-for-debug strategy.

#*Enabling unrestricted automated synthesis of portable hardware accelerators for virtual machines.
#@Miljan Vuletic,Christophe Dubach,Laura Pozzi,Paolo Ienne
#t2005
#cCODES+ISSS
#index106339
#%132090
#%1135393
#%805889
#%203410
#%134195
#%858620
#!The performance of virtual machines (e.g., Java Virtual Machines---JVMs) can be significantly improved when critical code sections (e.g., Java bytecode methods) are migrated from software to reconfigurable hardware. In contrast to the compile-once-run-anywhere concept of virtual machines, reconfigurable applications lack portability and transparent SW/HW interfacing: applicability of accelerated hardware solutions is often limited to a single platform. In this work, we apply a virtualisation layer that provides portable and seamless integration of hardware and software components to a Java Virtual Machine platform, making it capable of accelerating any Java bytecode method by using platform-independent hardware accelerators. The virtualisation layer not only improves portability of accelerated Java bytecode applications, but also supports runtime optimisations and enables unrestricted automated synthesis of arbitrary Java bytecode to hardware. To show the advantages and measure the limited overheads of our approach, we run several accelerated applications (handwritten and synthesised) on a real embedded platform. We also show our synthesis flow and discuss its advanced features fostered by the virtualisation layer.

#*Synthesizing operating system based device drivers in embedded systems.
#@Shaojie Wang,Sharad Malik
#t2003
#cCODES+ISSS
#index106340
#%131961
#%450616
#%143247
#%141925
#!This paper presents a correct-by-construction synthesis method for generating operating system based device drivers from a formally specified device behavior model. Existing driver development is largely manual using an ad-hoc design methodology. Consequently, this task is error prone and becomes a bottleneck in embedded system design methodology.Our solution to this problem starts by accurately specifying device access behavior with a formal model, viz. extended event driven finite state machines. We state easy to check soundness conditions on the model that subsequently guarantee properties such as bounded execution time and deadlock-free behavior. We design a deadlock-free resource accessing scheme for our device access model. Finally, we synthesize an operating system (OS) based event processing mechanism, which is the core of the device driver, using a disciplined methodology that assures the correctness of the resulting driver.We validate our synthesis method using two case studies: an infrared port and the USB device controller for an SA1100 based handheld. Besides assuring a correct-by -construction driver, the size of the specification is 70% smaller than a manually written driver, which is a strong indicator of improved design productivity.

#*Using minimal minterms to represent programmability.
#@Scott J. Weber,Kurt Keutzer
#t2005
#cCODES+ISSS
#index106341
#%1496132
#%142020
#%106342
#!We address the problem of formally representing the programmability of a system. We define the programmability of a system as the set of valid execution paths that can be configured statically by software. We formally represent this programmability as a Boolean function. From this representation, we extract a subset of on-set minterms that we call minimal minterms. We prove that these minimal minterms represent the set of smallest schedulable atomic actions of the system, and that we can use a special generator relation to determine if subsets of these actions can be executed in parallel. We also prove that given an arbitrary Boolean function we can extract the minimal minterms and recreate the entire on-set by applying the generator relation to every element of the power set of the set of minimal minterms. Thus, the minimal minterms represent the complete instruction set supported by the system, and the generator relation represents the inherent parallelism among the instructions. Furthermore, we automatically generate the required software development tools and hardware implementation from this representation of programmability. Finally, we show that we can efficiently compute the minimal minterms and apply the generator relation to verify parallel executions on interesting data path systems.

#*Fast cycle-accurate simulation and instruction set generation for constraint-based descriptions of programmable architectures.
#@Scott J. Weber,Matthew W. Moskewicz,Matthias Gries,Christian Sauer,Kurt Keutzer
#t2004
#cCODES+ISSS
#index106342
#!State-of-the-art architecture description languages have been successfully used to model application-specific programmable architectures limited to particular control schemes. In this paper, we introduce a language and methodology that provide a framework for constructing and simulating a wider range of architectures. The framework exploits the fact that designers are often only concerned with data paths, not the instruction set and control. In the framework, each processing element is described in a structural language that only requires the specification of the data path and constraints on how it can be used. From such a description, the supported operations of the processing element are automatically extracted and a controller is generated. Various architectures are then realized by composing the processing elements. Furthermore, hardware descriptions and bit-true cycle-accurate simulators are automatically generated. Results show that our simulators are up to an order of magnitude faster than other reported simulators of this type and two orders of magnitude faster than equivalent Verilog simulations.

#*HW/SW partitioning of an embedded instruction memory decompressor.
#@Shlomo Weiss,Shay Beren
#t2001
#cCODES
#index106343
#%499323
#%890976
#!We introduce a new PLA-based decoder architecture for random-access run-time decompression of compressed instruction memory in embedded systems. The compression method employs class-based coding. We show that this new decoder architecture can be extended to provide high throughput decompression. The design of the decompressor is based on the following HW/SW tradeoff: decoding is done in hardware to provide high throughput, yet the codebook used for decompression is fully programmable.

#*Developing design tools for biological and biomedical applications of micro- and nano-technology.
#@Jacob White
#t2005
#cCODES+ISSS
#index106344
#%132941
#%131988
#%282951
#%134088
#%132749
#%134277
#!This short paper, an update of [75], is intended to provide a brief summary and extensive references on biological applications for micro- and nano-machining, as well as the computer-aided design challenges generated by those applications.

#*Retargetable generation of TLM bus interfaces for MP-SoC platforms.
#@Andreas Wieferink,Rainer Leupers,Gerd Ascheid,Heinrich Meyr,Tom Michiels,Achim Nohl,Tim Kogel
#t2005
#cCODES+ISSS
#index106345
#%1494237
#%133044
#%131624
#%133707
#%132380
#%450564
#%645567
#%1135608
#%143275
#!In order to meet flexibility, performance and energy efficiency constraints, future SoC (System-on-Chip) designs will contain an increasing number of heterogeneous processor cores combined with a complex communication architecture. Optimal platforms are obtained by customizing both computation and communication modules to the application's needs. In our design flow both kinds of SoC modules are automatically derived from abstract specifications. This work focuses on generating the communication adaptors, which are tailored to the processor as well as to the bus side. For early system simulation, the adaptors are capable of bridging an abstraction gap by implementing a bus interface state machine. The generated processor cores, adaptors and bus nodes are applied in the exemplary design of a JPEG decoding platform.

#*Design flow for hardware/software cosynthesis of a video compression system.
#@Jörg Wilberg,Raul Camposano,Wolfgang Rosenstiel
#t1994
#cCODES
#index106346
#%86927
#%86944
#%1166080
#%132207
#%159
#%502762
#%81325
#%286968
#%858044
#%858582
#%858146
#%858145
#%282721
#%2353
#!The implementation of a cosynthesis design flow in the CASTLE system is presented. The design flow generates a synthesizable hardware description and a C, C++, or Fortran compiler for an application-oriented processor. The approach is illustrated by the design of an embedded video compression system which can be integrated into the video card of a PC. The design flow is structured as follows: First, the requirements of the application programs are analyzed. Based on these analysis results, the designer decides on the appropriate processor structure. The processor structure is entered on a block diagram level into the CASTLE system by using a schematic entry. The CASTLE system performs the processor cosynthesis based on a VHDL library of processor components. Several processor datapaths for the video compression system were synthesized to illustrate the trade-offs between flexibility and performance when designing application-oriented processors.

#*A core flight software system.
#@Jonathan Wilmot
#t2005
#cCODES+ISSS
#index106347
#!No two flight missions are alike, hence, development and on-orbit software costs are high. Software portability and adaptability across hardware platforms and operating systems has been minimal at best. Standard interfaces across applications and/or common applications are almost non-existent. To reduce flight software costs, these issues must be addressed. This presentation describes how the Flight Software Branch at Goddard Space Flight Center has architected a solution to these problems.

#*Hardware/software selected cycle solution.
#@John Wilson
#t1994
#cCODES
#index106348

#*ASDEN: a comprehensive design framework vision for automotive electronic control systems.
#@Deborah Wilson,Daniel Dayton,R. Todd Hansell
#t2000
#cCODES
#index106349
#!The automotive electronics industry is experiencing an era of unprecedented growth. Driven by emissions and safety legislation, fuel economy constraints, cost constraints, and customer demand for convenience features and enhanced performance, electronic controls are steadily replacing their mechanical and hydraulic predecessors. As the sophistication of these systems grows, their complexity has grown dramatically as well, creating difficulties in the application of traditional engineering methods to modern systems. New design paradigms, such as model-based control, have begun to emerge. These factors have created a need for more sophisticated, integrated tool sets to help support the systems engineering process and manage the designs of the new systems. The Automotive Systems Design Environment (ASDEN) project has been undertaken by Motorola to address this need for a sophisticated, capable framework of interoperable tools. This project paves the way for a future where the &ldquo;Virtual Automobile&rdquo; becomes a reality: a car designed, simulated, and &ldquo;driven&rdquo; before the first physical prototype is even built.

#*CODES and co-design: a look back and a look forward.
#@Wayne Wolf
#t2001
#cCODES
#index106350

#*Design and programming of embedded multiprocessors: an interface-centric approach.
#@Pieter van der Wolf,Erwin A. de Kock,Tomas Henriksson,Wido Kruijtzer,Gerben Essink
#t2004
#cCODES+ISSS
#index106351
#!We present design technology for the structured design and programming of embedded multi-processor systems. It comprises a task-level interface that can be used both for developing parallel application models and as a platform interface for implementing applications on multi-processor architectures. Associated mapping technology supports refinement of application models towards implementation. By linking application development and implementation aspects, the technology integrates the specification and design phases in the MPSoC design process. Two design cases demonstrate the efficient implementation of the platform interface on different architectures. Industry-wide standardization of a task-level interface can facilitate reuse of function-specific hardware / software modules across companies.

#*An MPEG-2 decoder case study as a driver for a system level design methodology.
#@Pieter van der Wolf,Paul Lieverse,Mudit Goel,David La Hei,Kees A. Vissers
#t1999
#cCODES
#index106352
#%50123
#%858144
#%410401

#*TigerSwitch: a case study in embedded computing system design.
#@Wayne Wolf,Andrew Wolfe,Steve Chinatti,Ravi Koshy,Gary Slater,Spencer Sun
#t1994
#cCODES
#index106353
#%808572
#%1072158
#!This paper describes and analyzes the design of TigerSwitch, a PC-based private branch exchange (PBX) designed at Princeton University. Building TigerSwitch required creating custom hardware and software designed to fit onto a standard IBM PC-compatible platform. Our design experience provides several lessons which we believe extend to other embedded design domains: the system architecture required to meet performance goals is often not isomorphic to the structure of the specification; system-level performance analysis is an essential part of system architecture design; architectural decisions must be made on the basis of estimates before complete implementations of the components are available; and most allocations of functions to software or custom hardware are obvious, while a few are very difficult.

#*Using codesign techniques to support analog functionality.
#@Francis G. Wolff,Michael J. Knieser,Daniel J. Weyer,Christos A. Papachristou
#t1999
#cCODES
#index106354
#%131250
#%858044
#%858146
#%858145
#%450689
#%450609

#*Task concurrency management methodology to schedule the MPEG4 IM1 player on a highly parallel processor platform.
#@Chun Wong,Paul Marchal,Peng Yang
#t2001
#cCODES
#index106355
#%106054
#%106308
#%133305
#%345541
#%450618
#%1052947
#%450609
#%283380
#%565699
#%436574
#%282292
#%131937
#%282718
#%1081894
#%806323
#%77592
#%1052923
#%141753
#!This paper addresses the concurrent task management of complex multi-media systems, like the MPEG4 IM1 player, with emphasis on how to derive energy-cost vs time-budget curves through task scheduling on a multi-processor platform. Starting from the original &ldquo;standard&rdquo; specification, we extract the concurrency originally hidden by implementation decisions in a &ldquo;grey-box&rdquo; model. Then we have applied two high-level transformations on this model to improve the task-level concurrency. Finally, by scheduling the transformed task-graph, we have derived energy-cost vs time-budget curves. These curves will be used to get globally optimized design decisions when combining subsystems into one complete system or to be used by a dynamic scheduler. The results on the MPEG4 IM1 player confirm the validity of our assumptions and the usefulness of our approach.

#*Enhanced code density of embedded CISC processors with echo technology.
#@Youfeng Wu,Mauricio Breternitz Jr.,Herbert H. J. Hum,Ramesh V. Peri,Jay Pickett
#t2005
#cCODES+ISSS
#index106356
#%146487
#%951121
#%542481
#%1123361
#%600856
#%483620
#%77463
#!Code density is an important issue in memory constrained systems. Some RISC processor, e.g. the THUMB extension in the ARM processor, supports aggressive code size reduction even at the cost of significant performance loss. In this paper, we develop an algorithm that utilizes a set of novel variable length Echo instructions and evaluate its effectiveness for IA32 binaries. Our experiments show that IA32 processor equipped with Echo instructions is capable of achieving a similar code density as the THUMB extension in the ARM instruction set with significantly lower performance penalty.

#*Energy-efficient flash-memory storage systems with an interrupt-emulation mechanism.
#@Chin-Hsien Wu,Tei-Wei Kuo,Chia-Lin Yang
#t2004
#cCODES+ISSS
#index106357
#!One of the emerging critical issues for flash-memory storage systems, especially on the implementations of many embedded systems, is on its programmed I/O nature for data transfers. Programmed-I/O-based data transfers might not only result in the wasting of valuable CPU cycles of microprocessors but also unnecessarily consume much more energy from batteries. This paper presents an interrupt-emulation mechanism for flash-memory storage systems with an energy-efficient management strategy. We propose to revise the waiting function in the Memory-Technology-Device (MTD) layer to relieve the microprocessor from busy waiting and to reduce the energy consumption of the system. We show that energy consumption could be significantly reduced with good saving on CPU cycles and minor delay on the average response time in the experiments.

#*CPU scheduling for statistically-assured real-time performance and improved energy efficiency.
#@Haisang Wu,Binoy Ravindran,E. Douglas Jensen,Peng Li
#t2004
#cCODES+ISSS
#index106358
#!We present a CPU scheduling algorithm, called Energy-efficient Utility Accrual Algorithm (or EUA), for battery-powered, embedded real-time systems. We consider an embedded software application model where repeatedly occurring application activities are subject to deadline constraints specified using step time/utility functions. For battery-powered embedded systems, system-level energy consumption is also a primary concern. We consider CPU scheduling that (1) provides assurances on individual and collective application timeliness behaviors and (2) maximizes system-level timeliness and energy efficiency. Since the scheduling problem is intractable, EUA heuristically computes CPU schedules with a polynomial-time cost. Several properties of EUA are analytically established, including timeliness optimality during under-load situations and statistical assurances on timeliness behavior. Further, our simulation results confirm EUAýs superior performance.

#*Efficient behavior-driven runtime dynamic voltage scaling policies.
#@Fen Xie,Margaret Martonosi,Sharad Malik
#t2005
#cCODES+ISSS
#index106359
#%542635
#%542919
#%418565
#%436519
#%77541
#%77637
#%613276
#%436796
#%418555
#%597322
#%646056
#%645532
#%564096
#%437192
#%141434
#%499234
#!Power consumption has long been a limiting factor in microprocessor design. In seeking energy efficiency solutions, dynamic voltage/frequency scaling (DVFS), a technique to vary voltage/frequency on the fly, has emerged as a powerful and practical power/energy reduction technique that exploits computation slack due to relaxed deadlines and memory accesses. DVFS has been implemented in some modern processors such as Intel XScale and Transmeta Crusoe. Hence the bulk of research efforts have been devoted to developing policies to detect slack and pick appropriate V/f assignments such that the energy is minimized while meeting performance requirements. Since slack is a product of memory accesses and relaxed deadlines, the number of instances and the duration of available slack are highly dependent on the runtime program behavior. Runtime DVFS policies must take into consideration program characteristics in order to achieve significant energy savings. In this paper, we characterize program behavior and classify programs in terms of the memory access behavior. We propose a runtime DVFS policy that takes into consideration the characteristics of program behavior for each category. Then we examine the efficiency of the proposed DVFS policies by comparing with previously derived upper bounds of energy savings. Results show that the proposed runtime DVFS policies approach the upper bounds of energy savings in most cases.

#*Architectural analysis and instruction-set optimization for design of network protocol processors.
#@Haiyong Xie,Li Zhao,Laxmi N. Bhuyan
#t2003
#cCODES+ISSS
#index106360
#%1122243
#%588526
#%588860
#%588713
#%597407
#%808131
#!TCP/IP protocol processing latency has been an important issue in high-speed networks. In this paper, we present an architectural study of TCP/IP protocol. We port the TCP/IP protocol stack from the 4.4 FreeBSD to the SimpleScalar simulation environment. The architectural characteristics, such as instruction level parallelism and cache behavior, are studied through simulation. We also compare the characteristics of TCP/IP protocol to that of SPECint benchmark programs. It turns out that the former is quite different from the latter due to the unique processing structure. Furthermore, in order to improve the effectiveness of instruction cache, frequent instruction pairs are analyzed, and corresponding architectural optimizations are made to the instruction set architecture. The performance is evaluated in the simulator. We find that a 23% improvement can be achieved by taking advantage of the optimization. The instruction set optimizations proposed in this paper will be helpful for the design of new programmable protocol processors in future.

#*Iterational retiming: maximize iteration-level parallelism for nested loops.
#@Chun Xue,Zili Shao,Meilin Liu,Edwin Hsing-Mean Sha
#t2005
#cCODES+ISSS
#index106361
#%773600
#%542338
#!Nested loops are the most critical sections in many scientific and Digital Signal Processing (DSP)applications.It is important to study effective and efficient transformation techniques to increase parallelism for nested loops.In this paper, we propose a novel technique,iterational retiming,that can satisfy any given timing constraint by achieving full parallelism for iterations in a partition. Theorems and efficient algorithms are proposed for iterational retiming. The experimental results show that iterational retiming is a promising technique for parallel embedded systems.It can achieve 87% improvement over software pipelining and 88%improvement over loop unfolding on average.

#*Pareto-optimization-based run-time task scheduling for embedded systems.
#@Peng Yang,Francky Catthoor
#t2003
#cCODES+ISSS
#index106362
#%1497225
#%1135294
#%132902
#%133894
#%141343
#%436647
#%436845
#%450550
#%277989
#%106020
#%283137
#%282376
#%437049
#%133896
#%133636
#%564008
#!Pareto-set-based optimization can be found in several different areas of embedded system design. One example is task scheduling, where different task mapping and ordering choices for a target platform will lead to different performance/cost tradeoffs. To explore this design space at run-time, a fast and effective heuristic is needed. We have modeled the problem as the well known Multiple Choice Knapsack Problem(MCKP) and have developed a fast greedy heuristic for the run-time task scheduling. To show the effectiveness of our algorithm, examples from randomly generated task graphs and realistic applications are studied. Compared to the optimal dynamic programming solver, the heuristic is more than ten times faster while the result is less than 5\% away from the optimum. Moreover, due to its iterative feature, the algorithm is well suitable to be used as an on-line algorithm.

#*CRAMES: compressed RAM for embedded systems.
#@Lei Yang,Robert P. Dick,Haris Lekatsas,Srimat T. Chakradhar
#t2005
#cCODES+ISSS
#index106363
#%1073810
#%132912
#%141311
#%410622
#%85565
#!Memory is a scarce resource in many embedded systems. Increasing memory often increases packaging and cooling costs, size, and energy consumption. This paper presents CRAMES, an efficient software-based RAM compression technique for embedded systems. The goal of CRAMES is to dramatically increase effective memory capacity without hardware design changes, while maintaining high performance and low energy consumption. To achieve this goal, CRAMES takes advantage of an operating system's virtual memory infrastructure by storing swapped-out pages in compressed format. It dynamically adjusts the size of the compressed RAM area, protecting applications capable of running without it from performance or energy consumption penalties. In addition to compressing working data sets, CRAMES also enables efficient in-RAM filesystem compression, thereby further increasing RAM capacity. CRAMES was implemented as a loadable module for the Linux kernel and evaluated on a battery-powered embedded system. Experimental results indicate that CRAMES is capable of doubling the amount of RAM available to applications. Execution time and energy consumption for a broad range of examples increase only slightly, by averages of 0.35% and 4.79%. In addition, this work identifies the software-based compression algorithms that are most appropriate for low-power embedded systems.

#*Power optimization for universal hash function data path using divide-and-concatenate technique.
#@Bo Yang,Ramesh Karri
#t2005
#cCODES+ISSS
#index106364
#%133970
#%217159
#%1134497
#%143323
#%134369
#!We present an architecture level low power design technique called divide-and-concatenate for universal hash functions based on the following observations: (i) the power consumption of a w-bit array multiplier and associated universal hash data path decreases as O(w4) if its clock rate remains constant. (ii) two universal hash functions are equivalent if they have the same collision probability property. In the proposed approach we divide a w-bit data path (with collision probability 2-w) into two/four w/2-bit data paths (each with collision probability 2-w/2) and concatenate their results to construct an equivalent w-bit data path (with a collision probability 2-w). A popular low power technique that uses parallel data paths saves 62.10% dynamic power consumption incurring 102% area overhead. In contrast, the divide-and-concatenate technique saves 55.44% dynamic power consumption with only 16% area overhead.

#*Microcoded coprocessor for embedded secure biometric authentication systems.
#@Shenglin Yang,Patrick Schaumont,Ingrid Verbauwhede
#t2005
#cCODES+ISSS
#index106365
#%83939
#%143146
#!We design and implement a cryptographic biometric authentication system using a microcoded architecture. The secure properties of the biometric matching process are obtained by means of a fuzzy vault scheme. The algorithm is implemented in a reprogrammable, microcoded coprocessor called FV16. We present the micro-architecture of FV16 as well as a dedicated assembler for this architecture. Our coprocessor can be attached to an ARM processor, and offers a 83-fold cycle count improvement when the fuzzy vault algorithm is migrated from embedded ARM software (13.8 million cycles) to the FV16 coprocessor (166 thousand cycles).

#*Virtual synchronization technique with OS modeling for fast and time-accurate cosimulation.
#@Youngmin Yi,Dohyung Kim,Soonhoi Ha
#t2003
#cCODES+ISSS
#index106366
#%143319
#%450469
#%134441
#%106367
#%133546
#%562618
#!Hardware/Software cosimulation is the key process to shorten the design turn around time. We have proposed a novel technique, called virtual synchronization, for fast and time accurate cosimulation that involves interacting component simulators. In this paper, we further extend the virtual synchronization technique with OS modeling for the case where multiple software tasks are executed under the supervision of a real-time operating system. The OS modeler models the RTOS overheads of context switching and tick interrupt handling as well as preemption behavior. While maintaining the timing accuracy to an acceptable level below a few percents, we could reduce the simulation time drastically compared with existent conservative approach by removing the need of time synchronization between simulators. It is confirmed with a preliminary experiment with a multimedia example that consists of four real-life tasks.

#*Optimistic distributed timed cosimulation based on thread simulation model.
#@Sungjoo Yoo,Kiyoung Choi
#t1998
#cCODES
#index106367
#%52283
#%282024
#%143100
#%282813
#%343281
#%565231


#*Optimizing geographically distributed timed cosimulation by hierarchically grouped messages.
#@Sungjoo Yoo,Kiyoung Choi
#t1999
#cCODES
#index106368
#%132381
#%106367

#*A generic wrapper architecture for multi-processor SoC cosimulation and design.
#@Sungjoo Yoo,Gabriela Nicolescu,Damien Lyonnard,Amer Baghdadi,Ahmed Amine Jerraya
#t2001
#cCODES
#index106369
#%106137
#%142431
#%132842
#%131540
#%142344
#%134163
#%133702
#%132381
#%133707
#%132380
#%282064
#%282563
#%52896
#%52279
#%133010
#%142632
#%141363
#!In communication refinement with multiple communication protocols and abstraction levels, the system specification is described by heterogeneous components in terms of communication protocols and abstraction levels. To adapt each heterogeneous component to the other part of system, we present a generic wrapper architecture that can adapt different protocols or different abstraction levels, or both. In this paper, we give a detailed explanation of applying the generic wrapper architecture to mixed-level cosimulation. As preliminary experiments, we applied it to mixed-level cosimulation of an IS-95 CDMA cellular phone system.

#*Performance estimation of multiple-cache IP-based systems: case study of an interdependency problem and application of an extended shared memory model.
#@Sungjoo Yoo,Kyoungseok Rha,Youngchul Cho,Jinyong Jung,Kiyoung Choi
#t2000
#cCODES
#index106370
#%142312
#%282565
#%645445
#%132842
#%1079630
#%597633
#%596821
#%132274
#%106056
#%282163
#%450574
#%106252
#!In estimating the performance of multiple-cache IP-based systems, we face a problem of interdependency between cache configuration and system behavior. In this paper, we investigate the effects of the interdependency on system performance in a case study. We present a method that gives fast and accurate estimation of system performance by simulating IP cores at the behavioral level with annotated delays and by simulating the multiple-cache communication architecture with an extended shared memory model. Experiments show the effectiveness of the proposed method.

#*RTOS scheduling in transaction level models.
#@Haobo Yu,Andreas Gerstlauer,Daniel Gajski
#t2003
#cCODES+ISSS
#index106371
#%131879
#%131961
#%450592
#%141925
#%141917
#!Raising the level of abstraction in system design promises to enable faster exploration of the design space at early stages. While scheduling decision for embedded software has great impact on system performance, it's much desired that the designer can select the right scheduling algorithm at high abstraction levels so as to save him from the error-prone and time consuming task of tuning code delays or task priority assignments at the final stage of system design. In this paper we tackle this problem by introducing a RTOS model and an approach to refine any unscheduled transaction level model (TLM) to a TLM with RTOS scheduling support. The refinement process provides a useful tool to the system designer to quickly evaluate different dynamic scheduling algorithms and make the optimal choice at the early stage of system design.

#*An efficient direct mapped instruction cache for application-specific embedded systems.
#@Chuanjun Zhang
#t2005
#cCODES+ISSS
#index106372
#%132243
#%436851
#%436925
#%419661
#%499311
#%53809
#%419005
#!Caches may consume half of a microprocessor's total power and cache misses incur accessing off-chip memory, which is both time consuming and energy costly. Therefore, minimizing cache power consumption and reducing cache misses are important to reduce total energy consumption of embedded systems. Direct mapped caches consume much less power than that of same sized set associative caches but with a poor hit rate on average. Through experiments, we observe that memory space of direct mapped instruction caches is not used efficiently in most embedded applications. We design an efficient cache - a configurable instruction cache that can be tuned to utilize the cache sets efficiently for a particular application such that cache memory is exploited more efficiently by index remapping. Experiments on 11 benchmarks drawn from Mediabench show that the efficient cache achieves almost the same miss rate as a conventional two-way set associative cache on average and with total memory-access energy savings of 30% compared with a conventional two-way set associative cache.

#*Programming embedded networked sensor systems.
#@Feng Zhao,Jie Liu,Jim Reich,Maurice Chu,Juan Liu
#t2003
#cCODES+ISSS
#index106373
#!This talk describes a state-centric abstraction for application users to interact with sensor networks. Just as in data-centric routing and storage where physical nodes are less important than the data itself, state-centric abstraction introduces "states" as a natural vocabulary to describe spatio-temporal physical phenomena that the sensor networks are typically designed for. Application programmers specify the computation as creation, sharing, and transformation of states, which naturally map to descriptions in signal processing and control applications. We argue that due to the dynamic nature of sensor networks, programs written in state-centric abstractions are more invariant to constant changes in data stream configurations and make the resulting software more portable across multiple sensor network platforms. With help of models of sensor collaboration, sensing, and estimation, the state-centric specifications are mapped into collaborative processing tasks at compile time, and further maintained at run time, leveraging the data-centric caching and routing services. We use a multi-target tracking system as an example to show how state-centric programming models can raise the abstraction level for users to interact with sensor networks and help modularize the design.

#*A probabilistic performance metric for real-time system design.
#@Tao Zhou,Xiaobo Sharon Hu,Edwin Hsing-Mean Sha
#t1999
#cCODES
#index106374
#%950986
#%565699
#%132599
#%564167

#*Energy-efficient address translation for virtual memory support in low-power and real-time embedded processors.
#@Xiangrong Zhou,Peter Petrov
#t2005
#cCODES+ISSS
#index106375
#%436691
#%499311
#%436810
#%805601
#%806829
#%106194
#!In this paper we present an application-driven address translation scheme for low-power and real-time embedded processors with virtual memory support. The power inefficiency and nondeterministic execution times of address-translation mechanisms have been major barriers in adopting and utilizing the benefits of virtual memory in embedded processors with low-power and real-time constraints. To address this problem, we propose a novel, Customizable Translation Table (CTT) organization, where application knowledge regarding the virtual memory footprint is used in order to eliminate conflicts in the hardware translation buffer and, thus, achieve tag-free address translation lookups. The set of virtual pages is partitioned into groups, such that for each group only a few of the least significant bits are used as an index to obtain the physical page number. We outline an efficient compile-time algorithm for identifying these groups and allocate their translation entries optimally into the CTT. The proposed methodology relies on the combined efforts of compiler, operating system, and hardware architecture to achieve a significant power reduction. The experiments that we have performed on a set of embedded applications show power reductions in the range of 55% to 80% compared to a general- purpose Translation Lookaside Buffer (TLB).

#*A unified formal model of ISA and FSMD.
#@Jianwen Zhu,Daniel Gajski
#t1999
#cCODES
#index106376
#%1123225
#%1067346
#%132276
#%142020

#*System-on-chip validation using UML and CWL.
#@Qiang Zhu,Ryosuke Oishi,Takashi Hasegawa,Tsuneo Nakata
#t2004
#cCODES+ISSS
#index106377
#!In this paper, a novel method for high-level specification and validation of SoC designs using UML is proposed. UML is introduced as a formal model of specification for SoC design. The consistency and completeness of the specification is validated based on the formal UML model. The implementation is validated by a systematic derivation of test scenarios and specification based coverage metrics from the UML model. The method has been applied to the design of a new media-processing chip for mobile devices. The application of the method shows that it is not only effective for finding logical errors in the implementation, but also eliminates errors due to inconsistency and incompleteness of the specification.

#*Modeling operation and microarchitecture concurrency for communication architectures with application to retargetable simulation.
#@Xinping Zhu,Wei Qin,Sharad Malik
#t2004
#cCODES+ISSS
#index106378
#!In multiprocessor based SoCs, optimizing the communication architecture is often as important as, if not more than, optimizing the computation architecture. While there are mature platforms and techniques for the modeling and evaluation of computation architectures, the same is not true for the communication architectures. A major challenge in modeling the communication architecture is managing the concurrency at multiple levels: at the operation level, multiple communication operations may be active at any time; at the microarchitecture level, several microarchitectural components may be operating in parallel. Further, it is important to be able to clearly specify how the operation level concurrency maps to the microarchitectural level concurrency. This paper presents a modeling methodology and a retargetable simulation framework which fill this gap. This framework seeks to facilitate the design space exploration of the communication sub-system through a rigorous modeling approach based on a formal concurrency model, the Operation State Machine (OSM). We first introduce the basic notions and concepts of OSM and show by example how this model can be used to represent the inherent concurrency in the architecture and microarchitecture of processors. Then we demonstrate the applicability of OSM in modeling on-chip communication architectures (OCAs) by walking though a router based packet switching network example and a bus example. Due to the fact that the OSM model is naturally suited to handle the operation and microarchitecture level concurrencies of OCAs as well, our OSM-based modeling methodology enables the entire system including both the computation and communication architectures to be modeled in a single OSM framework. This allows us to develop a tool set that can synthesize cycle-accurate system simulators for multi-PE SoC prototypes. To demonstrate the flexibility of this methodology, we choose two distinct system configurations with different types of OCA: a 4x4 mesh network of 16 PEs, and a cluster of 4 PEs connected by a bus. We show that by simulation, critical system information such as timing and communication patterns can be obtained and evaluated. Consequently, system-level design choices regarding the communication architecture can be made with high confidence in early stages of design. In addition to improving design quality, this methodology also results in significantly shortened design-time.

#*Design space minimization with timing and code size optimization for embedded DSP.
#@Qingfeng Zhuge,Zili Shao,Bin Xiao,Edwin Hsing-Mean Sha
#t2003
#cCODES+ISSS
#index106379
#%1134971
#%1166094
#%483673
#%133756
#%1124703
#!One of the most challenging problems in high-level synthesis is how to quickly explore a wide range of design options to achieve high-quality designs. This paper presents an Integrated Framework for Design Optimization and Space Minimization (IDOM) towards finding the minimum configuration satisfying timing and code size constraints. We show an effective way to reduce the design space to be explored through the study of the fundamental properties and relations among multiple design parameters, such as retiming value, unfolding factor, timing, and code size. Theoreies are presented to produce a small set of feasible design choices with provable quality. IDOM algorithm is proposed to generate high-quality design by integrating performance and code size optimization techniques. The experimental results on a set of DSP benchmarks show the efficiency and effectiveness of the IDOM algorithm. It constantly generates the minimal configuration for all the benchmarks. The cost of design space exploration using IDOM is only 3% of that using the standard method.

#*Combining multiple models of computation for scheduling and allocation.
#@Dirk Ziegenbein,Rolf Ernst,Kai Richter,Jürgen Teich,Lothar Thiele
#t1998
#cCODES
#index106380
#%143991
#%282088
#%106188

#*A fault model notation and error-control scheme for switch-to-switch buses in a network-on-chip.
#@Heiko Zimmer,Axel Jantsch
#t2003
#cCODES+ISSS
#index106381
#%1135243
#%282009
#%141970
#%141486
#%450493
#%805785
#%142643
#%645451
#!The reliability of a Network-on-Chip will be significantly influenced by the reliability of the switch-to-switch connections. Faults on these buses may cause disturbances on multiple adjacent wires, so that errors on these wires can no longer be considered as statistically independent from one another, as it is expected due to deep submicron effects. A new fault model notation for buses is proposed which can represent multiple-wire, multiple-cycle faults. An estimation method based on this notation is presented which can accurately predict error probabilities. This method is used to examine bus encoding schemes. Finally, an encoding scheme for four Quality-of-Service classes is proposed which can be dynamically selected for each packet.

#*Automatic phase detection for stochastic on-chip traffic generation.
#@Antoine Scherrer,Antoine Fraboulet,Tanguy Risset
#t2006
#cCODES+ISSS
#index106382
#%141996
#%335437
#%446225
#%141918
#%1063931
#%645447
#%142397
#%142447
#%50240
#%1134646
#%466420
#!During System on Chip (SoC) design, Network on Chip (NoC) prototyping is used for adapting NoC parameters to the application running on the chip. This prototyping is currently done using traffic generators which emulate the SoC components (IPs) behavior: processors, hardware accelerators, etc. Traffic generated by processor-like IPs is highly non-regular, it must be decomposed into program phases. We propose an original feature for NoC prototyping, inspired by techniques used in processor architecture performance evaluation: the automatic detection of traffic phases. Integrated in our NoC prototyping environment, this feature permits to have a completely automatic toolchain for the generation of stochastic traffic generators. We show that our traffic generators emulate precisely the behavior of processors and that our environment is a versatile tool for networks-on-chip prototyping. Simulations are performed in a SystemC-based simulation environment with a mesh network-on-chip (DSPIN) and a processor running MP3 decoding applications.

#*A multiprocessing approach to accelerate retargetable and portable dynamic-compiled instruction-set simulation.
#@Wei Qin,Joseph D'Errico,Xinping Zhu
#t2006
#cCODES+ISSS
#index106383
#%597113
#%133591
#%597692
#%133297
#%573335
#%499019
#%141714
#%1008359
#%890601
#%1008476
#%9811
#!Traditionally, instruction-set simulators (ISS's) are sequential programs running on individual processors. Besides the advances of simulation techniques, ISS's have been mainly driven by the continuously improving performance of single processors. However, since the focus of processor manufacturers is shifting from frequency scaling to multiprocessing, ISS developers need to seize this opportunity for further performance growth. This paper proposes a multiprocessing approach to accelerate one class of dynamic-compiled ISS's. At the heart of the approach is a simulation engine capable of mixed interpretative and compiled simulation. The engine selects frequently executed target code blocks and translates them into dynamically loaded libraries (DLLs), which are then linked to the engine at run time. While the engine performs simulation on one processor, the translation tasks are distributed among several assistant processors. Our experiment results using SPEC CINT2000 benchmarks show that this approach achieves on average 197 million instructions per second (MIPS) for the MIPS32 ISA and 133 MIPS for the ARM V4ISA. Compared with the uniprocessing configuration under the same general approach, multiprocessing offers higher performance and improved speed consistency. In addition, our approach is highly retargetable, portable and capable of simulating self-modifying code. To our best knowledge, this is the first reported approach that uses multiprocessing to accelerate functional simulation.

#*Design space exploration of real-time multi-media MPSoCs with heterogeneous scheduling policies.
#@Minyoung Kim,Sudarshan Banerjee,Nikil Dutt,Nalini Venkatasubramanian
#t2006
#cCODES+ISSS
#index106384
#%106029
#%196018
#%52826
#%141877
#%282781
#%565502
#%134295
#!Real-time multi-media applications are increasingly being mapped onto MPSoC (multi-processor system-on-chip) platforms containing hardware-software IPs (intellectual property) along with a library of common scheduling policies such as EDF, RM. The choice of a scheduling policy for each IP is a key decision that greatly affects the design's ability to meet real-time constraints, and also directly affects the energy consumed by the design. We present a cosynthesis framework for design space exploration that considers heterogenous scheduling while mapping multimedia applications onto such MPSoCs. In our approach, we select a suitable scheduling policy for each IP such that system energy is minimized - our framework also includes energy reduction techniques utilizing dynamic power management. Experimental results on a realistic multi-mode multi-media terminal application demonstrate that our approach enables us to select design points with up to 60.5% reduced energy for a given area constraint, while meeting all real-time requirements. More importantly, our approach generates a tradeoff space between energy and cost allowing designers to comparatively evaluate multiple system level mappings.


#*Floorplan driven leakage power aware IP-based SoC design space exploration.
#@Aseem Gupta,Nikil D. Dutt,Fadi J. Kurdahi,Kamal S. Khouri,Magdy S. Abadir
#t2006
#cCODES+ISSS
#index106385
#%436501
#%133543
#%143133
#%106063
#%282064
#%447966
#%131761
#%52776
#%132339
#!Multi-million gate System-on-Chip (SoC) designs increasingly rely on Intellectual Property (IP) blocks. However, due to technology scaling the leakage power consumption of the IP blocks has risen thus leading to possible thermal runaway. In IP-based design there has been a disconnect between system level design and physical level steps such as floorplanning which can lead to failures in manufactured chips. This necessitates coupling between system level and physical level design steps. The leakage power of an IP-block increases with its temperature which is dependent on the SoC's floorplan due to thermal diffusion. We have observed that different floorplans of the same SoC can have up to 3X difference in leakage power. Hence the system designer needs to be aware of this design space between floorplans and leakage power. We propose a leakage aware exploration (LAX) framework which enables the system designer to create this design space early in the design cycle and provides an opportunity to make changes in the system design. We show the size of the design space generated by applying LAX on ten industrial SoC designs from Freescale Semiconductor Inc. and observe that the leakage power can vary by as much as 190% for 65% difference in the inactive area.

#*A unified hardware/software runtime environment for FPGA-based reconfigurable computers using BORPH.
#@Hayden Kwok-Hay So,Artem Tkachenko,Robert W. Brodersen
#t2006
#cCODES+ISSS
#index106386
#%203222
#%562492
#%857963
#%133707
#%106351
#!This paper presents a hw/sw codesign methodology based on BORPH, an operating system designed for FPGA-based reconfigurable computers (RC's). By providing native kernel support for FPGA hardware, BORPH offers a homogeneous UNIX interface for both software and hardware processes. Hardware processes inherit the same level of service from the kernel, such as file system support, as typical UNIX software processes. Hardware and software components of a design therefore run as hardware and software processes within BORPH's run-time environment. The familiar and language independent UNIX kernel interface facilitates easy design reuse and rapid application development. Performance of our current implementation and our experience with developing a real-time wireless digital signal processing system based on BORPH will be presented.

#*TLM/network design space exploration for networked embedded systems.
#@Nicola Bombieri,Franco Fummi,Davide Quaglia
#t2006
#cCODES+ISSS
#index106387
#%132118
#%510267
#%447856
#%106094
#%141897
#%133541
#!This paper presents a methodology to combine Transaction Level Modeling and System/Network co-simulation for the design of networked embedded systems. As a result, a new design dimension is added to the traditional TLM refinement process to represent network configuration alternatives. Each network configuration can be used both to drive architecture refinement and exploration and to validate the system after each refinement step. A general criterion to map functionalities to System and Network models is presented. As a case study, the proposed methodology is applied to the design of a Voice-over-IP client.

#*Hardware assisted pre-emptive control flow checking for embedded processors to improve reliability.
#@Roshan G. Ragel,Sri Parameswaran
#t2006
#cCODES+ISSS
#index106388
#%132088
#%1124618
#%220440
#%499174
#%454112
#%153386
#%1080729
#%645747
#%1081712
#%1081790
#%1082435
#!Reliability in embedded processors can be improved by control flow checking and such checking can be conducted using software or hardware. Proposed software-only approaches suffer from significant code size penalties, resulting in poor performance. Proposed hardware-assisted approaches are not scalable and therefore cannot be implemented in real embedded systems. This paper presents a scalable, cost effective and novel fault detection technique, to ensure proper control flow of a program. This technique includes architectural changes to the processor and software modifications. While architectural refinement incorporates additional instructions, the software transformation utilizes these instructions into the program flow. Applications from an embedded systems benchmark suite are used for testing and evaluation. The overheads are compared with the state of the art approach that performs the same error coverage using software-only techniques. Our method has greatly reduced overheads compared to the state of the art. Our approach increased code size by between 3.85-11.2% and reduced performance by just 0.24-1.47% for eight different industry standard applications. The additional hardware (gates) overhead in this approach was just 3.59%. In contrast, the state of the art software-only approach required 50-150% additional code, and reduced performance by 53.5-99.5% when error detection was inserted.

#*Automotive electronics system, software, and local area network.
#@Yoshimi Furukawa,Seiji Kawamura
#t2006
#cCODES+ISSS
#index106389
#!In this tutorial, an overview of automotive electronic systems and details of the development methodologies are presented. Automobiles were born to enhance human mobile performance. In early development stage, automotive engineers focused to strengthen automobile engine power. Afterwards, automobiles had enough function to drive faster than any animal, but they caused some social problems such as traffic accidents, environmental problems and traffic congestions. Automotive electronic technologies have been developed in order to solve these social problems.Roles of electronic technologies on automobile functional developments For the solution to safety, environment and traffic problems, various functions are necessary which could not be completed only by mechanical systems. In this section, roles of automobile electronic systems on countermeasures to the social problems are discussed. Vehicle motion control systems, power-train control systems, navigation systems, and advanced drive assist systems are introduced and automotive functions are defined. Design requirement for automotive electronic systems architecture Electronic systems composed basically of sensors, ECU's (Electronic Control Units), actuators and human interfaces. In early days, each electronic system was designed independently. Today's automobile has various functions which could be completed by multiple electric systems. Therefore, fundamental architecture of integrated electronic systems in an automobile is important to be designed in order to optimize the total function, cost and productivity.Design and development procedure of electronic systems and software In vehicle systems and software, required functions and complexity of products are increasing. In this situation, ECU suppliers are working with efficient development methodology to achieve the highest quality. Today most common development processes are still classical V shaped process, module design and C language programming. However, several new technologies such as UML design method are tried and some of them are adopted as the standard process. Automatic testing and simulation environment are also important for the development procedure.

#*A bus architecture for crosstalk elimination in high performance processor design.
#@Wen-Wen Hsieh,Po-Yuan Chen,TingTing Hwang
#t2006
#cCODES+ISSS
#index106390
#%452177
#%133022
#%142362
#%143291
#%283323
#%141802
#%52981
#!In deep sub-micron technology, the crosstalk effect between adjacent wires has become an important issue, especially between long on-chip buses. This effect leads to the increase in delay, in power consumption, and in worst case, to incorrect result. In this paper, we propose a deassembler/assembler structure to eliminate undesirable crosstalk effect on bus transmission. By taking advantage of the prefetch process where the instruction/data fetch rate is always higher than instruction/data commit rate in high performance processors, the proposed method would hardly reduce the performance. In addition, the required number of extra bus wires is only 7 as compared with 85 needed in [6] when the bus width is 128 bits.

#*Bounded arbitration algorithm for QoS-supported on-chip communication.
#@Mohammad Abdullah Al Faruque,Gereon Weiss,Jörg Henkel
#t2006
#cCODES+ISSS
#index106391
#%148790
#%141996
#%805785
#%990953
#%131914
#%142871
#%645213
#%452401
#%133273
#%806492
#%106204
#!Time-critical multi-processor systems require guaranteed services in terms of throughput, bandwidth etc. in order to comply to hard real-time constraints. However, guaranteed-service schemes suffer from low resource utilization.To the best of our knowledge, we are presenting the first approach for on-chip communication that provides a high resource utilization under a transaction-specific, flexible (i.e. different classifications on data exchange) communication scheme. It does provide tight time-related guarantees. Hence, we are presenting our bounded arbitration scheme considering lower and upper bounds for each type of transaction level. We demonstrate its advantages by means of a complete MPEG4 decoder case study and achieve under these constraints a bandwidth utilization of up to 100%, on an average 97% with a guaranteed (100%) bandwidth.

#*Creation and utilization of a virtual platform for embedded software optimization: : an industrial case study.
#@Sungpack Hong,Sungjoo Yoo,Sheayun Lee,Sangwoo Lee,Hye Jeong Nam,Bum-Seok Yoo,Jaehyung Hwang,Donghyun Song,Janghwan Kim,Jeongeun Kim,HoonSang Jin,Kyu-Myung Choi,Jeong-Taek Kong,Soo-Kwan Eo
#t2006
#cCODES+ISSS
#index106392
#%132281
#%133297
#%133702
#%143313
#%52896
#%142036
#%143023
#%142155
#%141481
#%50182
#!Virtual platform (ViP), or ESL (Electronic System Level) simulation model, is one of the most widely renowned system level design techniques. In this paper, we present a case study of creating and applying the ViP in the development of a new hard disk system called Hybrid-HDD that is one of the main features in the Windows VISTA (R). First, we summarize how we developed the ViP including the levels of timing accuracy of models, automatic generation of models from RTL code, external subsystem models, etc. Then, we explain how we exploited the ViP in software optimization. Compared with the conventional flow of software development, e.g. based on the real board, the ViP gives a better profiling capability thereby allowing designers to find more chances of code optimization. Based on the simulation and analysis with the ViP, the software optimization could improve system performance by more than 50%. However, in our case study, we found that the current ViP technique needs further improvements to become a true ESL design technique.

#*Increasing hardware efficiency with multifunction loop accelerators.
#@Kevin Fan,Manjunath Kudlur,Hyunchul Park,Scott A. Mahlke
#t2006
#cCODES+ISSS
#index106393
#%203178
#%203172
#%133191
#%282267
#%1165860
#%214676
#%499212
#%499060
#%81488
#%408248
#%805889
#%542521
#%499162
#%1098582
#%133324
#%194003
#!To meet the conflicting goals of high-performance low-cost embedded systems, critical application loop nests are commonly executed on specialized hardware accelerators. These loop accelerators are traditionally designed in a single-function manner, wherein each loop nest is implemented as a dedicated hardware block. This paper focuses on hardware sharing across loop nests by creating multifunction loop accelerators, or accelerators capable of executing multiple algorithms. A compiler-based system for automatically synthesizing multifunction loop accelerator architectures from C code is presented. We compare the effectiveness of three architecture synthesis approaches with varying levels of complexity: sum of individual accelerators, union of individual accelerators, and joint accelerator synthesis. Experiments show that multifunction accelerators achieve substantial hardware savings over combinations of single-function designs. In addition, the union approach to multifunction synthesis is shown to be effective at creating low-cost hardware by exploiting hardware sharing, while remaining computationally tractable.

#*Multi-processor system design with ESPAM.
#@Hristo Nikolov,Todor Stefanov,Ed F. Deprettere
#t2006
#cCODES+ISSS
#index106394
#%450530
#%450592
#%143072
#%858471
#%1081312
#%133010
#%106305
#!For modern embedded systems, the complexity of embedded applications has reached a point where the performance requirements of these applications can no longer be supported by embedded system architectures based on a single processor. Thus, the emerging embedded System-on-Chip platforms are increasingly becoming multiprocessor architectures. As a consequence, two major problems emerge, i.e., how to design and how to program such multiprocessor platforms in a systematic and automated way in order to reduce the design time and to satisfy the performance needs of applications executed on these platforms. Unfortunately, most of the current design methodologies and tools are based on Register Transfer Level (RTL) descriptions, mostly created by hand. Such methodologies are inadequate, because creating RTL descriptions of complex multiprocessor systems is error-prone and time consuming.As an efficient solution to these two problems, in this paper we propose a methodology and techniques implemented in a tool called Espam for automated multiprocessor system design and implementation. Espam moves the design specification from RTL to a higher, so called system level of abstraction. We explain how starting from system level platform, application, and mapping specifications, a multiprocessor platform is synthesized and programmed in a systematic and automated way. Furthermore, we present some results obtained by applying our methodology and Espam tool to automatically generate multiprocessor systems that execute a real-life application, namely a Motion-JPEG encoder.

#*Automatic selection of application-specific instruction-set extensions.
#@Carlo Galuzzi,Elena Moscu Panainte,Yana Yankova,Koen Bertels,Stamatis Vassiliadis
#t2006
#cCODES+ISSS
#index106395
#%106038
#%283219
#%141414
#%77502
#%106004
#%106014
#%498980
#%214265
#%77570
#%499311
#%1082482
#%77474
#!In this paper, we present a general and an efficient algorithm for automatic selection of new application-specific instructions under hardware resources constraints. The instruction selection is formulated as an ILP problem and efficient solvers can be used for finding the optimal solution. An important feature of our algorithm is that it is not restricted to basic-block level nor does it impose any limitation on the number of the newly added instructions or on the number of the inputs/outputs of these instructions. The presented results show that a significant overall application speedup is achieved even for large kernels (for ADPCM decoder the speedup ranges from x1.2 to x3.7) and that our algorithm compares well with other state-of-art algorithms for automatic instruction set extensions.

#*A formal approach to robustness maximization of complex heterogeneous embedded systems.
#@Arne Hamann,Razvan Racu,Rolf Ernst
#t2006
#cCODES+ISSS
#index106396
#%141631
#%296860
#%1053057
#%174590
#%1129728
#!Embedded system optimization typically considers objectives such as cost, timing, buffer sizes and power consumption. Robustness criteria, i.e. sensitivity of the system to variations of properties like execution and transmission delays, input data rates, CPU clock rates, etc., has found less attention despite its practical relevance.In this paper we introduce robustness metrics and propose an algorithm considering these metrics in design space exploration and system optimization. The algorithm can optimize for static and for dynamic robustness, the latter including system or designer reactions to property variations. We explain several applications ranging from platform optimization to critical component identification.By means of extensive experiments we show that design space exploration pursuing classical design goals does not necessarily yield robust systems, and that our method leads to systems with significantly higher design robustness.


#*Automatic generation of transaction level models for rapid design space exploration.
#@Dongwan Shin,Andreas Gerstlauer,Junyu Peng,Rainer Dömer,Daniel D. Gajski
#t2006
#cCODES+ISSS
#index106397
#%283380
#%141663
#%106094
#%282905
#%133541
#%282563
#%133010
#%142964
#%106345
#%106371
#!Transaction-level modeling has been touted to improve simulation performance and modeling efficiency for early design space exploration. But no tools are available to generate such transaction-level models from abstract input descriptions. Designers have to write such models manually, which is a tedious and error-prone task, and one of bottlenecks in improving designer's productivity. In this paper, we propose a method to generate transaction-level models from virtual architecture models where components communicate via abstract message-passing channels. We have applied our approach to a set of industrial-strength examples with a wide range of target architectures. Experimental results show that significant productivity gains can be achieved, demonstrating the effectiveness and benefits of our approach for rapid, early exploration of communication design space.

#*Yield prediction for architecture exploration in nanometer technology nodes: : a model and case study for memory organizations.
#@Antonis Papanikolaou,T. Grabner,Miguel Miranda,Philippe Roussel,Francky Catthoor
#t2006
#cCODES+ISSS
#index106398
#%134180
#%436542
#%143061
#%805592
#%1008319
#%106223
#%282207
#%133971
#%133972
#%133092
#%142727
#!Process variability has a detrimental impact on the performance of memories and other system components, which can lead to parametric yield loss at the system level due to timing violations. Conventional yield models do not allow to accurately analyze this, at least not at the system level. In this paper we propose a technique to estimate this system level yield loss for a number of alternative memory organization implementations. This can aid the designer into making educated trade-offs at the architecture level between energy consumption and parametric timing yield by using memories from different available libraries with different energy/performance characteristics considering the impact of manufacturing variations. The accuracy of this technique is very high, an average error of less than 1% is reported, which enables an early exploration of the available options.

#*Application specific forwarding network and instruction encoding for multi-pipe ASIPs.
#@Swarnalatha Radhakrishnan,Hui Guo,Sri Parameswaran,Aleksandar Ignjatovic
#t2006
#cCODES+ISSS
#index106399
#%283219
#%282604
#%133299
#%106164
#%77502
#%1124514
#%77570
#%282336
#%282436
#%806926
#%142818
#%645987
#%143020
#%646126
#!Small area and code size are two critical design issues in most of embedded system designs. In this paper, we tackle these issues by customizing forwarding networks and instruction encoding schemes for multi-pipe Application Specific Instruction-Set Processors (ASIPs). Forwarding is a popular technique to reduce data hazards in the pipeline to improve performance and is applied in almost all modern processor designs; but it is very area expensive. Instruction encoding schemes have a direct impact on code size; an efficient encoding method can lead to a small instruction width, and hence reducing the code size. We propose application specific techniques to reduce forwarding networks and instruction widths for ASIPs with multiple pipelines. By these design techniques, it is possible to reduce area, code size, and even power consumption (due to reduced area), without costing any performance. Our experiments, on a set of benchmarks using the proposed customization approaches show that, on average, there are 27% savings on area, 30% on leakage power, 16.7% on code size, and at the same time, performance even improves by 4% because of the reduced clock period.

#*Architectural support for safe software execution on embedded processors.
#@Divya Arora,Anand Raghunathan,Srivaths Ravi,Niraj K. Jha
#t2006
#cCODES+ISSS
#index106400
#%542513
#%542475
#%1073642
#%542532
#%542393
#%636117
#%133639
#%1123770
#%601331
#%141315
#%77582
#%77655
#%1074921
#%499311
#!The lack of memory safety in many popular programming languages, including C and C++, has been a cause for great concern in the realm of software reliability, verification, and more recently, system security. A major portion of known security attacks against software systems can be attributed to this shortcoming, including the well-known stack overflow, heap overflow, and format string attacks. Despite their limitations, the flexibility, performance, and ease of use of these languages have made them the choice of most embedded software developers. Researchers have proposed various techniques to enhance programs for memory safety; however, they are all subject to severe performance penalties, making their use impractical in most scenarios. In this paper, we present architectural enhancements to enable efficient, memory-safe execution of software on embedded processors. The key insight behind our approach is to extend embedded processors with hardware that significantly accelerates the execution of the additional computations involved in memory-safe execution. Specifically, we design custom instructions to perform various kinds of memory-safety checks and augment the instruction set of a state-of-the-art extensible processor (Xtensa from Tensilica, Inc.) to implement them. We demonstrate the application of the proposed architectural enhancements using CCured, an existing tool for type-safe retrofitting of C programs. The tool uses a type-inferencing engine that is built around strong type-safety theory and is provably safe. Simulations of memory-safe versions of popular embedded benchmarks on a cycle-accurate simulator modeling a typical embedded system configuration indicate an average performance improvement of 2.3x, and a maximum of 4.6x when using the proposed architecture. These enhancements entail minimal (less than 10%) hardware overhead to the base processor. Our approach is completely automated, and applicable to any C program, making it a promising and practical approach for addressing the growing security and reliability concerns in embedded software.

#*Increasing the throughput of an adaptive router in network-on-chip (NoC).
#@Seung Eun Lee,Nader Bagherzadeh
#t2006
#cCODES+ISSS
#index106401
#%344119
#%614526
#%1124915
#%131914
#%805785
#%419513
#%419428
#%131304
#%1078797
#%1124809
#%858239
#%858092
#!In this paper, we propose a simple and efficient mechanism to increase the throughput of an adaptive router in Network-on-Chip (NoC). One of the most serious disadvantages of fully adaptive wormhole routers is its performance degradation due to the routing decision time. The key idea to overcome this shortcoming is the use of different clocks in a head flit and body flits, because the body flits can be forwarded immediately and the FIFO usually operates faster than route decision logic in an adaptive router. The major contributions of this paper are: 1) a proposal of a simple and efficient mechanism to improve the performance of fully adaptive wormhole routers, 2) a quantitative evaluation of the proposed mechanism showing that the proposed one can support higher throughput than a conventional one, and 3) an evaluation of hardware overhead for the proposed router. In summary, the proposed clock boosting mechanism enhances the throughput of the original adaptive router by increasing the accepted load and decreasing the average latency in the region of effective bandwidth.

#*UML and model-driven development for SoC design.
#@Wolfgang Mueller,Yves Vanderperren
#t2006
#cCODES+ISSS
#index106402
#!UML (Unified Modeling Language™) as an OMG standard has received wide acceptance in software engineering over the last years. As electronic systems design moved towards software engineering, there is emerging interest for UML within the hardware community and different UML diagrams and their variations found their application in requirements specification, testbenches, architectural descriptions, and behavioral modeling.In most cases, UML is just applied as a graphical capture, though UML 2.0 meanwhile comes as a computationally complete language based on a generic metamodeling mechanism. Though it introduces considerable complexity, it is one of the key strengths of UML 2.0, providing a flexible foundation for its customization towards different application domains through so-called UML profiles, which currently receives increasing tool support and gives UML great potential to complement current C++-oriented languages for ESL design. In this context, SysML and the UML for SoC extension are already available as OMG profiles for Systems Engineering and SoC application and several proprietary profiles are under development. In that context, the concepts of the Model Driven Architecture (MDA) are of emerging interest. However, since MDA was mainly introduced for CASE tool support, its full application for hardware design still needs some investigations and certainly comes with some pitfalls.For industrial applications, the availability of appropriate tool support is crucial for deployment of UML in SoC design. UML tools currently come in different variations based on different UML versions and subsets with the support of specific flows, so that the selection of the appropriate tools becomes a key decision for the successful introduction of UML. Recently, several groups have reported positive outcomes regarding the customization of UML and tool support towards SoC design. These efforts result from collaborations between industrial users, researchers, and tool vendors, and constitute steps in the right direction. Regarding model exchange between tools, the UML-related XMI (XML Metadata Interchange) format and its relationship to SPIRIT, the emerging IEEE standard, are of additional particular interest. Partial overlaps can be identified and are currently under investigations by some projects, like SPRINT.

#*Generic netlist representation for system and PE level design exploration.
#@Bita Gorjiara,Mehrdad Reshadi,Pramod Chandraiah,Daniel Gajski
#t2006
#cCODES+ISSS
#index106403
#%144022
#%645568
#%106276
#%52158
#!Designer productivity and design predictability are vital factors for successful embedded system design. Shrinking time-to-market and increasing complexity of these systems require more productive design approaches starting from high-level languages such as C. On the other hand, tight constraints of embedded systems require careful design exploration at system level (coarse grained exploration) and at the processing-element (PE) level (fine grained exploration).In this paper we presented GNR, a formal modeling approach, developed to improve productivity of designing systems and processing elements, the same way that traditional ADLs improved productivity for designing processors. The GNR is an order of magnitude shorter than state-of-the-art ADLs with RTL generation capabilities and yet can capture any structural details that affect the implementation quality. Using relatively short GNR description, we explored several designs for implementing an MP3 decoder and achieved 3.25 speedup compared to MicroBlaze processor. We have also developed a web-based interface for our tools, so that users can upload and evaluate new architectures described in GNR. Our toolset and GNR is an intermediate step towards synthesis of TLM to RTL.

#*Pack instruction generation for media pUsing multi-valued decision diagram.
#@Hiroaki Tanaka,Yoshinori Takeuchi,Keishi Sakanushi,Masaharu Imai,Yutaka Ota,Nobu Matsumoto,Masaki Nakagawa
#t2006
#cCODES+ISSS
#index106404
#%542704
#%918446
#%1123225
#%542522
#%483622
#!SIMD instructions are often implemented in modern multimedia oriented processors. Although SIMD instructions are useful for many digital signal processing applications, most compilers do not exploit SIMD instructions. The difficulty in the utilization of SIMD instructions stems from data parallelism in registers. In assembly code generation, the positions of data in registers must be noted. A technique of generating pack instructions which pack or reorder data in registers is essential for exploitation of SIMD instructions. This paper presents a code generation technique for SIMD instructions with pack instructions. SIMD instructions are generated by finding and grouping the same operations in programs. After the SIMD instruction generation, pack instructions are generated. In the pack instruction generation, Multi-valued Decision Diagram (MDD) is introduced to represent and to manipulate sets of packed data. Experimental results show that our code generation technique can generate assembly code with SIMD and pack instructions performing complex repacking of 8 packed data in registers for a commercial VLIW processor with 6 pack instructions and achieved speedup ratio of up to 7.7.

#*A methodology for design of application specific deadlock-free routing algorithms for NoC systems.
#@Maurizio Palesi,Rickard Holsmark,Shashi Kumar,Vincenzo Catania
#t2006
#cCODES+ISSS
#index106405
#%134146
#%1124915
#%1124809
#%131914
#%131304
#%142588
#%990928
#!In this paper, we present a methodology to specialize the routing algorithm in routing table based NoC routers. It tries to maximize the communication performance while ensuring deadlock free routing for an application. We demonstrate through analysis that routing algorithms generated by our methodology have higher adaptiveness as compared to turn-model based deadlock free routing algorithms for a mesh topology NoC architecture. Performance evaluation is carried out by using a flit-accurate simulator on traffic scenarios generated by both synthetic and real applications. The routing algorithms generated by the proposed methodology achieve an improvement in delay close to 50% and 30% over deterministic XY routing algorithm and adaptive Odd-Even routing algorithm respectively.

#*Accurate yet fast modeling of real-time communication.
#@Gunar Schirner,Rainer Dömer
#t2006
#cCODES+ISSS
#index106406
#%141663
#%52280
#%133849
#%143023
#!Accurate modeling of communication is a necessary part of system level design for real-time safety-critical applications. For efficient prediction of a system's performance, Transaction Level Modeling (TLM) is often used which increases the simulation speed by orders of magnitude. The speed advantage, however, comes at the cost of low accuracy.In this paper, we use a novel modeling technique, called Result Oriented Modeling (ROM), which yields 100% accuracy in timing, yet approaches the same speed as traditional TLM. ROM also abstracts away internal details of the communication but, in contrast to TLM, fully maintains accurate timing. ROM optimistically predicts the timing and retroactively takes corrective measures, if necessary.In this paper, we compare the ROM technique to TLM at different levels of abstraction, using a Controller Area Network (CAN) bus example. Our results show that ROM yields a simulation speedup close to the traditional TLM, yet exhibits the same timing accuracy as a bus functional model. Thus, for safety-critical real-time applications, ROM is a viable replacement for the inaccurate TLM.

#*Battery discharge aware energy feasibility analysis.
#@Henrik Lipskoch,Karsten Albers,Frank Slomka
#t2006
#cCODES+ISSS
#index106407
#%1052972
#%142339
#%142970
#%174410
#%141404
#%565034
#%132986
#%436966
#!It is observed that pulsed discharge currents allow to drain the battery with a higher specific power. Thus they improve the batteries durability and discharge performance. The question is how can the allowed discharge of a battery be modeled. Embedded real-time systems often rely on batteries. For these systems it is necessary to prove both, real-time feasibility and the constraint to not exceed the allowed discharge currents. This paper presents a unified approach for both objectives using the flexible model of event streams, because it allows both to model a complex allowed-discharge curve and the real-time requirements for complex task stimuli. We present the model and the calculation of the allowed and requested discharge curves. Together with the known event-stream based real-time feasibility analysis this allows a unified analysis of both aspects of the system. This work enables the modeling of complex discharge requirements of batteries for real-time systems.

#*Challenges in exploitation of loop parallelism in embedded applications.
#@Arun Kejariwal,Alexander V. Veidenbaum,Alexandru Nicolau,Milind Girkar,Xinmin Tian,Hideki Saito
#t2006
#cCODES+ISSS
#index106408
#%538238
#%419574
#%450648
#%133010
#%134295
#%646126
#%286037
#%418771
#%770111
#%410479
#%408982
#!Embedded processors have been increasingly exploiting hardware parallelism. Vector units, multiple processors or cores, hyper-threading, special-purpose accelerators such as DSPs or cryptographic engines, or a combination of the above have appeared in a number of processors. They serve to address the increasing performance requirements of modern embedded applications. How this hardware parallelism can be exploited by applications is directly related to the amount of parallelism inherent in a target application. In this paper we evaluate the performance potential of different types of parallelism, viz., true thread-level parallelism, speculative thread-level parallelism and vector parallelism, when executing loops. Applications from the industry-standard EEMBC 1.1, EEMBC 2.0 and the MiBench embedded benchmark suites are analyzed using the Intel C compiler. The results show what can be achieved today, provide upper bounds on the performance potential of different types of thread parallelism, and point out a number of issues that need to be addressed to improve performance. The latter include parallelization of libraries such as libc and design of parallel algorithms to allow maximal exploitation of parallelism. The results also point to the need for developing new benchmark suites more suitable to parallel compilation and execution.

#*Automatic run-time extraction of communication graphs from multithreaded applications.
#@Ai-Hsin Liu,Robert P. Dick
#t2006
#cCODES+ISSS
#index106409
#%483614
#%418656
#%133920
#%252717
#%597733
#%106020
#%50121
#%562661
#%360639
#%1098604
#%859018
#!Embedded system synthesis, multiprocessor synthesis, and thread assignment policy design all require detailed knowledge of the runtime communication patterns among different threads or processes. Researchers have commonly relied on manual estimation, compiletime analysis, or synthetic benchmarks when developing and evaluating synthesis algorithms and thread assignment policies. In a more ideal world, it would be possible to quickly and easily determine the run-time communication properties of large commercial and academic multithreaded applications. This article describes a fully-automated method of extracting run-time communication graphs from multithreaded applications. The resulting graphs may be used to better understand, design, and synthesize application-specific hardware-software systems. The proposed graph extraction method is implemented as a module within the Simics multiprocessor simulator. It presently supports the analysis of arbitrary multithreaded applications running on the Linux operating system. This software is called CETA. It is freely available for academic and non-profit use.

#*Are current ESL tools meeting the requirements of advanced embedded systems?
#@Jürgen Teich
#t2006
#cCODES+ISSS
#index106410
#!Electronic System Level (ESL) tools are becoming more and more important in order to bridge the well-known productivity design gap. This panel brings together specialists from industry and ESL tool houses to discuss whether current ESL tools available are usable and meeting the requirements of the industry. In particular, we would like to know to what degree currently available tools from major ESL tool houses are used for designing what kind of systems in industry, and for what purpose such as analysis, design space exploration, or synthesis, etc. these tools are currently used. Also, we would like to discuss to what degree existing tools can help in reducing design time, and finally, what the industry sees the most challenging features of tools currently not yet available. On the other side, we would like to know the opinion of the ESL tool houses what they see the most important offerings of ESL tools currently available as well as the most challenging points and problems why ESL hasn't really taken off so far. Could this either be an industry issue, a methodology issue, a design issue or a tool issue.

#*Hardware based frequency/voltage control of voltage frequency island systems.
#@Puru Choudhary,Diana Marculescu
#t2006
#cCODES+ISSS
#index106411
#%55205
#%282324
#%252911
#%437144
#%1134959
#%281644
#%499027
#%52770
#%283010
#%53700
#!The ability to do fine grain power management via local voltage selection has shown much promise via the use of Voltage/Frequency Islands (VFIs). VFI-based designs combine the advantages of using fine-grain speed and voltage control for reducing energy requirements, while allowing for maintaining performance constraints. We propose a hardware based technique to dynamically change the clock frequencies and potentially voltages of a VFI system driven by the dynamic workload. This technique tries to change the frequency of a synchronous island such that it will have efficient power utilization while satisfying performance constraints. We propose a hardware design that can be used to change the frequencies of various synchronous islands interconnected together by mixed-clock/mixed-voltage FIFO interfaces. Results show up to 65% power savings for the set of benchmarks considered with no loss in throughput.

#*Retargetable code optimization with SIMD instructions.
#@Manuel Hohenauer,Christoph Schumacher,Rainer Leupers,Gerd Ascheid,Heinrich Meyr,Hans van Someren
#t2006
#cCODES+ISSS
#index106412
#%132088
#%542704
#%142348
#%450600
#%1008179
#%858377
#%52494
#%2346
#%142082
#%86531
#%483622
#!Retargetable C compilers are nowadays widely used to quickly obtain compiler support for new embedded processors and to perform early processor architecture exploration. One frequent concern about retargetable compilers, though, is their lack of machine-specific code optimization techniques in order to achieve highest code quality. While this problem is partially inherent to the retargetable compilation approach, it can be circumvented by designing flexible, configurable code optimization techniques that apply to a certain range of target architectures. This paper focuses on target machines with SIMD instruction support which is widespread in embedded processors for multimedia applications. We present an efficient and quickly retargetable SIMD code optimization technique that is integrated into an industrial retargetable C compiler. Experimental results for the Philips Trimedia processor demonstrate that the proposed technique applies to real-life target machines and that it produces code quality improvements close to the theoretical limit.

#*Integrated analysis of communicating tasks in MPSoCs.
#@Simon Schliecker,Matthias Ivers,Rolf Ernst
#t2006
#cCODES+ISSS
#index106413
#%106260
#%1053257
#%1275423
#%564307
#%564418
#%1081894
#!Predicting timing behavior is key to efficient embedded real-time system design and verification. Especially memory accesses and co-processor calls over shared communication networks, basic operations of every embedded application pose a challenge for precise system analysis. Current approaches to determine end-to-end latencies in parallel heterogeneous architectures either focus on system level and allow only limited task models, or focus on activities inside a component, abstracting system level influences by overestimations.In this paper, we identify feedbacks of the system behavior that directly or indirectly impact local execution. To tackle these complex interactions we present a novel technique to integrate an extended component level scheduling analysis with refined system level approaches. Bringing the different levels of abstraction together allows the analysis of a new class of interacting applications and architectures - which could not be addressed on a single level alone.On the component level, we investigate two scheduling behaviors more closely, namely stalling during external requests, and allowing context-switches to other tasks that are ready. For both, we present a precise response time analysis. Finally, we compare the scheduling techniques with respect to real-time requirements.

#*Fuzzy decision making in embedded system design.
#@Alessandro G. Di Nuovo,Maurizio Palesi,Davide Patti,Giuseppe Ascia,Vincenzo Catania
#t2006
#cCODES+ISSS
#index106414
#%644846
#%858028
#%141842
#%499311
#%880542
#%1033442
#!The use of Application Specific Instruction-set Processors (ASIP) is a solution to the problem of increasing complexity in embedded systems design. One of the major challenges in ASIP design is Design Space Exploration (DSE), because of the heterogeneity of the objectives and parameters involved. Typically DSE is a multi-objective search problem, where performance, power, area, etc. are the different optimization criteria. The output of a DSE strategy is a set of candidate design solutions called a Pareto-optimal set. Choosing a solution for system implementation from the Pareto-optimal set can be a difficult task, generally because Pareto-optimal sets can be extremely large or even contain an infinite number of solutions. In this paper we propose a methodology to assist the decision-maker in analysis of the solutions to multi-objective problems. By means of fuzzy clustering techniques, it finds the reduced Pareto subset, which best represents all the Pareto solutions. This optimal subset will be used for further and more accurate (but slower) analysis. As a real application example we address the optimization of area, performance, and power of a VLIW-based embedded system.

#*Methodology for attack on a Java-based PDA.
#@Catherine H. Gebotys,Brian A. White
#t2006
#cCODES+ISSS
#index106415
#%87045
#%86971
#%327166
#!Although mobile Java code is frequently executed on many wireless devices, the susceptibility to electromagnetic (EM) attacks is largely unknown. If analysis of EM waves emanating from the wireless device during a cryptographic computation does leak sufficient information, it may be possible for an attacker to reconstruct the secret key. Possession of the secret cryptographic key would render all future wireless communications insecure and cause further potential problems such as identity theft. Despite the complexities of a Java-based PDA device, this paper proposes and verifies a methodology which confirms EM attacks are possible. The proposed methodology involves pre-characterization of the PDA device through SEMA, thresholding, pattern recognition, and frequency-based DEMA. Results are repeatable over several different secret keys. Unlike previous research the new methodology does not require perfect alignment of EM frames and demonstrates robustness in the presence of a complex embedded system. This research is important for future wireless embedded systems which will increasingly demand higher levels of security.

#*Resource virtualization in real-time CORBA middleware.
#@Christopher D. Gill
#t2006
#cCODES+ISSS
#index106416
#%362153
#%361832
#%1053217
#%181509
#%565296
#%563931
#%563933
#%181363
#%564047
#%601275
#%248258
#%565501
#%808234
#%248674
#%564148
#!Middleware for parallel and distributed systems is designed to virtualize computation and communication resources so that a more abstract and consistent view of those resources is presented to the applications that use them. Providing such a consistent virtualization in distributed real-time and embedded systems becomes increasingly challenging due to application constraints such as timeliness and resource constraints such as CPU speed, power, memory, and bandwidth limitations, which also must be considered.This paper describes several examples of real-time CORBA middleware and examines how different constraints impact the way in which resources are virtualized in each case. Particular attention is paid to which details are hidden from users of the middleware, which details are exposed in the middleware's programming model, and how the hidden and exposed details interact to shape middleware design and implementation choices.

#*Streamroller: : automatic synthesis of prescribed throughput accelerator pipelines.
#@Manjunath Kudlur,Kevin Fan,Scott A. Mahlke
#t2006
#cCODES+ISSS
#index106417
#%1165860
#%499060
#%1068187
#%131846
#%645095
#%499162
#%106393
#%133324
#%143072
#%134078
#%1165956
#%143299
#!In this paper, we present a methodology for designing a pipeline of accelerators for an application. The application is modeled using sequential C language with simple stylizations. The synthesis of the accelerator pipeline involves designing loop accelerators for individual kernels, instantiating buffers for arrays used in the application, and hooking up these building blocks to form a pipeline. A compiler-based system automatically synthesizes loop accelerators for individual kernels at varying performance levels. An integer linear program formulation which simultaneously optimizes the cost of loop accelerators and the cost of memory buffers is proposed to compose the loop accelerators to form an accelerator pipeline for the whole application. Cases studies for some applications, including FMRadio and Beamformer, are presented to illustrate our design methodology. Experiments show significant cost savings are achieved through hardware sharing, while achieving the prescribed throughput requirements.

#*A buffer-sizing algorithm for networks on chip using TDMA and credit-based end-to-end flow control.
#@Martijn Coenen,Srinivasan Murali,Andrei Radulescu,Kees Goossens,Giovanni De Micheli
#t2006
#cCODES+ISSS
#index106418
#%401403
#%489530
#%106121
#%9757
#%142537
#%132165
#%77578
#%142589
#%858092
#%133849
#!When designing a System-on-Chip (SoC) using a Network-on-Chip (NoC), silicon area and power consumption are two key elements to optimize. A dominant part of the NoC area and power consumption is due to the buffers in the Network Interfaces (NIs) needed to decouple computation from communication. Having such a decoupling prevents stalling of IP blocks due to the communication interconnect. The size of these buffers is especially important in real-time systems, as there they should be big enoughto obtain predictable performance. To ensure that buffers do not overflow, end-to-end flow-control is needed. One form of end-to-end flow-control used in NoCs is credit-based flow-control. This form places additional requirements on the buffer sizes, because the flow-control delays need to be taken into account. In this work, we present an algorithm to find the minimal decoupling buffer sizes for a NoC using TDMA and credit-based end-to-end flow-control, subject to the performance constraints of the applications running on the SoC. Our experiments show that our method results in a 84% reduction of the total NoC buffer area when compared to the state-of-the art buffer-sizing methods. Moreover, our method has a low run-time complexity, producing results in the order of minutes for our experiments, enabling quick design cycles for large SoC designs. Finally, our method can take into account multiple usecases running on the same SoC.

#*Cutting across layers of abstraction: : removing obstacles from the advancement of embedded systems.
#@Krisztián Flautner
#t2006
#cCODES+ISSS
#index106419
#!Silicon technology evolution over the last four decades has yielded an exponential increase in integration densities with steady improvements of performance and power consumption at each technology generation. This steady progress has created a sense of entitlement for the riches that future process generations would bring. Today, however, classical process scaling seems to be dead and living up to technology expectations requires continuous innovation at many levels, which comes at steadily progressing implementation and design costs. Solutions to problems need to cut across layers of abstractions and require coordination between software, architecture and circuit features.Heterogeneous multiprocessor clusters are increasingly used to deliver the required compute power for high-end applications. Heterogeneity ensures that the necessary processing power can be delivered at high levels of efficiency at reasonable implementation cost, while the use of processors endow these systems with large degrees of flexibility. One of the key challenges with these systems is system-level programming. Traditional compiler technologies are strong at programming individual cores but leave the task of parallelization to a team of experts. The first part of this talk will describe the coupling of the compiler to the system architecture on a multi-core signal-processing cluster and illustrate how compiler technology can enable the writing of portable parallel programs for it using little more than C.As claimed above, close coupling of abstraction layers can be beneficial. This can also be illustrated at the microarchitecture - circuit boundary. The second part of the talk will describe a prototype microarchitecture which is designed explicitly to deal with issues such as silicon variation and soft errors. These features in return enable system designers to focus on the typical-case performance of their implementations without having to be over-constrained by worst-case conditions.

#*Decision-theoretic exploration of multiProcessor platforms.
#@Giovanni Beltrame,Dario Bruschi,Donatella Sciuto,Cristina Silvano
#t2006
#cCODES+ISSS
#index106420
#%1495733
#%106221
#%1497225
#%483528
#%858394
#%133763
#!In this paper, we present an efficient technique to perform design space exploration of a multi-processor platform that minimizes the number of simulations needed to identify the power-performance approximate Pareto curve. Instead of using semi-random search algorithms (like simulated annealing, tabu search, genetic algorithms, etc.), we use domain knowledge derived from the platform architecture to set-up exploration as a decision problem. Each action in the decision-theoretic framework corresponds to a change in the platform parameters. Simulation is performed only when information about the probability of action outcomes becomes insufficient for a decision. The algorithm has been tested with two multi-media industrial applications, namely an MPEG4 encoder and an Ogg-Vorbis decoder. Results show that the exploration of the number of processors and two-level cache size and policy, can be performed with less than 15 simulations with 95% accuracy, increasing the exploration speed by one order of magnitude when compared to traditional operation research techniques.

#*Heterogeneous multiprocessor implementations for JPEG: : a case study.
#@Seng Lin Shee,Andrea Erdos,Sri Parameswaran
#t2006
#cCODES+ISSS
#index106421
#%250925
#%450541
#%563840
#%807028
#!Heteregenous multiprocessor SoCs are becoming a reality, largely due to the abundance of transistors, intellectual property cores and powerful design tools. In this project, we explore the use of multiple cores to speed up the JPEG compression algorithm. We show two methods to parallelize this algorithm: one, a master-slave model; and two, a pipeline model. The systems were implemented using Tensilica's Xtensa LX processors with queues. We show that even with this relatively simple application, parallelization can be carried out with up to nine processors with utilization of between 50% to 80%. We obtained speed ups of up to 4.6X with a seven core system with an area increase of 3.1X.

#*Phase guided sampling for efficient parallel application simulation.
#@Jeffrey Namkung,Dohyung Kim,Rajesh K. Gupta,Igor Kozintsev,Jean-Yves Bouguet,Carole Dulong
#t2006
#cCODES+ISSS
#index106422
#%597458
#%419632
#%446225
#%489631
#%499370
#%252985
#%1082823
#!Simulating chip-multiprocessor systems (CMP) can take a long time. For single-threaded workloads, earlier work has shown the utility of phase analysis, that is identification of repetitive program behaviors, in reducing overall simulation time while maintaining an acceptable loss in accuracy. To cope with multithreaded workloads, a combination of phases from all executing threads must be taken into consideration since inter-thread interference may distort the homogeneity of each phases' true performance. Unfortunately, phase analysis does not work for multithreaded (MT) workloads because the possible phase combinations in an inherently nondeterministic execution model grows exponentially with the number of threads. To this end, we propose a new technique to reduce the number of simulation samples by synthesizing samples from similar phase combinations. We present a simple cost function for measuring the similarity between phase combinations and by using the individual thread samples from the similar phase combinations, a new sample can be constructed. This cost function provides a convenient control knob for exploiting tradeoffs between simulation speed and accuracy. Our experimental results show that in most cases, properly setting the cost function's threshold can yield a reduction in sampling by 90%, while maintaining error to less than 5%.

#*Layout aware design of mesh based NoC architectures.
#@Krishnan Srinivasan,Karam S. Chatha
#t2006
#cCODES+ISSS
#index106423
#%805785
#%141387
#%286820
#%142588
#%133110
#%437122
#%142009
#%141409
#%143071
#%1134533
#%142153
#!Design of System-on-Chip (SoC) with regular mesh based Network-on-Chip (NoC) consists of mapping processing cores to routers, and routing of the traffic traces on the topology such that power consumption is minimized, and performance constraints are satisfied. Technology scaling increases the contribution of the link power to the overall power consumption of the NoC. Since link power consumption is dependent on the length of the link, its contribution cannot be accurately estimated without system-level floorplanning. In this paper, we propose a novel design technique that integrates system-level floorplanning into the NoC design flow. Our technique invokes an existing floorplanner to generate an initial layout of the cores. This is followed by invocation of a novel low complexity algorithm that generates the mesh based NoC architecture with complete information of the floorplan. In comparison to an existing approach, our technique results in lower total power consumption and much lower link power consumption.

#*Demand paging for OneNAND Flash eXecute-in-place.
#@Yongsoo Joo,Yongseok Choi,Chanik Park,Sung Woo Chung,Eui-Young Chung,Naehyuck Chang
#t2006
#cCODES+ISSS
#index106424
#%144052
#%106225
#%437034
#%181385
#%436677
#%141487
#%142139
#%1078680
#%857904
#%858236
#!NAND flash memory can provide cost-effective secondary storage in mobile embedded systems, but its lack of a random access capability means that code shadowing is generally required, taking up extra RAM space. Demand paging with NAND flash memory has recently been proposed as an alternative which requires less RAM. This scheme is even more attractive for OneNAND flash, which consists of a NAND flash array with SRAM buffers, and supports eXecute-In-Place (XIP), which allows limited random access to data on the SRAM buffers.We introduce a novel demand paging method for OneNAND flash memory with XIP feature. The proposed on-line demand paging method with XIP adopts finite size sliding window to capture the paging history and thus predict future page demands. We particularly focus on non-critical code accesses which can disturb real-time code.Experimental results show that our method outperforms conventional LRU-based demand paging by 57% in terms of execution time and by 63% in terms of energy consumption. It even beats the optimal solution obtained from MIN, which is a conventional off-line demand paging technique by 30% and 40% respectively.

#*Efficient computation of buffer capacities for multi-rate real-time systems with back-pressure.
#@Maarten Wiggers,Marco Bekooij,Pierre G. Jansen,Gerard J. M. Smit
#t2006
#cCODES+ISSS
#index106425
#%1165870
#%1117788
#%106198
#%106169
#!A key step in the design of multi-rate real-time systems is the determination of buffer capacities. In our multi-processor system, we apply back-pressure as caused by bounded buffers in order to control jitter. This requires the derivation of buffer capacities that both satisfy the temporal constraints as well as constraints on the buffer capacity. Existing exact solutions suffer from the computational complexity associated with the required conversion from a multi-rate dataflow graph to a single-rate dataflow graph. In this paper we present an algorithm, with linear computational complexity, that does not require this conversion and that determines close to minimal buffer capacities. The algorithm is applied to an MP3 play-back application that is mapped on our network based multi-processor system.

#*System-level power-performance trade-offs in bus matrix communication architecture synthesis.
#@Sudeep Pasricha,Young-Hwan Park,Fadi J. Kurdahi,Nikil D. Dutt
#t2006
#cCODES+ISSS
#index106426
#%499553
#%52851
#%805785
#%141409
#%141552
#%450514
#%133543
#%286698
#%142393
#%142669
#%605149
#%281829
#%141557
#!System-on-chip communication architectures have a significant impact on the performance and power consumption of modern multi-processor system-on-chips (MPSoCs). However, customization of such architectures for an application requires the exploration of a large design space. Thus designers need tools to rapidly explore and evaluate relevant communication architecture configurations exhibiting diverse power and performance characteristics. In this paper we present an automated framework for fast system-level, application-specific, power-performance trade-offs in bus matrix communication architecture synthesis. Our paper makes two specific contributions. First, we develop energy macro-models for system-level exploration of bus matrix communication architectures. Second, we incorporate these macro-models into a bus matrix synthesis flow that enables designers to efficiently explore the power-performance design space of different bus matrix configurations. Experimental results show that our energy macro-models incur less than 5% average absolute error compared to gate-level models. Furthermore, our bus matrix synthesis framework generates a tradeoff space with designs that exhibits an approximately 20% variation in power and 40% variation in performance on an industrial networking MPSoC application, demonstrating the utility of our approach.

#*Data reuse driven energy-aware MPSoC co-synthesis of memory and communication architecture for streaming applications.
#@Ilya Issenin,Nikil Dutt
#t2006
#cCODES+ISSS
#index106427
#%133503
#%436518
#%52045
#%1135121
#%450514
#%132489
#%133010
#%142723
#%52849
#%53059
#%437215
#!The memory subsystem of a complex multiprocessor systems-on-chip (MPSoC) is an important contributor to the chip power consumption. The selection of memory architecture, as well as of communication architecture, both affect the power efficiency of the design. In this paper we propose a novel approach that enables energy-aware co-synthesis of both memory and communication architecture for streaming applications. As opposed to earlier techniques, we employ a powerful compile-time analysis of memory access behavior that adds flexibility in selecting memory architectures. Additionally, we target TDMA bus-based communication architectures, which not only guarantee performance, but also greatly reduce the design time and allow us to find the energy optimal system configuration. We propose and compare three techniques: an optimal mixed ILP-based co-synthesis technique, a mixed ILP-based traditional two-step synthesis approach where memory and communication synthesis is performed sequentially, and a co-synthesis heuristic that synthesizes energy-efficient hierarchical bus-based communication architectures with guaranteed throughput. Our experimental results on a number of streaming applications show that both the traditional two-step synthesis approach and heuristic result in up to 50% worse power consumption in comparison with proposed co-synthesis approach. However, on some of the streaming benchmarks, our co-synthesis heuristic approach was able to find optimal or near-optimal results in a much shorter time than the MILP co-synthesis approach.

#*A run-time, feedback-based energy estimation model For embedded devices.
#@Selim Gurun,Chandra Krintz
#t2006
#cCODES+ISSS
#index106428
#%596862
#%77637
#%53916
#%436623
#%436653
#%499185
#%436808
#%530354
#%499311
#!We present an adaptive, feedback-based, energy estimation model for battery-powered embedded devices such as sensor network gateways and hand-held computers. Our technique maps hardware and software counters to energy consumption values using a set of first order, linear regression equations. Our system is novel in that it combines online and offline techniques to enable runtime power prediction. Our system employs an offline instantiated model that it continuously updates using feedback from a readily available battery monitor within the device.We empirically evaluate our model and detail its robustness, accuracy, and computational cost. We also analyze the stability of the model in the presence of feedback errors. We demonstrate that our approach can achieve an error rate of 1% (extant techniques: 2.6% to 4%) for computationally bound tasks and 6.6% (extant techniques: 11%) for communication bound tasks.

#*BSim: : a fast micro-architecture simulator based on basic block characterization.
#@Wonbok Lee,Kimish Patel,Massoud Pedram
#t2006
#cCODES+ISSS
#index106429
#!State-of-the-art architectural simulators support cycle accurate pipeline execution of application programs. However, it takes days and weeks to complete the simulation of even a moderate-size program. During the execution of a program, program behavior does not change randomly but changes over time in a predictable/periodic manner. This behavior provides the opportunity to limit the use of a pipeline simulator. More precisely, this paper presents a hybrid simulation engine, named B2Sim for (cycle-characterized) Basic Block based Simulator, where a fast cache simulator e.g., sim-cache and a slow pipeline simulator e.g., sim-outorder are employed together. B2Sim reduces the runtime of architectural simulation engines by making use of the instruction behavior within executed basic blocks. We have integrated B2Sim into SimpleScalar and have achieved on average a factor of 3.3 times speedup on the SPEC2000 benchmark and Media-bench programs compared to conventional pipeline simulator while maintaining the accuracy of the simulation results with less than 1% CPI error on average.

#*Thermal-aware high-level synthesis based on network flow method.
#@Pilok Lim,Taewhan Kim
#t2006
#cCODES+ISSS
#index106430
#%282424
#%131371
#%446664
#%419433
#%406816
#%131677
#%1077149
#%132448
#%446501
#%281988
#%133263
#%436980
#%499311
#!Lowering down the chip temperature is becoming one of the important design considerations, since temperature adversely and seriously affects many of design qualities, such as reliability, performance and leakage power of chip, and also increases the packaging cost. In this work, we address a new problem of thermal-aware module binding in high-level synthesis, in which the objective is to minimize the peak temperature of the chip. The two key contributions are (1) to solve the binding problem with the primary objective of minimizing the 'peak' switched capacitance of modules and the secondary objective of minimizing the 'total' switched capacitance of modules and (2) to control the switched capacitances with respect to the floorplan of modules in a way to minimize the 'peak' heat diffusion between modules. For (1), our proposed thermal-aware binding algorithm, called TA-b, formulates the thermal-aware binding problem into a problem of repeated utilization of network flow method, and solve it effectively. For (2), TA-b is extended, called TA-bf, to take into account a floorplan information, if exists, of modules to be practically effective. From experiments using a set of benchmarks, it is shown that TA-bf is able to use 10.1°C and 11.8°C lower peak temperature on the average, compared to that of the conventional low-power and thermal-aware methods, which target to minimizing total switched capacitance only ([18]) and to minimizing peak switched capacitance only ([16]), respectively.

#*Application-specific workload shaping in multimedia-enabled personal mobile devices.
#@Balaji Raman,Samarjit Chakraborty
#t2006
#cCODES+ISSS
#index106431
#%106285
#%1117577
#%400864
#%134146
#%1011278
#%805601
#%858308
#%565043
#%436788
#%400718
#%142463
#%143236
#%927036
#%132350
#%519578
#%133057
#%613403
#%1134646
#%564994
#!Today, most personal mobile devices (e.g., cell phones and PDAs) are multimedia-enabled and support a variety of concurrently running applications, such as audio/video players, word processors, and web browsers. Media-processing applications are often computationally expensive and most of these devices typically have 100--400-MHz processors. As a result, the user-perceived application response times are often poor when multiple applications are concurrently fired. In this paper, we show that by using application-specific dynamic buffering techniques, the workload of these applications can be suitably &ldquo;shaped&rdquo; to fit the available processor bandwidth. Our techniques are analogous to traffic shaping, which is widely used in communication networks to optimally utilize network bandwidth. Such shaping techniques have recently attracted a lot of attention in the context of embedded systems design (e.g., for dynamic voltage scaling). However, they have not been exploited for enhanced schedulability of multiple applications, as we do in this paper.

#*SHAPES: : a tiled scalable software hardware architecture platform for embedded systems.
#@Pier Stanislao Paolucci,Ahmed Amine Jerraya,Rainer Leupers,Lothar Thiele,Piero Vicini
#t2006
#cCODES+ISSS
#index106432
#%49862
#%1135295
#%132734
#%1008371
#%805630
#%1008827
#%106224
#%142229
#%142230
#%141631
#%831825
#!Nanoscale systems on chip will integrate billion-gate designs. The challenge is to find a scalable HW/SW design style for future CMOS technologies. Tiled architectures suggest a possible path: "small" processing tiles connected by "short wires". A typical SHAPES tile contains a VLIW floating-point DSP, a RISC, a DNP (Distributed Network Processor), distributed on chip memory, the POT (a set of Peripherals On Tile) plus an interface for DXM (Distributed External Memory). The SHAPES routing fabric connects on-chip and off-chip tiles, weaving a distributed packet switching network. 3D next-neighbours engineering methodologies is adopted for off-chip networking and maximum system density. The SW challenge is to provide a simple and efficient programming environment for tiled architectures. SHAPES will investigate a layered system software, which does not destroy algorithmic and distribution info provided by the programmer and is fully aware of the HW paradigm. For efficiency and QoS, the system SW manages intra-tile and inter-tile latencies, bandwidths, computing resources, using static and dynamic profiling. The SW accesses the on-chip and off-chip networks through a homogeneous interface.

#*A smart random code injection to mask power analysis based side channel attacks.
#@Jude Angelo Ambrose,Roshan G. Ragel,Sri Parameswaran
#t2007
#cCODES+ISSS
#index106433
#%50105
#%86974
#%87100
#%1080842
#%1080837
#%188674
#%19209
#%77572
#%1098026
#%142941
#%457367
#%134084
#!One of the security issues in embedded system is the ability of an adversary to perform side channel attacks. Power analysis attacks are often very successful, where the power sequence dissipated by the system is observed and analyzed to predict secret keys. In this paper we show a processor architecture, which automatically detects the execution of the most common encryption algorithms, starts to scramble the power waveform by adding randomly placed instructions with random register accesses, and stops injecting instructions when it is safe to do so. Our technique prevents both Simple Power Analysis (SPA) and Differential Power Analysis (DPA). This approach has less overheads compared to previous solutions and avoids software instrumentation, allowing programmers with no special knowledge to use the system. Our processor model costs an additional area of 1.2%, and an average of 25% in runtime and 28.5% in energy overheads for industry standard cryptographic algorithms.

#*Locality optimization in wireless applications.
#@Javed Absar,Min Li,Praveen Raghavan,Andy Lambrechts,Murali Jayapala,Arnout Vandecappelle,Francky Catthoor
#t2007
#cCODES+ISSS
#index106434
#%542461
#%1123732
#%2286
#%360101
#%546411
#%1079918
#%360526
#%1123823
#!There is a strong need now for compilers of embedded systems to find effective ways of optimizing series of loop-nests, wherein majority of the memory references occur in the form of multi-dimensional arrays, indexed primarilywith linear functions of iterators and parameterized constants. The reason for this are the new wireless standards, e.g. 802.11n, WiMAX, Bluetooth, HIPERMAN, 3GPP-LTE and WiBro, where the codes are predominantly of the type described above. These standards provide high bitrate and mobility but are also extremely power and performance hungry. For even wider commercial applicability of these standards it is important to optimize their power consumption. We propose a novel solution to multiple loop-nest optimization problem using the concept of constraints. Experiments show that our technique leads to 40.8% reduction in external memory accesses over state-of-the-art.

#*Beyond gaming: programming the PLAYSTATION®3 cell architecture for cost-effective parallel processing.
#@Rodric M. Rabbah
#t2007
#cCODES+ISSS
#index106435
#%252743

#*Combined approach to system level performance analysis of embedded systems.
#@Simon Künzli,Arne Hamann,Rolf Ernst,Lothar Thiele
#t2007
#cCODES+ISSS
#index106436
#%106260
#%174538
#%1275423
#%174590
#%141631
#%565036
#%565100
#%133357
#%564564
#!Compositional approaches to system-level performance analysis have shown great flexibility and scalability in the design of heterogeneous systems. These approaches often assume certain system architectures and application domains, and are thus tailored to give tight analysis results for specific systems. We consider two different compositional analysis methods. Both methods have their particular strengths for different architectures and applications. In this paper, we aim to enhance the analysis capabilities for these techniques. A method for event model conversion allows us a seamless integration of the two methods. Finally, we present a detailed case study to show the applicability and benefits of the enhanced performance analysis technique.

#*Ensuring secure program execution in multiprocessor embedded systems: a case study.
#@Krutartha Patel,Sridevan Parameswaran,Seng Lin Shee
#t2007
#cCODES+ISSS
#index106437
#%542513
#%546557
#%106400
#%131299
#%141315
#%83800
#%806299
#%970483
#%83948
#%133639
#%1080226
#%77527
#%133655
#%1098650
#%499507
#%134295
#%143284
#%464576
#%252989
#!Multiprocessor SoCs are increasingly deployed in embedded systems with little or no security features built in. Code Injection attacks areone of the most commonly encountered security threats. Most solutions to this problem in the single processor domain are purely software based and have high overheads. A few hardware solutions have been provided for the single processor case, which significantly reduce overheads. In this paper, for the first time, we propose a methodology addressing code injection attacks in a multiprocessor domain. A dedicated security (monitor) processor is used to oversee the application at runtime. Each processor communicates with the monitor processor through a FIFO queue, and is continuously checked. Static analysis of program map and timing profile are used to obtain program information at compile time, which is utilized by the monitor processor at runtime. This information is encrypted using a secure key and stored in the monitor processor. A copy of this secure key is built into the processor's hardware and is used for decryption by the monitor processor. Each basic block of the program is also instrumented with security information that uniquely identifies itself at runtime. The information from static analysis thus allows the monitor processor to supervise the proceedings on each processor at runtime. Our approach uses a combination of hardware and software techniques to keep overheads to a minimum. We implemented our methodology on a commercial extensible processor (Xtensa LX). Our approach successfully detects the execution of injected code when tested on a JPEG multiprocessor benchmark. The results show a small increase of 6.6% in application processors' runtime (clock cycle count) and 35.2% in code size for the JPEG encoder benchmark.

#*Reliable multiprocessor system-on-chip synthesis.
#@Changyun Zhu,Zhenyu (Peter) Gu,Robert P. Dick,Li Shang
#t2007
#cCODES+ISSS
#index106438
#%106150
#%419433
#%419490
#%132358
#%50313
#%142669
#%161853
#%1080841
#%106020
#!This article presents a multiprocessor system-on-chip synthesis (MPSoC) algorithm that optimizes system mean time to failure. Given a set of directed acyclic periodic graphs of communicating tasks, the proposed algorithm determines a processor core allocation, level of system-level and processor-level structural redundancy, assignment of tasks to processors, floorplan, and schedule in order to minimize system failure rate and area while meeting functionality and timing constraints. Changes to the thermal profile resulting from changes in allocation, assignment, scheduling, and floorplan are modeled and optimized during synthesis, as is the impact of thermal profile on temperature-dependent failure mechanisms. The proposed techniques have the potential to substantially increase MPSoC system mean time to failure compared to area-optimized solutions. If power densities are high and the dominant lifetime failure mechanisms are strongly dependent on temperature, our results indicate that thermal and structural redundancy optimization during synthesis have the potential to greatly increase MPSoC lifetime with low area cost.

#*Incremental run-time application mapping for homogeneous NoCs with multiple voltage levels.
#@Chen-Ling Chou,Radu Marculescu
#t2007
#cCODES+ISSS
#index106439
#%499553
#%134383
#%131914
#%142588
#%134326
#%133301
#%133569
#%134754
#%141484
#!In this paper, we propose an efficient technique for run-time application mapping onto Network-on-Chip (NoC) platforms with multiple voltage levels. Our technique consists of a region selection algorithm and a heuristic for run-time application mapping which minimizes the communication energy consumption, while still providing the required performance guarantees. The proposed technique allows for new applications to be easily added to the system platform with minimal inter-processor communication overhead. Moreover, our approach scales very well for large designs. Finally, the experimental results show as much as 50% communication energy savings compared to arbitrary mapping solutions.

#*Thread warping: a framework for dynamic synthesis of thread accelerators.
#@Greg Stitt,Frank Vahid
#t2007
#cCODES+ISSS
#index106440
#%106270
#%214254
#%805680
#%106053
#%105979
#%483667
#%645223
#%214759
#%1117972
#%203321
#%133222
#%283198
#%9888
#!We present a dynamic optimization technique, thread warping, that uses a single processor on a multiprocessor system to dynamically synthesize threads into custom accelerator circuits on FPGAs (field-programmable gate arrays). Building on dynamic synthesis for single-processor single-thread systems, known as warp processing, thread warping improves performances of multiprocessor systems by speeding up individual threads and by allowing more threads to execute concurrently. Furthermore, thread warping maintains the important separation of function from architecture, enabling portability of applications to architectures with different quantities of microprocessors and FPGA.an advantage not shared by static compilation/synthesis approaches. We introduce a framework of architecture, CAD tools, and operating system that together support thread warping. We summarize experiments on an extensive architectural simulation framework we developed, showing application speedups of 4x to 502x, averaging 130x compared to a multiprocessor system having four ARM11 microprocessors, for eight benchmark applications. Even compared to a 64-processor system, thread warping achieves 11x speedup.

#*Predator: a predictable SDRAM memory controller.
#@Benny Akesson,Kees Goossens,Markus Ringhofer
#t2007
#cCODES+ISSS
#index106441
#%419363
#%141512
#%858022
#%858092
#%696671
#%143554
#%132350
#%143071
#%499537
#!Memory requirements of intellectual property components (IP) in contemporary multi-processor systems-on-chip are increasing. Large high-speed external memories, such as DDR2 SDRAMs, are shared between a multitude of IPs to satisfy these requirements at a low cost per bit. However, SDRAMs have highly variable access times that depend on previous requests. This makes it difficult to accurately and analytically determine latencies and the useful bandwidth at design time, and hence to guarantee that hard real-time requirements are met. The main contribution of this paper is a memory controller design that provides a guaranteed minimum bandwidth and a maximum latency bound to the IPs. This is accomplished using a novel two-step approach to predictable SDRAM sharing. First, we define memory access groups, corresponding to precomputed sequences of SDRAM commands, with known efficiency and latency. Second, a predictable arbiter is used to schedule these groups dynamically at run-time, such that an allocated bandwidth and a maximum latency bound is guaranteed to the IPs. The approach is general and covers all generations of SDRAM. We present a modular implementation of our memory controller that is efficientlyintegrated into the network interface of a network-on-chip. The area of the implementation is cheap, and scales linearly with the number of IPs. An instance with six ports runs at 200 MHz and requires 0.042mm2 in 0.13μm CMOS technology.

#*Performance and resource optimization of NoC router architecture for master and slave IP cores.
#@Glenn Leary,Krishna Mehta,Karam S. Chatha
#t2007
#cCODES+ISSS
#index106442
#%499553
#%142153
#%141439
#%285951
#%645560
#%990953
#%141387
#!System-on-Chip architectures incorporate several IP cores with well defined master and slave characteristics in terms of on-chip communication. The paper presents a parameterized NoC router architecture that can be optimized for performance and resource requirement by exploiting the master or slave behavior of the cores that are attached to it. We implemented the proposed router architecture for the IBM Coreconnect protocol and mapped it on the Xilinx Virtex series FPGA. We compared the FPGA based implementation against industry strength bus design that supports the IBM Coreconnect protocol, namely processor local bus (PLB). For similar resource requirements, our design demonstrated a 97.6% increase in throughput and 76.53% decrease in latency in comparison to the PLB. We also compared the proposed architecture with an existing NoC router design that is oblivious to master/slave IP cores. In the case of a router with all shared slaves our design resulted in 65.9% reduction in resources, 548% increase in throughput and 84.7% reduction in latency.

#*Compile-time decided instruction cache locking using worst-case execution paths.
#@Heiko Falk,Sascha Plazar,Henrik Theiling
#t2007
#cCODES+ISSS
#index106443
#%597721
#%174589
#%174482
#%189917
#%565406
#%825604
#!Caches are notorious for their unpredictability. It is difficult or even impossible to predict if a memory access results in a definite cache hit or miss. This unpredictability is highly undesired for real-time systems. The Worst-Case Execution Time (WCET) of a software running on an embedded processor is one of the most important metrics during real-time system design. The WCET depends to a large extent on the total amount of time spent for memory accesses. In the presence of caches, WCET analysis must always assume a memory access to be a cache miss if it can not be guaranteed that it is a hit. Hence, WCETs for cached systems are imprecise due to the overestimation caused by the caches. Modern caches can be controlled by software. The software can load parts of its code or of its data into the cache and lock the cache afterwards. Cache locking prevents the cache's contents from being flushed by deactivating the replacement. A locked cache is highly predictable and leads to very precise WCET estimates, because the uncertainty caused by the replacement strategy is eliminated completely. This paper presents techniques exploring the lockdown of instruction caches at compile-time to minimize WCETs. In contrast to the current state of the art in the area of cache locking, our techniques explicitly take the worst-case execution path into account during each step of the optimization procedure. This way, we can make sure that always those parts of the code are locked in the I-cache that lead to the highest WCET reduction. The results demonstrate that WCET reductions from 54% up to 73% can be achieved with an acceptable amount of CPU seconds required for the optimization and WCET analyses themselves.

#*Simultaneous synthesis of buses, data mapping and memory allocation for MPSoC.
#@Brett H. Meyer,Donald E. Thomas
#t2007
#cCODES+ISSS
#index106444
#%134314
#%133543
#%52851
#%142723
#%605149
#%282563
#%645264
#%133174
#%1134631
#!Heterogeneous multiprocessors are emerging as the dominant implementation approach to embedded multiprocessor systems. In addition to having processing elements suited to the target applications, these systems will also have custom memory and bus architectures. Because of performance and cost constraints, these systems must be carefully designed to balance system partitioning and resource sharing. The sheer size of the design space requires that tools be able to do this balancing. We have developed an augmented simulated annealing synthesis tool that uses system performance and layout evaluation to drive simultaneous data mapping, memory allocation and bus synthesis. Performing these optimizations at the same time, our tool is able to explore a larger design space and take advantage of cost-saving resource sharing unavailable to previous approaches that allocate memories before synthesizing buses. This results in 20% cost reduction for high-performance designs as well as 27% for low-cost designs in comparison with an approach that performs memory allocation and data mapping separately from bus synthesis.

#*Power deregulation: eliminating off-chip voltage regulation circuitry from embedded systems.
#@Seunghoon Kim,Robert P. Dick,Russ Joseph
#t2007
#cCODES+ISSS
#index106445
#%436610
#%418565
#%437062
#%450674
#%1117771
#%436580
#%413038
#%142422
#%437039
#%805613
#%53794
#!In battery-powered embedded systems, dedicated circuitry is used to convert stored energy into a form that can be directly used by processors. These power regulation devices seek to mask non-ideal aspects of the battery and present an ideal, fixed-voltage power source to the processor. However, this comes at a high price in terms of form factor, component cost, and energy efficiency. We describe and evaluate a new method for eliminating voltage regulation circuitry from battery-powered embedded systems. This method makes use of power gating, frequency scaling, and thread migration in chip-level multiprocessors to dynamically adjust to varying battery voltage. The key advantages of this approach are reduction in printed circuit board area (by 1/3 in many embedded applications) and the elimination of bulky unreliable discrete components such as electrolytic capacitors while maintaining similar battery lifespan. We have evaluated the power consumption, performance, and reliability implications of the proposed method using analytical techniques, power models, and detailed full-system simulation of numerous benchmarks from the ALPBench and MediaBench benchmark suites. For a number of battery technologies, the proposed technique holds the potential to eliminate power regulation circuitry and maintain battery lifespan while maintaining the same performance as systems using Buck-Boost voltage regulators.

#*Predictable execution adaptivity through embedding dynamic reconfigurability into static MPSoC schedules.
#@Chengmo Yang,Alex Orailoglu
#t2007
#cCODES+ISSS
#index106446
#%419335
#%1125646
#%1125254
#%1125030
#%134295
#%858022
#%141404
#%52161
#%1078569
#%616811
#%1126108
#%106020
#!Advances in semiconductor technologies have placed MPSoCs center stage as a standard architecture for embedded applications of ever increasing complexity. Because of real-time constraints, applications are usually statically parallelized and scheduled onto the target MPSoC so as to obtain predictable worst-case performance. However, both technology scaling trends and resource competition among applications have led to variations in the availability of resources during execution, thus questioning the dynamic viability of the initial static schedules. To eliminate this problem, in this paper we propose to statically generate a compact schedule with predictable response to various resource availability constraints. Such schedules are generated by adhering to a novel band structure, capable of spawning dynamically a regular reassignment upon resource variations. Through incorporating several soft constraints into the original scheduling heuristic, the proposed technique can furthermore exploit the inherent timing slack between dependent tasks, thus retaining the spatial and temporal locality of the original schedule. The efficacy of the proposed technique is confirmed by incorporating it into a widely adopted list scheduling heuristic, and experimentally verifying it in the context of single processor deallocations.

#*A data protection unit for NoC-based architectures.
#@Leandro Fiorin,Gianluca Palermo,Slobodan Lukovic,Cristina Silvano
#t2007
#cCODES+ISSS
#index106447
#%452280
#%805785
#%77524
#%131914
#%696666
#%106095
#!Security is gaining increasing relevance in the development of embedded devices. Towards a secure system at each level of design, this paper addresses the security aspects related to Network-on-Chip (NoC) architectures, foreseen as the communication infrastructure of next-generation embedded devices. In the context of NoC-based Multiprocessor systems, we focus on the topic, not thoroughly faced yet, of data protection. We present the architecture of a Data Protection Unit (DPU) designed for implementation within the Network Interface (NI). The DPU supports the capability to check and limit the access rights (none, read, write or both) of processors requesting access to data locations in a shared memory - in particular distinguishing between the operating roles (supervisor or user) of processing elements. We explore different alternative implementations and demonstrate how the DPU unit does not affect the network latency if the memory request has the appropriate rights. In the experimental section we show synthesis results for different ASIC implementations of the Data Protection Unit.

#*Compiling code accelerators for FPGAs.
#@Walid A. Najjar
#t2007
#cCODES+ISSS
#index106448
#!This tutorial addresses the challenges and opportunities presented by compiled FPGA-based code accelerators. In recent years we have witnessed a fast growth of both size and speed of FPGAs. These had been initially designed and marketed as convenient devices for "glue logic." Later, they became used as fast prototyping platforms. As their size and speed grew, they have been used for the short time to market they can afford. Lately, their size and speed have made them attractive as code accelerator. While the clock speed achievable on a typical FPGA design is about an order of magnitude lower than that on a typical CPU, their advantage comes from two sources: (1) Large degree of instruction and loop level parallelism. Parallel loops can typically be unrolled by factors ranging in the 100s. (2) Increased efficiency of hardware execution. The streaming of the data through a dedicated circuit eliminates a large number of support operations such as data fetch, address calculations, index management, loop control, etc. The combined higher efficiency and parallelism of hardware execution on FPGAs has been shown to result in speedups ranging from the 10s to the 1,000s over traditional processor on frequently executed code segments.

#*Scheduling and voltage scaling for energy/reliability trade-offs in fault-tolerant time-triggered embedded systems.
#@Paul Pop,Kåre Harbo Poulsen,Viacheslav Izosimov,Petru Eles
#t2007
#cCODES+ISSS
#index106449
#%1117821
#%1052996
#%52043
#%340998
#%1134333
#%565160
#%142147
#%142148
#%1080805
#%142760
#%1098543
#%283486
#!In this paper we present an approach to the scheduling and voltage scaling of low-power fault-tolerant hard real-time applications mapped on distributed heterogeneous embedded systems. Processes and messages are statically scheduled, and we use process re-execution for recovering from multiple transient faults. Addressing simultaneously energy and reliability is especially challenging because lowering the voltage to reduce the energy consumption has been shown to increase the transient fault rates. In addition, time-redundancy based fault-tolerance techniques such as re-execution and dynamic voltage scaling-based low-power techniques are competing for the slack in the schedules. Our approach decides the voltage levels and start times of processes and the transmission times of messages, such that the transient faults are tolerated, the timing constraints of the application are satisfied and the energy is minimized. We present a constraint logic programming-based approach which is able to find reliable and schedulable implementations within limited energy and hardware resources.

#*Performance analysis and design space exploration for high-end biomedical applications: challenges and solutions.
#@Iyad Al Khatib,Davide Bertozzi,Axel Jantsch,Luca Benini
#t2007
#cCODES+ISSS
#index106450
#%143462
#%80297
#%142397
#%233983
#%141557
#%141886
#%132680
#!High-end biomedical applications are a good target for specific-purpose system-on-chip (SoC) implementations. Human heart electrocardiogram (ECG) real-time monitoring and analysis is an immediate example with a large potential market. Today, the lack of scalable hardware platforms limits real-time analysis capabilities of most portable ECG analyzers, and prevents the upgrade of analysis algorithms for better accuracy. Multiprocessor system-on-chip (MPSoC) technology, which is becoming main-stream in the domain of high-performance microprocessors, is becoming attractive even for power-constrained portable applications, due to the capability to provide scalable computation horsepower at an affordable power cost. This paper illustrates one of the first comprehensive HW/SW exploration frameworks to fully exploit MPSoC technology to improve the quality of real-time ECG analysis.

#*On the impact of manufacturing process variations on the lifetime of sensor networks.
#@Siddharth Garg,Diana Marculescu
#t2007
#cCODES+ISSS
#index106451
#%131504
#%153543
#%77738
#%437323
#%143441
#%412900
#!As an emerging technology, sensor networks provide the ability to accurately monitor the characteristics of wide geographical areas over long periods of time. The lifetime of individual nodes in a sensor network depends strongly on the leakage power that the nodes dissipate in the idle state, especially for low-throughput applications. With the introduction of advanced low power design techniques, such as sub-threshold voltage design styles, and the migration of fabrication processes to smaller technology generations, variability in leakage power dissipation of the sensor nodes will lead to increased variability in their lifetimes. In this paper, we analyze how this increased variability in the lifetime of individual sensor nodes affects the performance and lifetime of the network as a whole. We demonstrate how sensor network designers can use the proposed analysis framework to trade-off the cost of a sensor network deployment with the performance it offers. Our results indicate that up to 37% improvement in the critical lifetime of a sensor network (defined as the expected time at which the sensor network becomes disconnected) can be obtained over a baseline design with a 20% increase in the cost of the individual sensor nodes.

#*A low power VLIW processor generation method by means of extracting non-redundant activation conditions.
#@Hirofumi Iwato,Keishi Sakanushi,Yoshinori Takeuchi,Masaharu Imai
#t2007
#cCODES+ISSS
#index106452
#%142585
#%1117705
#%450479
#%436534
#%141680
#%2353
#%282336
#%52500
#%437017
#!This paper proposes a low power VLIW processor generation method by automatically extracting non-redundant activation conditions of pipeline registers for clock gating. It is important for the best power reduction by clock gating to create control signals that can completely shut off redundant clock supplies for registers. In order to generate the control signals automatically, the proposed method utilizes high-level architecture information called Micro-Operation Descriptions, which describes a VLIW processor architecture. Exploiting the Micro-Operation Descriptions in a VLIW processor generation process, the proposed method automatically extracts the non-redundant activation conditions that can control clock gating to supply the minimum clocks to the pipeline registers. Using the non-redundant activation condition extraction, the proposed method achieves short calculation time and low area overhead; the proposed method can be applied to VLIW processor generation. Experimental results show that the VLIW processor generated with proposed method achieves power reduction about 60% compared to the non-clock-gated VLIW processor, and about 35% compared to the VLIW processor that is applied clock gating by PowerCompiler with negligible area overhead.

#*Influence of procedure cloning on WCET prediction.
#@Paul Lokuciejewski,Heiko Falk,Martin Schwarzer,Peter Marwedel,Henrik Theiling
#t2007
#cCODES+ISSS
#index106453
#%832280
#%189917
#%141846
#%189926
#%2346
#%1077161
#!For the worst-case execution time (WCET) analysis, especially loops are an inherent source of unpredictability and loss of precision. This is caused by the difficulty to obtain safe and tight information on the number of iterations executed by a loop in the worst case. In particular, data-dependent loops whose iteration counts depend on function parameters are extremely difficult to analyze precisely. Procedure cloning helps by making such data-dependent loops explicit within the source code, thus making them accessible for high-precision WCET analyses. This paper presents the effect of procedure cloning applied at the source-code level on worst-case execution time. Theoptimization generates specialized versions of functionsbeing called with constant values as arguments. In standardliterature, it is used to enable further optimizations like constant propagation within functions and to reduce calling overhead. We show that procedure cloning for WCET minimization leads to significant improvements. Reductions of the WCET from 12% up to 95% were measured for real-life benchmarks. These results demonstrate that procedure cloning improves analyzability and predictability of real-time applications dramatically. In contrast, average-case performance as the criterion procedure cloning was developed for is reduced by only 3% at most. Our results also show that these WCET reductions only implied small overhead during WCET analysis.

#*HySim: a fast simulation framework for embedded software development.
#@Stefan Kraemer,Lei Gao,Jan Weinstock,Rainer Leupers,Gerd Ascheid,Heinrich Meyr
#t2007
#cCODES+ISSS
#index106454
#%548306
#%133591
#%359982
#%419632
#%133297
#%106383
#%77661
#%132531
#%132647
#%142230
#%282972
#%446352
#%53716
#%1082823
#%143313
#!Instruction Set Simulation (ISS) is widely used in system evaluation and software development for embedded processors. Despite the significant advancements in the ISS technology, it still suffers from low simulation speed compared to real hardware. Especially for embedded software developers simulation speed close to real time is important in order to efficiently develop complex software. In this paper a novel, retargetable, hybrid simulation framework (HySim) is presented which allows switching between native code execution and ISS-based simulation. To reach a certain state of an application as fast as possible, all platform-independent parts of the application are directly executed on the host, while the platform dependent code executes on the ISS. During the native code execution a performance estimation is conducted. A case study shows that speed-ups ranging from 7x to 72x can be achieved without compromising debugging accuracy. The performance estimation during native code execution shows an average error of 9.5%.

#*Pointer re-coding for creating definitive MPSoC models.
#@Pramod Chandraiah,Rainer Dömer
#t2007
#cCODES+ISSS
#index106455
#%542537
#%601337
#%546769
#%1123831
#%1008187
#%546090
#%483117
#%576818
#%1117720
#%530346
#!Today's MPSoC synthesis and exploration design flows start from an abstract input specification model captured in a system level design language. Usually this model is created from a C reference code by encapsulating the computation and the communication using behaviors and channels. However, often pointers in the reference code hamper the necessary analysis and transformations. In this paper, we present an automated approach to re-code and eliminate pointers. By re-coding the pointer accesses to the actual variables, MPSoC models with definitive computational blocks that communicate using explicit channels become possible. Our pointer re-coding approach not only increases synthesizeability, analyzeability and verifiability by system tools, but also helps the designer in program comprehension. Our experiments show that this approach is not only feasible, but also effective in creating better models of real-life applications in shorter time.

#*HW/SW co-design for Esterel processing.
#@Sascha Gädtke,Claus Traulsen,Reinhard von Hanxleden
#t2007
#cCODES+ISSS
#index106456
#%1117811
#%132535
#%53918
#%181280
#!We present a co-synthesis approach that accelerates reactive software processing by moving the calculation of complex expressions into external combinational hardware. The starting point is a system model written in the synchronous language Esterel, which can be mapped to both hardware and software. Our approach performs the partitioning at the source-code level and preserves the original, strictly synchronous semantics. It is thus platform-independent and allows to use standard simulation and synthesis tools. Furthermore, the source-level partitioning approach presented here should be applicable to non-reactive processing platforms as well. However, the challenge is to partition the program without changing its meaning under any circumstances. In particular, signal scopes and inter-partition signal dependencies must be maintained, which rules out a naive top-level partitioning. We have implemented the co-synthesis approach based on the Columbia Esterel Compiler and have validated it on the Kiel Esterel Processor. As the experimental results confirm, this can significantly reduce execution times and energy consumption per reaction, with minimal additional hardware requirements.

#*Performance improvement of block based NAND flash translation layer.
#@Siddharth Choudhuri,Tony Givargis
#t2007
#cCODES+ISSS
#index106457
#%1124089
#%523749
#%832611
#%807096
#%623741
#%283397
#!With growing capacities of flash memories, an efficient layer to manage read and write access to flash is required. NFTL is a widely used block based flash translation layer designed to manage NAND flash memories. NFTL is designed to achieve fast write times at the expense of slower read times. While traditionally, it is assumed that the read traffic to secondary storage is insignificant, as reads are cached, we show that this need not be true for NAND flash based storage due to garbage collection and reclamation processes. In this work, we present two independent techniques that extend NFTL and improve the read throughput in particular. The techniques presented add a minimal amount of RAM overhead to a flash controller, while providing, on an average, a 22.9% improvement in page read times and a 2.6% improvements in page write times on a set of file system and rigorous synthetic benchmarks. The techniques presented are well suited for flash controllers that are typically space constrained and have minimal processing power.

#*Energy efficient co-scheduling in dynamically reconfigurable systems.
#@Pao-Ann Hsiung,Pin-Hsien Lu,Chih-Wen Liu
#t2007
#cCODES+ISSS
#index106458
#%203308
#%106020
#%52425
#%77551
#%282244
#%142855
#%133589
#%142929
#%646009
#%1098555
#!Energy consumption is a major issue in dynamically reconfigurable systems because of the high power requirements during repeated configurations. Hardware designs employ low power techniques such as configuration prefetch and reuse. Software designs restrain energy usage by dynamically scaling the voltage of processors. However, when these techniques are implemented in a system, they might be conflicting and thus cancel their mutual benefits, which results in high power consumption and low performance. We propose run-time co-scheduling of hardware and software tasks by using the slack time, which is introduced due to reusing hardware task configurations, for dynamically scaling the processor voltage such that preceding software tasks consume lesser power. At the same time, the reuse of hardware task configurations also result in lower power consumption and higher performance due to fewer number of reconfigurations. The combined effects of hardware configuration reuse and software dynamic voltage scaling result in schedules with a lower power consumption and higher performance than that obtained through individual techniques applied to hardware and software separately. We performed extensive experiments whose results show that irrespective of different slack ratios, number of voltage levels, or hardware partitions, the schedules generated by our proposed method are more energy efficient than methods that either do not apply any runtime techniques or only apply hardware configuration prefetch and reuse.

#*A computational reflection mechanism to support platform debugging in SystemC.
#@Bruno Albertini,Sandro Rigo,Guido Araujo,Cristiano C. de Araujo,Edna Barros,Willians Azevedo
#t2007
#cCODES+ISSS
#index106459
#%1098641
#%573793
#%918425
#%522142
#!System-level and Platform-based design, along with Transaction Level modeling (TLM) techniques and languages like SystemC, appeared as a response to the ever increasing complexity of electronics systems design, where complex SoCs composed of several modules integrated on the same chip have become very common. In this scenario, the exploration and verification of several architecture models early in the design flow has played an important role. This paper proposes a mechanism that relies on computational reflection to enable designers to interact, on the fly, with platform simulation models written in SystemC TLM. This allows them to monitor and change signals or even IP internal register values, thus injecting specific stimuli that guide the simulation flow through corner cases during platform debugging, which are usually hard to handle by standard techniques, thus improving functional coverage. The key advantages of our approach are that we do not require code instrumentation from the IP designer, do not need a specialized SystemC library, and not even need the IP source code to be able to inspect its contents. The reflection mechanism was implemented using a C++ reflection library and integrated into a platform modeling framework. We evaluate our technique through some platform case studies.

#*Event-based re-training of statistical contention models for heterogeneous multiprocessors.
#@Alex Bobrek,JoAnn M. Paul,Donald E. Thomas
#t2007
#cCODES+ISSS
#index106460
#%106042
#%1008759
#%134668
#%141532
#%106094
#%133541
#!Embedded single-chip heterogeneous multiprocessor (SCHM) systems experience frequent system events such as task pre-emption, power-saving voltage/frequency scaling, or arrival of new events/data from the outside world. Traditionally, the designers model these events by explicitly coupling them to corresponding simulation events within environments such as SystemC. However, this approach places a burden on the designer to identify which events are important enough to be captured by simulation, resulting in an overly conservative selection of events to model. This work presents a technique for de-coupling of system events from simulation events, removing the burden from the designer to determine which events significantly affect the system performance model, while decreasing simulation runtime. Enabling this de-coupling is a prediction model that quantifies the magnitude of changes introduced by system events, and identifies those important enough to be considered simulation events. The prediction model is evaluated by over 4000 separate scenarios featuring dynamic event changes to processor speed, bus speed, application type, and application input data, finding that almost 70% of tested events impacted contention modeling by less than 10%. Without resorting to detailed simulation, the prediction model captures the system event effects to within 5% of actual measured error, while staying within 18% in 95% of all tests.

#*Automotive networks: are new busses and gateways the answer or just another challenge?
#@Rolf Ernst,Gernot Spiegelberg,Thomas Weber,Hermann Kopetz,Alberto L. Sangiovanni-Vincentelli,Marek Jersak
#t2007
#cCODES+ISSS
#index106461
#!For many years, the automotive network was a set of isolated field buses used for independent applications. Now, gateways are used to allow the exchange of sensor data, diagnostics, and signalling for networked control. The approved design and certification process developed around the CAN bus does not easily scale to such larger networks and to interdependent embedded systems functions. With the new FlexRay bus standard, much higher bandwidth is provided. Combined with higher performance configurable gateways, there is a good chance that next generation network bandwidth requirements will be met. However, higher bandwidth does not necessarily mean better real-time or safety properties. Also, the automotive network is still widely seen as a collection of network components that are configured by the OEM to fit an individual set of automotive functions. How does this approach match the new automotive software standard, AUTOSAR, which defines a new level of interoperability and portability hiding much of the embedded platform properties from the application software. Would it be more appropriate to switch to an integrated automotive network that offers performance and safety guarantees based on formally defined performance and safety parameters and leave it to an independent network development how to reach such QoS data? Or are such integrated networks - as known from telecom - inappropriate and will be inferior, given the very complex function dependencies and cost pressure?. There are many more questions in this context: are the current protocols, architectures, design methods, and tools appropriate? What innovations are most urgently needed? who shall develop the networks in the future, the OEM or a 1st tier supplier? What would be the consequence for the design process? Do we need interoperable network service standards, e.g. as a complement to AUTOSAR? Will there be a unified automotive "internet protocol" that eventually dominates all communication in a car? How will future car-to-car communication be included in the automotive network strategy if it shall be used for real-time applications, such as in driver assistance systems?. The panel will start with a brief overview on the state of the art in automotive networking followed by the panel statements and discussion.

#*Channel trees: reducing latency by sharing time slots in time-multiplexed networks on chip.
#@Andreas Hansson,Martijn Coenen,Kees Goossens
#t2007
#cCODES+ISSS
#index106462
#%106418
#%161184
#%578593
#%55063
#%141515
#%131914
#%858022
#%141969
#%106121
#%142537
#!Networks on Chip (NoC) have emerged as the design paradigm for scalable System on Chip communication infrastructure. A growing number of applications, often with firm (FRT) or soft real-time (SRT) requirements, are integrated on the same chip. To provide time-related guarantees, NoC resources are reserved, e.g. by non-work-conserving time-division multiplexing (TDM). Traditionally, reservations are made on a per-communication-channel basis, thus providing FRT guarantees to individual channels. For SRT applications, this strategy is overly restrictive, as slack bandwidth is not used to improve performance. In this paper we introduce the concept of channel trees, where time slots are reserved for sets of communication channels. By employing work-conserving arbitration within a tree, we exploit the inherent single-threaded behaviour of the resource at the root of the tree, resulting in a drastic reduction in both average-case latency and TDM-table size. We show how channel trees enable us to halve the latter in a car entertainment SoC, and reduce the average latency by as much as much as 52% in a mobile phone SoC. By applying channel trees to an H264 decoder SoC, we increase processor utilisation by 25%.

#*Improved response time analysis of tasks scheduled under preemptive Round-Robin.
#@Razvan Racu,Li Li,Rafik Henia,Arne Hamann,Rolf Ernst
#t2007
#cCODES+ISSS
#index106463
#%297512
#%1053257
#%481916
#%565211
#%1054359
#%890906
#!Round-Robin scheduling is the most popular time triggered scheduling policy, and has been widely used in communication networks for the last decades. It is an efficient scheduling technique for integration of unrelated system parts, but the worst-case timing depends on the system properties in a very complex way. The existing works on response time analysis of task scheduled under Round-Robin determine very pessimistic response time bounds, without considering in detail the interactions between tasks. This may lead to a degradation of the efficiency of Round-Robin scheduling algorithm, and becomes a practical obstacle to its application in real-time systems. In this paper we present an approach to compute much tighter best-case and worst-case response time bounds of tasks scheduled under preemptive Round-Robin, including also the effects of the scheduling algorithm.

#*Dynamic security domain scaling on symmetric multiprocessors for future high-end embedded systems.
#@Hiroaki Inoue,Akihisa Ikeno,Tsuyoshi Abe,Junji Sakai,Masato Edahiro
#t2007
#cCODES+ISSS
#index106464
#%636411
#%636189
#%636249
#%890233
#%613072
#%106160
#%132477
#!We propose a method for dynamic security domain scaling on SMPs that offers both highly scalable performance and high security for future high-end embedded systems. Its most important feature is its highly efficient use of processor resources, accomplished by dynamically changing the number of processors within a security domain in response to application load requirements. Two new technologies make this scaling possible without any virtualization software: 1) self-transition management and 2) unified virtual address mapping. Evaluations show that this domain control provides highly scalable performance and incurs almost no performance overhead in security domains. The increase in binary code size is less than 40KB, and the time required for individual state transitions is of a single-millisecond order. This scaling is the first in the world to make possible dynamic changing of the number of processors within a security domain on an ARM SMP.

#*Synchronization after design refinements with sensitive delay elements.
#@Tarvo Raudvere,Ingo Sander,Axel Jantsch
#t2007
#cCODES+ISSS
#index106465
#%879028
#%131214
#%281728
#%879075
#%131621
#%1128272
#%282735
#%234466
#!The synchronous computational model with its simple computation and communication mechanism makes it easy to describe, simulate and formally verify synchronous embedded systems at a high level of abstraction. In synchronous models, a local refinement increasing the delay in a single computation block may affect the functionality of the entire model. We provide a synchronization algorithm that preserves the system's functionality after design refinements, by using additional synchronization delays and making some delays sensitive to their input values. The refined and synchronized model stays latency equivalent to the original model. The advantages of our approach are the following: (a) we remain fully within the synchronous model of computation, (b) we preserve the functionality of the existing computation blocks, and (c) we do not require additional computation resources, specific communication protocols, wrapper circuits around computation blocks or schedulers.

#*Temperature-aware processor frequency assignment for MPSoCs using convex optimization.
#@Srinivasan Murali,Almir Mutapcic,David Atienza,Rajesh Gupta,Stephen P. Boyd,Giovanni De Micheli
#t2007
#cCODES+ISSS
#index106466
#%360682
#%133618
#%437131
#%565021
#%252708
#%1008747
#%283137
#%174417
#%448277
#%282179
#%52747
#%53212
#%1077149
#%499225
#%446381
#%446438
#%142120
#%418687
#%131321
#%142691
#%52675
#%141409
#%1008688
#!The increasing processing capability of Multi-Processor Systems-on-Chips (MPSoCs) is leading to an increase in chip power dissipation, which in turn leads to significant increase in chip temperature. An important challenge facing the MPSoC designers is to achieve the highest performance system operation that satisfies the temperature and power consumption constraints. The frequency of operation of the different processors and the application workload assignment play a critical role in determining the performance, power consumption and temperature profile of the MPSoC. In this paper, we propose novel convex optimization based methods that solve this important problem of temperature-aware processor frequency assignment, such that the total system performance is maximized and the temperature and power constraints are met. We perform experiments on several realistic SoC benchmarks using a cycle-accurate FPGA-based thermal emulation platform, which show that the systems designed using our methods meet the temperature and power consumption requirements at all time instances, while achieving maximum performance.


#*Bridging gap between simulation and spreadsheet study.
#@Antoine Perrin,Frank Ghenassia
#t2007
#cCODES+ISSS
#index106467
#!System architects working on SoC design have traditionally been hampered by the lack of a cohesive methodology for architecture evaluation and co-verification of hardware and software. This paper focuses on a comprehensive analysis framework providing platform assembly facilities, system analysis tools, enhanced traffic model and SystemC TLM IP. This framework has been intensively used to design and analyze complex SOC Interconnect based on STBus protocol such as the one of 71xx families. By hiding the complexity of a simulation and filling the gap towards spreadsheet study and costly On-Chip analysis using traffic model, architects benefit from an easy access to an efficient simulation for performance evaluation.

#*A framework for rapid system-level exploration, synthesis, and programming of multimedia MP-SoCs.
#@Mark Thompson,Hristo Nikolov,Todor Stefanov,Andy D. Pimentel,Cagkan Erbas,Simon Polstra,Ed F. Deprettere
#t2007
#cCODES+ISSS
#index106468
#%106306
#%805701
#%450592
#%106394
#%1098612
#%141599
#%133010
#%132531
#%858471
#%133131
#%1081312
#%143072
#!In this paper, we present the Daedalus framework, which allows for traversing the path from sequential application specification to a working MP-SoC prototype in FPGA technology with the (parallelized) application mapped onto it in only a matter of hours. During this traversal, which offers a high degree of automation, guidance is provided by Daedalus' integrated system-level design space exploration environment. We show that Daedalus offers remarkable potentials for quickly experimenting with different MP-SoC architectures and exploring system-level design options during the very early stages of design. Using a case study with a Motion-JPEG encoder application, we illustrate Daedalus' design steps and demonstrate its efficiency.

#*Probabilistic performance risk analysis at system-level.
#@Alexander Viehl,Markus Schwarz,Oliver Bringmann,Wolfgang Rosenstiel
#t2007
#cCODES+ISSS
#index106469
#%485247
#%106300
#%106413
#%174571
#%141404
#%805601
#%564943
#%1117150
#%141631
#%132196
#%1098622
#%142475
#%1117545
#%1117968
#%53191
#%143299
#%287030
#!We present a novel hybrid approach for performance analysis of a system design. Unlike other approaches in this area, in this paper we do not focus on the determination of pessimistic best-case and worst-case quantities of system properties. Our proposed analysis methodology determines qualitative numbers between best-case and worst-case of system properties and quantifies them with probabilities. For this issue, we combine local coarse-grained profiling and formal system-level analysis models in a hybrid approach for an early quantitative determination of qualitative system properties. Our approach considers the control-flow of communicating processes and the impact of blocking communication instances on the temporal behavior of the entire system during formal analysis. This can be used for determining the global system performance. The application of our new methodology leads to an inclusion of probabilities concerning system properties and allows an early performance risk estimation of a design with regard to predefined system requirements and constraints.

#*Smart driver for power reduction in next generation bistable electrophoretic display technology.
#@Michael A. Baker,Aviral Shrivastava,Karam S. Chatha
#t2007
#cCODES+ISSS
#index106470
#%436639
#%77556
#%141719
#!Microencapsulated electrophoretic displays (EPDs) are quickly emerging as an important technology for use in battery-powered portable computing devices. Thanks to bistability and their efficient reflective nature, these displays offer power savings on the order of 90% over liquid crystal displays (LCDs) commonly found in today's portable devices. EPD technology is also suitable for use in flexible displays opening the door for integrating much larger displays into small form factors for hand-held devices. Here we present a method for power reduction in next generation EPD displays with full color and video capability. A "smart driver" for power optimization of next-generation bistable displays is presented which reduces switching power consumption by as much as 50% without affecting quality of service. A more aggressive "lazy driver" capable of achieving significant additional energy savings in exchange for quality of service is also presented. Finally, important challenges engineers face as they work to advance EPD technology for use in future generation hand-held computing devices are explored.

#*Embedded software development on top of transaction-level models.
#@Wolfgang Klingauf,Robert Günzel,Christian Schröder
#t2007
#cCODES+ISSS
#index106471
#%106397
#%857995
#%53173
#%142066
#%132727
#%142552
#%52982
#!Early embedded SW development with transaction-level models has been broadly promoted to improve SoC design productivity. But the proposed APIs only provide low-level read/write operations via a TLM interconnect. SW developers have to implement platform-specific communication procedures and handshake protocols to access HW functions, which requires a deep understanding of both the HW interfaces and the TLM fabric used. In this paper, we propose our concept of hardware procedure calls (HPC) with which HW services are provided to SW processes as remote methods on top of transaction-level communication. To this end, a lightweight HPC protocol is presented, and we propose a method to generate the infrastructure for HPC communication from a straightforward input description. Our experiments show that with HPC, embedded SW development is considerably made easier, and that also the effort to create the transaction-level model itself is reduced.

#*Fresh air: the emerging landscape of design for networked embedded systems.
#@Radu Marculescu,Borivoje Nikolic,Alberto L. Sangiovanni-Vincentelli
#t2007
#cCODES+ISSS
#index106472
#!This session consists of three talks addressing the fundamental challenges and new approaches for communication-centric design of future systems and applications.

#*Three-dimensional multiprocessor system-on-chip thermal optimization.
#@Chong Sun,Li Shang,Robert P. Dick
#t2007
#cCODES+ISSS
#index106473
#%419433
#%142970
#%1008306
#%890961
#%499572
#%143464
#%447964
#%806847
#%133010
#%282164
#%1080841
#%436764
#%282558
#%133263
#%52301
#%142691
#%1165276
#%281988
#%282179
#!3D stacked wafer integration has the potential to improve multiprocessor system-on-chip (MPSoC) integration density, performance, and power efficiency. However, the power density of 3D MPSoCs increases with the number of active layers, resulting in high chip temperatures. This can reduce system reliability, reduce performance, and increase cooling cost. Thermal optimization for 3D MPSoCs imposes numerous challenges. It is difficult to manage assignment and scheduling of heterogeneous workloads to maintain thermal safety. In addition, the thermal characteristics of 3D MPSoCs differ from those of 2D MPSoCs because each stacked layer has a different thermal resistance to the ambient and vertically-adjacent processors have strong temperature correlation. We propose a 3D MPSoC thermal optimization algorithm that conducts task assignment, scheduling, and voltage scaling. A power balancing algorithm is initially used to distribute tasks among cores and active layers. Detailed thermal analysis is used to guide a hotspot mitigation algorithm that incrementally reduces the peak MPSoC temperature by appropriately adjusting task execution times and voltage levels. The proposed algorithm considers leakage power consumption and adapts to inter-layer thermal heterogeneity. Performance evaluation on a set of multiprogrammed and multithreaded benchmarks indicates that the proposed techniques can optimize 3DMPSoC power consumption, power profile, and chip peak temperature.

#*A code-generator generator for multi-output instructions.
#@Hanno Scharwächter,Jonghee M. Youn,Rainer Leupers,Yunheung Paek,Gerd Ascheid,Heinrich Meyr
#t2007
#cCODES+ISSS
#index106474
#%142020
#%141
#%759
#%131287
#%282591
#%77722
#%1123225
#%546145
#%132647
#%837948
#%578566
#!We address the problem of instruction selection for Multi-Output Instructions (MOIs), producing more than one result. Such inherently parallel hardware instructions are very common in the area of Application Specific Instruction Set Processors (ASIPs) and Digital Signal Processors (DSPs) which are frequently used in System-on-Chips as programmable cores. In order to provide high-level programmability, and consequently guarantee widespread acceptance, sophisticated compiler support for these programmable cores is of high importance. Since it is not possible to model Multi-Output Instructions as trees in the compiler's Intermediate Representation (IR), traditional approaches for code selection are not sufficient. Extending traditional code-generation approaches for MOI-selection is essentially a graph covering problem, which is known to be NP-complete. We present a new heuristic algorithm incorporated in a retargetable code-generator generator capable of exploiting arbitrary inherently parallel MOIs. We prove the concept by integrating the tool into the LCC compiler which has been targeted towards different Instruction Set Architectures based on the MIPS architecture. Several network applications as well as some DSP benchmarks were compiled and evaluated to obtain results.

#*Complex task activation schemes in system level performance analysis.
#@Wolfgang Haid,Lothar Thiele
#t2007
#cCODES+ISSS
#index106475
#%174538
#%141631
#%53043
#!The design and analysis of today's complex real-time systems requires advanced methods. Due to ever growing functionality, hardware complexity and component interaction, applying traditional methods like HW/SW cosimulation is getting increasingly difficult. On the other hand, analytic approaches have proven their usefulness and efficiency for system analysis when end-to-end performance figures like delay, throughput and memory consumption are requested. One of the main drawbacks of these methods is the limited set of systems that can be analyzed with high accuracy: Only simple models for task interaction and task semantics can be used. In this paper, we extend existing methods for analyzing heterogeneous multiprocessor systems such that (a) nonpreemptive scheduling policies, (b) complex activation schemes for tasks and (c) conditional behavior of task executions can be modeled and analyzed. We demonstrate the usefulness of the proposed approach in a case study.

#*Performance modeling for early analysis of multi-core systems.
#@Reinaldo A. Bergamaschi,Indira Nair,Gero Dittmann,Hiren D. Patel,Geert Janssen,Nagu R. Dhanwada,Alper Buyuktosunoglu,Emrah Acar,Gi-Joon Nam,Dorothy Kucar,Pradip Bose,John A. Darringer,Guoling Han
#t2007
#cCODES+ISSS
#index106476
#%418565
#%807885
#%805601
#%890249
#%890830
#!Performance analysis of microprocessors is a critical step in defining the microarchitecture, prior to register-transfer-level (RTL) design. In complex chip multiprocessor systems, including multiple cores, caches and busses, this problem is compounded by complex performance interactions between cores, caches and interconnections, as well as by tight interdependencies between performance, power and physical characteristics of the design (i.e., floorplan). Although there are many point tools for the analysis of performance, or power, or floorplan of complex systems-on-chip (SoCs), there are surprisingly few works on an integrated tool that is capable of analyzing these various system characteristics simultaneously and allow the user to explore different design configurations and their effect on performance, power, size and thermal aspects. This paper describes an integrated tool for early analysis of performance, power, physical and thermal characteristics of multi-core systems. It includes cycle-accurate, transaction-level SystemC-based performance models of POWER processors and system components (i.e., caches, buses). Power models, for power computation, physical models for floorplanning and packaging models for thermal analysis are also included. The tool allows the user to build different systems by selecting components from a library and connecting them together in a visual environment. Using these models, users can simulate and dynamically analyze the performance, power and thermal aspects of multi-core systems.


#*ESL design and HW/SW co-verification of high-end software defined radio platforms.
#@A. C. H. Ng,J. W. Weijers,Miguel Glassee,Thomas Schuster,Bruno Bougard,Liesbet Van der Perre
#t2007
#cCODES+ISSS
#index106477
#%1135505
#%142263
#!Multiple wireless technologies are converging to run on personal handhelds. The plethora of communication standards next to the cost issues of deeper submicron processing require handheld platforms to shift from sets of multiple application specific ICs (ASICs) to multi-purpose Multi-Processor System-on-Chip (MPSoC) on which Software Defined Radios (SDR) are run. SDR design faces hard real-time processing and data transfer latency constraints. Designing SDR under stringent time-to-market (cost), energy and real-time processing constraints requires the help of advanced Electronic System-Level (ESL) design methodologies. This paper demonstrates an integrated ESL design flow built on advanced ESL tools to design SDR platforms for handhelds. We share the experience from creation of a high-level virtual platform model down to hardware/software (HW/SW) co-verification of a large scale SoC (5 million gates+). Incremental RTL verification based on co-simulation and co-emulation is also presented.

#*Specification and OS-based implementation of self-adaptive, hardware/software embedded systems.
#@Yvan Eustache,Jean-Philippe Diguet
#t2008
#cCODES+ISSS
#index106478
#%142534
#!This paper presents our solution for specifying and implementing self-adaptivness within an OS-based and reconfigurable embedded system according to objectives such as quality of service (QoS), performance or power consumption. More precisely, we detail our approach to separate, at runtime, application-specific decisions and hardware/software implementation decisions at system level. The first ones are related to the control of the efficiency of applications, they are specified in Local Configuration Managers (LCM) based on the knowledge of application engineers. The second ones are generic and address the choice between various hardware and software implementations according to observations of the gap between online measurements and objectives set by the user, these decisions are implemented in the Global Configuration Manager (GCM) as an adaptive close-loop model. We have designed a video tracking application on an FPGA to demonstrate the effectiveness of our solution, results are given for a system built around a NIOS soft-core with ¼COS II RTOS and new services for managing hardware and soft-ware tasks transparently.

#*Hardware/software partitioning of floating point software applications to fixed-pointed coprocessor circuits.
#@Lance Saldanha,Roman L. Lysecky
#t2008
#cCODES+ISSS
#index106479
#%106035
#%132357
#%141622
#%562534
#%214341
#%142000
#%214383
#%142227
#%499311
#%1117972
#%77523
#%133881
#%106307
#%1098520
#%77626
#!While hardware/software partitioning has been shown to provide significant performance gains, most hardware/software partitioning approaches are limited to partitioning computational kernels utilizing integers or fixed point implementations. Software developers often initially develop an application using built-in floating point representations and later convert the application to a fixed point representation - a potentially time consuming process. In this paper, we present a hardware/software partitioning approach for floating point applications that eliminates the need for developers to rewrite software applications for fixed point implementations. Instead, the proposed approach incorporates efficient, configurable floating point to fixed point and fixed point to floating point hardware converters at the boundary between the hardware coprocessors and memory. This effectively separates the system into a floating point domain consisting of the microprocessor and memory subsystem and a fixed point domain consisting of the partitioned hardware coprocessors, thereby providing an efficient and rapid method for implementing fixed point hardware coprocessors.

#*Software optimization for MPSoC: a mpeg-2 decoder case study.
#@Eric Cheung,Harry Hsieh,Felice Balarin
#t2008
#cCODES+ISSS
#index106480
#%106044
#%142533
#%857832
#%1073737
#%131712
#%196769
#%77570
#%133131
#%133459
#%1098520
#%134232
#%134403
#!Using traditional software profiling to optimize embedded software in an MPSoC design is not reliable. With multiple processors running concurrently and programs interacting, traditional profiling on individual processors cannot capture useful execution information to assist software optimization. A new method to model parallel executions of interacting programs is needed. In this paper, we consider the software optimization problem for throughput-constrained MPSoC designs. We define the "longest delay path" as a sequence of steps leading to a throughput constraint violation and propose an algorithm to build up the path dynamically during simulation. Using an industrial-strength MPEG-2 decoder design in our case study and custom instructions for software optimization, we show that we can optimize the software efficiently in MPSoC designs using frequently executed statement information from the longest delay path.

#*ODOR: a microresonator-based high-performance low-cost router for optical networks-on-Chip.
#@Huaxi Gu,Jiang Xu,Zheng Wang
#t2008
#cCODES+ISSS
#index106481
#%141996
#%142533
#%133849
#%133131
#%696680
#%106294
#%645213
#%858641
#%131914
#%858092
#%1098577
#%1124656
#%143701
#%409947
#%696678
#!The performance of system-on-chip is determined not only by the performance of its functional units, but also by how efficiently they cooperate with one another. It is the on-chip communication architecture which determines the cooperation efficiency. Network-on-Chip (NoC) is introduced to improve communication bandwidth and power efficiency. However, traditional metallic interconnects consume significant amount of power to deliver large communication bandwidths. Optical NoCs are based on silicon optical interconnects with significant bandwidth and power advantages. Optical routers are the key enabling components of optical NoCs. This paper proposed a novel optical router architecture, ODOR, for optical NoCs based on XY routing algorithm. We compared ODOR with four other router architectures, and analyzed three aspects in details, including power consumption, optical power insertion loss, and the number of microresonators. The results show that ODOR has the lowest power consumption and losses and requires the least microresonators. ODOR has 40% less power consumption, 40% less loss, and 52% less microresonator than the full-connected crossbar. Furthermore, ODOR has a special feature which guarantees the maximum power to route a packet through a network to be a small constant number, regardless of the network size. The maximum power consumption is 0.96fJ/bit under current technology. We simulated a 6x6 2D mesh NoC based on ODOR, and showed the end-to-end delay and network throughput under different offered loads and packet sizes.

#*SPaC: a symbolic pareto calculator.
#@Hamid Shojaei,Twan Basten,Marc Geilen,Phillip Stanley-Marbell
#t2008
#cCODES+ISSS
#index106482
#%114015
#%11143
#%1078390
#%832295
#%1078714
#%143594
#%24964
#%625154
#%509801
#%542719
#!The compositional computation of Pareto points in multi-dimensional optimization problems is an important means to efficiently explore the optimization space. This paper presents a symbolic Pareto calculator, SPaC, for the algebraic computation of multidimensional trade-offs. SPaC uses BDDs as a representation for solution sets and operations on them. The tool can be used in multi-criteria optimization and design-space exploration of embedded systems. The paper describes the design and implementation of Pareto algebra operations, and it shows that BDDs can be used effectively in Pareto optimization.

#*Synthesis of heterogeneous pipelined multiprocessor systems using ILP: jpeg case study.
#@Haris Javaid,Sri Parameswaran
#t2008
#cCODES+ISSS
#index106483
#%214769
#%341258
#%193833
#%106421
#%134711
#%646126
#!Streaming applications can be implemented with a pipeline of processors. Each processor in the pipeline can be an application Specific Instruction Set Processor (ASIP) with the result being a heterogeneous pipelined MPSoC system. Since ASIPs can be of differing configurations, finding the optimal set of configurations for a multiprocessor architecture is a difficult problem. In this paper, we obtain an optimal system design for a set of processors which execute a multimedia application. The variables in the system are the presence or absence of different additional instructions and differing cache configurations for each of the processors. The problem is formulated as a 0-1 Integer Linear Programming (ILP) problem. To reduce the complexity of the ILP formulation, inferior ASIP configurations are efficiently pruned so that the solution could be reached quickly. Given a system runtime constraint, the proposed methodology finds a design with minimal area. We integrated this design methodology into a commercial design flow, and performed a case study upon the JPEG encoding application. We obtained 15 optimal designs subject to 15 different runtime constraints, each in less than 100 seconds from more than 4.2 x 1013 design points.

#*A performance-oriented hardware/software partitioning for datapath applications.
#@Laura Frigerio,Fabio Salice
#t2008
#cCODES+ISSS
#index106484
#%50123
#%143164
#%52684
#%1118010
#!This article proposes a hardware/software partitioning method targeted to performance-constrained systems for datapath applications. Exploiting a platform based design, a Timed Petri Net formalism is proposed to represent the mapping of the application onto the platform, allowing to statically extract performance estimations in early phases of the design process and without the need of expensive simulations. The mapping process is generalized in order to allow an automatic exploration of the solution space, that identifies the best performance/area configurations among several application-architecture combinations. The method is evaluated implementing a typical datapath performance constrained system, i.e. a packet processing application.

#*You can catch more bugs with transaction level honey.
#@Miron Abramovici,Kees Goossens,Bart Vermeulen,Jack Greenbaum,Neal Stollon,Adam Donlin
#t2008
#cCODES+ISSS
#index106485
#!In this special session we explore holistic approaches to hardware/software debug that use or integrate transaction level models (TLMs). We present several TLM-based approaches to system-level diagnostics, ranging from use of most popular transaction level modeling languages through to hybrid technologies that combine TLMs with other well known diagnostic tools like in-silicon trace logic.

#*Yield maximization for system-level task assignment and configuration selection of configurable multiprocessors.
#@Love Singhal,Sejong Oh,Eli Bozorgzadeh
#t2008
#cCODES+ISSS
#index106486
#%419661
#%214769
#%646126
#%499621
#%53550
#%283718
#%283703
#%214701
#%283629
#!Configurable multiprocessor system is a promising design alternative because of its high degree of flexibility, short development time, and potentially high performance under constraints and challenges driven by applications. An important design challenge at 45nm for multi-core system is manufacturing process variation. Due to increasing concern of WID variation, designers will have to choose configurations of processing cores that maximize yield of the system while not affecting performance and throughput constraints. Due to interdependency between processor configuration selection and task allocation and its impact on yield and latency constraints, we tackle both problems simultaneously. In this paper, we propose the problem of task allocation and configuration selection for yield optimization. We prove the problem is NP-hard and propose an optimal pseudo-polynomial on Serial-Parallel graphs. We target streaming applications in pipelined reconfigurable multiprocessor systems. We provide a case study of configurable Leon processors as the cores implemented on FPGA. Results show that proposed problem could result in significant improvement of the timing yield of the system by exploiting extra slack on tasks.

#*Online adaptive utilization control for real-time embedded multiprocessor systems.
#@Jianguo Yao,Xue Liu,Mingxuan Yuan,Zonghua Gu
#t2008
#cCODES+ISSS
#index106487
#%565478
#%808040
#%565652
#%1125385
#%997685
#%1126150
#%565623
#%49065
#%1098679
#!To provide Quality of Service (QoS) guarantees in open and unpredictable environments, the utilization control problem is defined to keep the processor utilization at the schedulable utilization bound, even in the face of unpredictable and/or varying task execution times. To handle the end-to-end task model where each task is comprised of a chain of subtasks distributed on multiprocessors, researchers have used Model Predictive Control (MPC) to address the Multiple-Input, Multiple-Output (MIMO) control problem. Although MPC can handle a limited range of model uncertainties due to execution time estimation errors, the system may suffer performance deterioration or even become unstable if the actual task execution times are much larger than their estimated values. In this paper, we present an online adaptive optimal control approach using Recursive Least Squares (RLS) based model estimator plus Linear Quadratic (LQ) optimal controller. We use simulation experiments to demonstrate the effectiveness of our controller compared with the MPC-based controller.

#*Application specific non-volatile primary memory for embedded systems.
#@Kwangyoon Lee,Alex Orailoglu
#t2008
#cCODES+ISSS
#index106488
#%106247
#%483733
#%106424
#%1117910
#%181385
#%106225
#%1098643
#!Memory subsystems have been considered as one of the most critical components in embedded systems and furthermore, displaying increasing complexity as application requirements diversify. Modern embedded systems are generally equipped with multiple heterogeneous memory devices to satisfy diverse requirements and constraints. NAND flash memory has been widely adopted for data storage because of its outstanding benefits on cost, power, capacity and non-volatility. However, in NAND flash memory, the intrinsic costs for the read and write accesses are highly disproportionate in performance and access granularity. The consequent data management complexity and performance deterioration have precluded the adoption of NAND flash memory. In this paper, we introduce a highly effective non-volatile primary memory architecture which incorporates application specific information to develop a NAND flash based primary memory. The proposed architecture provides a unified non-volatile primary memory solution which relieves design complications caused by the growing complexity in memory subsystems. Our architecture aggressively minimizes the overhead and redundancy of the NAND based systems by exploiting efficient address space management and dynamic data migration based on accurate application behavioral analysis. We also propose a highly parallelized memory architecture through an active and dynamic data redistribution over the multiple flash memories based on run-time workload analysis. The experimental results show that our proposed architecture significantly enhances average memory access cycle time which is comparable to the standard DRAM access cycle time and also considerably prolongs the device life-cycle by autonomous wear-leveling and minimizing the program/erase operations.

#*Slack analysis in the system design loop.
#@Girish Venkataramani,Seth Copen Goldstein
#t2008
#cCODES+ISSS
#index106489
#%55276
#%53617
#%106094
#%1117788
#%418748
#%1135075
#%1166121
#%132719
#%499311
#%106171
#%2346
#%133282
#%808316
#%134799
#%283587
#%283735
#%283334
#!We present a system-level technique to analyze the impact of design optimizations on system-level timing dependencies. This technique enables us to speed up the design cycle by substituting, in the design the loop, the time-consuming simulation step with a fast timing update routine. As a result, we can significantly reduce the design time from on the order of hours/days to the order of seconds/minutes. The update algorithm is defined on the Transaction Level Model (TLM) and can be used by any design flow that invokes TLM-based optimizations. This algorithm has linear-time complexity in the program size and experimental results indicate that any loss of accuracy due to this technique is negligible (

#*Traversal caches: a first step towards FPGA acceleration of pointer-based data structures.
#@Greg Stitt,Gaurav Chaudhari,James Coole
#t2008
#cCODES+ISSS
#index106490
#%498982
#%132179
#%53635
#%252730
#%806039
#%806211
#%203145
#%141988
#%483667
#%214427
#%576058
#%418925
#%214508
#%1117910
#%283106
#%1135393
#%9873
#!Field-programmable gate arrays (FPGAs) often achieve order of magnitude speedups compared to microprocessors, but typically have been unable to improve the performance of applications with irregular memory access patterns, such as traversals of pointer-based data structures. Due to the common use of these data structures, the applicability and widespread success of FPGAs has been limited. In this paper, we introduce the traversal cache framework - a first step towards improving the performance of FPGA applications that utilize pointer-based data structures. The traversal cache is a local FPGA memory that stores repeated traversals of pointer-based data structures, allowing for these traversals to be efficiently streamed into the FPGA. Although the cache is generally limited to improving applications that exhibit repeated traversals, we show that many applications in fact have this characteristic. Furthermore, we show that few repetitions are needed to achieve performance improvements. We present experimental results showing that FPGA implementations using the traversal cache framework achieve speedups ranging from 7x to 29x compared to pointer-based software on a 3.2 GHz Xeon.

#*Dynamic tuning of configurable architectures: the AWW online algorithm.
#@Chen Huang,David Sheldon,Frank Vahid
#t2008
#cCODES+ISSS
#index106491
#%132842
#%436925
#%419661
#%499061
#%949819
#%134773
#%807028
#%283509
#%283102
#%134171
#!Architectures with software-writable parameters, or configurable architectures, enable runtime reconfiguration of computing platforms to the applications they execute. Such dynamic tuning can improve application performance, as well as energy. However, reconfiguring incurs a temporary performance cost. Thus, online algorithms are needed that decide when to reconfigure and which configuration to choose such that overall performance is optimized. We introduce the adaptive weighted window (AWW) algorithm, and compare with several other algorithms, including algorithms previously developed by the online algorithm community. We describe experiments showing that AWW results are within 4% of the offline optimal on average. AWW outperforms the other algorithms, and is robust across three datasets and across three categories of application sequences too. AWW improves a non-dynamic approach on average by 6%, and by up to 30% in low-reconfiguration-time situations.

#*Cache-aware optimization of BAN applications.
#@Yun Liang,Lei Ju,Samarjit Chakraborty,Tulika Mitra,Abhik Roychoudhury
#t2008
#cCODES+ISSS
#index106492
#%418565
#%805601
#%453162
#%680789
#%132680
#%432281
#%1117724
#%567498
#%506698
#%1079984
#%106450
#%106193
#%1117914
#%133516
#%1117895
#!Body-area sensor network or BAN-based health monitoring is increasingly becoming a popular alternative to traditional wired biomonitoring techniques. However, most biomonitoring applications need continuous processing of large volumes of data, as a result of which both power consumption and computation bandwidth turn out to be serious constraints for sensor network platforms. This has resulted in a lot of recent interest in design methods, modeling and software analysis techniques specifically targeted towards BANs and applications running on them. In this paper we show that appropriate optimization of the application running on the communication gateway of a wireless BAN and accurate modeling of the microarchitectural details of the gateway processor can lead to significantly better resource usage and power savings. In particular, we propose a method for deriving the optimal order in which the different sensors feeding the gateway processor should be sampled, to maximize cache re-use. Our case study using a faint fall detection application - from the geriatric care domain - which is fed by a number of smart sensors to detect physiological and physical gait signals of a patient show very attractive energy savings in the underlying processor. Alternatively, our method can be used to improve the sampling frequency of the sensors, leading to higher reliability and better response time of the application.

#*Model checking SystemC designs using timed automata.
#@Paula Herber,Joachim Fellmuth,Sabine Glesner
#t2008
#cCODES+ISSS
#index106493
#%1088788
#%233851
#%142013
#%142212
#%142908
#%142926
#!SystemC is widely used for modeling and simulation in hardware/software co-design. Due to the lack of a complete formal semantics, it is not possible to verify SystemC designs. In this paper, we present an approach to overcome this problem by defining the semantics of SystemC by a mapping from SystemC designs into the well-defined semantics of Uppaal timed automata. The informally defined behavior and the structure of SystemC designs are completely preserved in the generated Uppaal models. The resulting Uppaal models allow us to use the Uppaal model checker and the Uppaal tool suite, including simulation and visualization tools. The model checker can be used to verify important properties such as liveness, deadlock freedom or compliance with timing constraints. We have implemented the presented transformation, applied it to two examples and verified liveness, safety and timing properties by model checking, thus showing the applicability of our approach in practice.

#*Providing accurate event models for the analysis of heterogeneous multiprocessor systems.
#@Simon Schliecker,Jonas Rox,Matthias Ivers,Rolf Ernst
#t2008
#cCODES+ISSS
#index106494
#%141631
#%1053257
#%141637
#%174718
#%174571
#%565074
#%174539
#%343630
#%106463
#%106413
#!This paper proposes a new method for deriving quantitative event information for compositional multiprocessor performance analysis. This procedure brakes down the complexity into the analysis of individual components (tasks mapped to resources) and the propagation of the timing information with the help of event models. This paper improves previous methods to derive event models in a multiprocessor system by providing tighter bounds and allowing arbitrarily shaped event models. The procedure is based on a a simple yet expressive resource model called the multiple event busy time which can be derived on the basis of classical scheduling theory -- it can therefore be provided for a large domain of scheduling policies. Our experiments show that overestimation by previous methods can be reduced significantly.

#*Holistic design and caching in mobile computing.
#@Mwaffaq Otoom,JoAnn M. Paul
#t2008
#cCODES+ISSS
#index106495
#%794195
#%296446
#%286645
#%53441
#%1330251
#%832948
#%596880
#%674918
#%142952
#%142293
#%141422
#%1080882
#!We utilize application trends analysis, focused on webpage content, in order to examine the design of mobile computers more holistically. We find that both Internet bandwidth and processing local to the computing device is being wasted by re-transmission of formatting data. By taking this broader view, and separating Macromedia Flash content into raw data and its packaging, we show that performance can be increased by 84%, power consumption can be decreased by 71%, and communications bandwidth can be saved by an order of magnitude.

#*LOCS: a low overhead profiler-driven design flow for security of MPSoCs.
#@Krutartha Patel,Sri Parameswaran
#t2008
#cCODES+ISSS
#index106496
#%542513
#%141315
#%233983
#%77527
#%546557
#%134794
#%106437
#%894578
#%133655
#%1098650
#%134711
#%134798
#%134295
#!Security is a growing concern in processor based systems and hence requires immediate attention. New paradigms in the design of MPSoCs must be found, with security as one of the primary objectives. Software attacks like Code Injection Attacks exploit vulnerabilities in "trusted" code. Previous countermeasures addressing code injection attacks in MPSoCs have significant performance overheads and do not check every single line of code. The work described in this paper has reduced performance overhead and ensures that all the lines in the program code are checked. We propose an MPSoC system where one processor (which we call a MONITOR processor) is responsible for supervising all other application processors. Our design flow, LOCS, instruments and profiles the execution of basic blocks in the program. LOCS subsequently uses the profiler output to re-instrument the source files to minimize runtime overheads. LOCS also aids in the design of hardware customizations required by the MONITOR. At runtime, the MONITOR checks the validity of the control flow transitions and the execution time of basic blocks. We implemented our system on a commercial extensible processor, Xtensa LX2, and tested it on three multimedia benchmarks. The experiments show that our system has the worst-case performance degradation of about 24% and an area overhead of approximately 40%. LOCS has smaller performance, area and code size overheads than all previous code injection countermeasures for MPSoCs.

#*Scratchpad allocation for concurrent embedded software.
#@Vivy Suhendra,Abhik Roychoudhury,Tulika Mitra
#t2008
#cCODES+ISSS
#index106497
#%106044
#%106322
#%1117912
#%143075
#%1098523
#%450484
#%450510
#%132609
#%77726
#%174589
#%77677
#%174607
#%287030
#%805601
#%77475
#%1098703
#%132489
#%52405
#%283698
#%77581
#%1057323
#%52674
#%106193
#%448221
#%86477
#%181436
#%134011
#%565503
#%77624
#%143208
#%665200
#!Software-controlled scratchpad memory is increasingly employed in embedded systems as it offers better timing predictability compared to caches. Previous scratchpad allocation algorithms typically consider single-process applications. But embedded applications are mostly multitasking with real-time constraints, where the scratchpad memory space has to be shared among interacting processes that may preempt each other. In this work, we develop a novel dynamic scratchpad allocation technique that takes these process interferences into account to improve the performance and predictability of the memory system. We model the application as a Message Sequence Chart (MSC) to best capture the interprocess interactions. Our goal is to optimize the Worst-Case Response Time (WCRT) of the application through runtime reloading of the scratchpad memory content at appropriate execution points. We propose an iterative allocation algorithm that consists of two critical steps: (1) analyze the MSC along with the existing allocation to determine potential interference patterns, and (2) exploit this interference information to tune the scratchpad reloading points and content so as to best improve the WCRT. We present various alternative scratchpad allocation heuristics and evaluate their effectiveness in reducing the WCRT. The scheme is also extended to work on Message Sequence Graph models. We evaluate our memory allocation scheme on two real-world embedded applications controlling an Unmanned Aerial Vehicle (UAV) and an in-orbit monitoring instrument, respectively.

#*Methodology for multi-granularity embedded processor power model generation for an ESL design flow.
#@Young-Hwan Park,Sudeep Pasricha,Fadi J. Kurdahi,Nikil Dutt
#t2008
#cCODES+ISSS
#index106498
#%418565
#%134384
#%106286
#%52550
#%161070
#%141387
#%436949
#%436743
#%106426
#!With power becoming a major constraint for multi-processor embedded systems, it is becoming important for designers to characterize and model processor power dissipation. It is critical for these processor power models to be useable across various modeling abstractions in an electronic system level (ESL) design flow, to guide early design decisions. In this paper, we propose a unified processor power modeling methodology for the creation of power models at multiple granularity levels that can be quickly mapped to an ESL design flow. Our experimental results based on applying the proposed methodology on an OpenRISC processor demonstrate the usefulness of having multiple power models. The generated models range from very high-level two-state and architectural/ISS models that can be used in transaction level models (TLM), to extremely detailed cycle-accurate models that enable early exploration of power optimization techniques. These models offer a designer tremendous flexibility to trade off estimation accuracy with estimation/simulation effort.

#*Highly-cited ideas in system codesign and synthesis.
#@Frank Vahid,Tony Givargis
#t2008
#cCODES+ISSS
#index106499
#%106150
#%106044
#%106221
#%106070
#%106216
#%106316
#%106260
#%106203
#%106120
#%106041
#%106138
#%106090
#%450462
#%450616
#%450618
#%106004
#%106014
#%106418
#%106020
#%106121
#%106180
#%106408
#%450524
#%106224
#%106226
#%450544
#%450554
#%450566
#%106134
#%106157
#%106193
#%106394
#%106204
#%450628
#%450679
#%106329
#%106425
#%450493
#%106362
#!We conducted a study of citations of papers published between 1996 and 2006 in the CODES and ISSS conferences, representing the hardware/software codesign and system synthesis community. Citations, meaning non-self-citations only, were considered from all papers known to Google Scholar, as well as only from subsequent CODES/ISSS papers. We list the most-cited CODES/ISSS papers of each year, summarizing their topics, and discussing common features of those papers. For comparison purposes, we also measured citations for the computer architecture community's ISCA and MICRO conferences, and for the field-programmable gate array community's FPGA and FCCM conferences. We point out several interesting differences among the citation patterns of the three communities.

#*Co-design in the wilderness.
#@Dan J. Gale
#t2008
#cCODES+ISSS
#index106500
#!Hardware technology platforms are blurring at the edges as the integration frontier, a co-design frontier, holds promise of new functionality being achieved beyond electronics and software, through photonic and fluidic technologies. The problems here are complex as one considers the multiple technology partitions and the possibilities for exploring trade-offs and so this co-design frontier is largely untamed. A co-design "box", somewhat empirical by nature, supports exploratory research interests. It is motivated by trying to merge two lines of activity: one involving electronic-software rapid-prototyping and the other involving the design and fabrication of novel non-electronic devices or structures. The expectation initially is to demonstrate from an embedded system perspective whether novel fluidic devices perform as intended. Other devices will be considered in the future. Individuals and groups working in these frontier areas have attempted to promote some degree of standardization which might help clear a path forward in support of less empirical co-design techniques. Experience with microelectronics is most often used as a model with reference to the hierarchy of leaf-cells, components, functionally-designated subsystems and defined physical and signal interfaces. Physical aspects of internet connectivity are an example of advances made at the photonics-electronics frontier using multiple signal wavelengths and command, control and communication involving software, microelectronics, photonics and signal conversion. Progress with fluidics is at an early stage and major outcomes, no less transformative than the internet in the last 20 years, will occur whether in health-care or the environment or in some other sector. Complex devices or micro-assemblies that carry electronic, photonic and fluidic signals are now made regularly. Co-design technology, while lagging seriously, has the potential to reduce exploration barriers at the integration frontier, multiplying the number of exploratory paths being pursued by an increasing number of practitioners and yielding beneficial outcomes sooner than might otherwise be expected.

#*Speculative DMA for architecturally visible storage in instruction set extensions.
#@Theo Kluter,Philip Brisk,Paolo Ienne,Edoardo Charbon
#t2008
#cCODES+ISSS
#index106501
#%131423
#%143075
#%106014
#%1078728
#%419202
#%77658
#%77474
#!Instruction set extensions (ISEs) can accelerate embedded processor performance. Many algorithms for ISE generation have shown good potential; some of them have recently been expanded to include Architecturally Visible Storage (AVS) - compiler-controlled memories, similar to scratchpads, that are accessible only to ISEs. To achieve a speedup using AVS, Direct Memory Access (DMA) transfers are required to move data from the main memory to the AVS; unfortunately, this creates coherence problems between the AVS and the cache, which previous methods for ISEs with AVS failed to address; additionally, these methods need to leave many conservative DMA transfers in place, whose execution significantly limits the achievable speedup. This paper presents a memory coherence scheme for ISEs with AVS, which can ensure execution correctness and memory consistency with minimal area overhead. We also present a method that speculatively removes redundant DMA transfers. Cycle-accurate experimental results were obtained using an FPGA-emulation platform. These results show that the application-specific instruction-set extended processors with speculative DMA-enhanced AVS gain significantly over previous techniques, despite the overhead of the coherence mechanism.

#*Distributed flit-buffer flow control for networks-on-chip.
#@Nicola Concer,Michele Petracca,Luca P. Carloni
#t2008
#cCODES+ISSS
#index106502
#%281958
#%281800
#%142416
#%805785
#%1124642
#%1008371
#%141646
#%131914
#%142153
#%133077
#%282546
#%573811
#%1008724
#!The combination of flit-buffer flow control methods and latency-insensitive protocols is an effective solution for networks-on-chip (NoC). Since they both rely on backpressure, the two techniques are easy to combine while offering complementary advantages: low complexity of router design and the ability to cope with long communication channels via automatic wire pipelining. We study various alternative implementations of this idea by considering the combination of three different types of flit-buffer flow control methods and two different classes of channel repeaters (based respectively on flip-flops and relay stations). We characterize the area and performance of the two most promising alternative implementations for NoCs by completing the RTL design and logic synthesis of the repeaters and routers for different channel parallelisms. Finally, we derive high-level abstractions of our circuit designs and we use them to perform system-level simulations under various scenarios for two distinct NoC topologies and various applications. Based on our comparative analysis and experimental results, we propose a NoC design approach that combines the reduction of the router queues to a minimum size with the distribution of flit buffering onto the channels. This approach provides precious flexibility during the physical design phase for many NoCs, particularly in those systems-on-chip that must be designed to meet a tight constraint on the target clock frequency.

#*Concurrency emulation and analysis of parallel applications for multi-processor system-on-chip co-design.
#@Giovanni Beltrame,Luca Fossati,Donatella Sciuto
#t2008
#cCODES+ISSS
#index106503
#%808554
#%53326
#%143649
#%534224
#%148591
#%805840
#%142806
#%573436
#%143861
#!This paper presents a novel technique for the modeling and the simulation of parallel applications for Multi-Processor Systems-on-Chip (MPSoCs). This technique consists of an application-transparent emulation of OS primitives, including task creation, scheduling, synchronization etc.; this emulation guarantees compatibility with any program compiled against the standard POSIX library, independently of the target OS. This methodology can be used to perform initial HW/SW partitioning and concurrent engineering of a given application, as it allows any software routine to be transparently emulated with SystemC modules. The proposed approach has been verified on a large set of multi-threaded benchmarks, with both POSIX Threads and OpenMP programming styles. Results show that our methodology enables (a) fast simulation of POSIX applications, (b) accurate analysis of multi-threaded applications, and (c) co-design and fast preliminary hardware-software partitioning.

#*Specification-based compaction of directed tests for functional validation of pipelined processors.
#@Heon-Mo Koo,Prabhat Mishra
#t2008
#cCODES+ISSS
#index106504
#%131587
#%857779
#%1117758
#%1117670
#%142266
#%1118103
#%1080937
#%1081675
#%133893
#%858604
#!Functional validation is a major bottleneck in microprocessor design methodology. Simulation is the widely used method for functional validation using billions of random and biased-random test programs. Although directed tests require a smaller test set compared to random tests to achieve the same functional coverage goal, there is a lack of automated techniques for directed test generation. Furthermore, the number of directed tests can still be prohibitively large. This paper presents a methodology for specification-based coverage analysis and test generation. The primary contribution of this paper is a compaction technique that can drastically reduce the required number of directed test programs to achieve a coverage goal. Our experimental results using a MIPS processor and an industrial processor (e500) demonstrate more than 90% reduction in number of directed tests without sacrificing the functional coverage goal.

#*Guaranteed scheduling for repetitive hard real-time tasks under the maximal temperature constraint.
#@Gang Quan,Yan Zhang,William Wiles,Pei Pei
#t2008
#cCODES+ISSS
#index106505
#%212033
#%419433
#%951936
#%564217
#%781392
#%143532
#%448488
#%106466
#%499459
#%1008640
#%1077149
#%565658
#!We study the problem of scheduling repetitive real-time tasks with the Earliest Deadline First (EDF) policy that can guarantee the given maximal temperature constraint. We show that the traditional scheduling approach, i.e., to repeat the schedule that is feasible through the range of one hyper-period, does not apply any more. Then, we present necessary and sufficient conditions for real-time schedules to guarantee the maximal temperature constraint. Based on these conditions, a novel scheduling algorithm is proposed for developing the appropriate schedule that can ensure the maximal temperature guarantee. Finally, we use experiments to evaluate the performance of our approach.

#*System-level mitigation of WID leakage power variability using body-bias islands.
#@Siddharth Garg,Diana Marculescu
#t2008
#cCODES+ISSS
#index106506
#%282424
#%437072
#%1013326
#%131694
#%447972
#%447865
#%283591
#%283500
#%134754
#%499660
#%53550
#%446686
#!Adaptive Body Biasing (ABB) is a popularly used technique to mitigate the increasing impact of manufacturing process variations on leakage power dissipation. The efficacy of the ABB technique can be improved by partitioning a design into a number of "body-bias islands," each with its individual body-bias voltage. In this paper, we propose a system-level leakage variability mitigation framework to partition a multiprocessor system into body-bias islands at the processing element (PE) granularity at design time, and to optimally assign body-bias voltages to each island post-fabrication. As opposed to prior gate- and circuit-level partitioning techniques that constrain the global clock frequency of the system, we allow each island to run at a different speed and constrain only the relevant system performance metrics - in our case the execution deadlines. Experimental results show the efficacy of the proposed framework in reducing the mean and standard deviation of leakage power dissipation compared to a baseline system without ABB. At the same time, the proposed techniques provide significant runtime improvements over a previously proposed Monte-Carlo based technique while providing similar reductions in leakage power dissipation.

#*A security monitoring service for NoCs.
#@Leandro Fiorin,Gianluca Palermo,Cristina Silvano
#t2008
#cCODES+ISSS
#index106507
#%805785
#%1117772
#%696666
#%1083174
#%106447
#%161252
#%106095
#%1128445
#%696651
#!As computing and communications increasingly pervade our lives, security and protection of sensitive data and systems are emerging as extremely important issues. Networks-on-Chip (NoCs) have appeared as design strategy to cope with the rapid increase in complexity of Multiprocessor Systems-on-Chip (MPSoCs), but only recently research community have addressed security on NoC-based architectures. In this paper, we present a monitoring system for NoC based architectures, whose goal is to help detect security violations carried out against the system. Information collected are sent to a central unit for efficiently counteracting actions performed by attackers. We detail the design of the basic blocks and analyse overhead associated with the ASIC implementation of the monitoring system, discussing type of security threats that it can help detect and counteract.

#*Deterministic service guarantees for nand flash using partial block cleaning.
#@Siddharth Choudhuri,Tony Givargis
#t2008
#cCODES+ISSS
#index106508
#%1124089
#%1098538
#%106457
#%586349
#%523749
#%832611
#%807096
#!NAND flash idiosyncrasies such as bulk erase and wear leveling results in non-linear and unpredictable read/write access times. In case of application domains such as streaming multimedia and real-time systems, a deterministic read/write access time is desired during design time. We propose a novel NAND flash translation layer called GFTL that guarantees fixed upper bounds (i.e., worst case service rates) for reads and writes that are comparable to a theoretical ideal case. Such guarantees are made possible by eliminating sources of non-determinism in GFTL design and using partial block cleaning. GFTL performs garbage collection in partial steps by dividing the garbage collection of a single block into several chunks, thereby interleaving and hiding the garbage collection latency while servicing requests. Further, GFTL guarantees are independent of flash utilization, size or state. Along with theoretical bounds, benchmark results show the efficacy of our approach. Based on our experiments, GFTL requires an additional 16% of total blocks for flash management. GFTL service guarantees can be calculated from flash specifications. Thus, with GFTL, a designer can determine the service guarantees and size requirements apriori, during design time.

#*Symbolic voter placement for dependability-aware system synthesis.
#@Felix Reimann,Michael Glabeta,Martin Lukasiewycz,Joachim Keinert,Christian Haubelt,Jürgen Teich
#t2008
#cCODES+ISSS
#index106509
#%131628
#%1078390
#%143611
#%143814
#%148691
#%143942
#%142168
#%85535
#%53546
#%140396
#%106449
#%143153
#%203457
#%50313
#%134454
#%106438
#!This paper presents a system synthesis approach for dependable embedded systems. The proposed approach significantly extends previous work by automatically inserting fault detection and fault toleration mechanisms into an implementation. The main contributions of this paper are 1) a dependability-aware system synthesis approach that automatically performs a redundant task binding and placement of voting structures to increase both, reliability and safety, respectively, 2) an efficient dependability analysis approach to evaluate lifetime reliability and safety, and 3) results from synthesizing a Motion-JPEG decoder for an FPGA platform using the proposed system synthesis approach. As a result, a set of high-quality solutions of the decoder with maximized reliability, safety, performance, and simultaneously minimized resource requirements is achieved.

#*Performance debugging of Esterel specifications.
#@Lei Ju,Bach Khoa Huynh,Abhik Roychoudhury,Samarjit Chakraborty
#t2008
#cCODES+ISSS
#index106510
#%1056624
#%870009
#%1057323
#%565274
#%25551
#%134011
#!Synchronous languages like Esterel have been widely adopted for designing reactive systems in safety-critical domains such as avionics. Specifications written in Esterel are based on the underlying "synchrony hypothesis", where the computation/communication associated with the processing of all events occurring within the same "clock tick" are assumed to happen instantaneously (or in zero time). In reality, Esterel specifications get compiled to implementations (such as C code) which do not satisfy the perfect synchrony assumption. Hence, platform-specific timing analysis of such implementations is an important research topic. Interest in this area has lately been renewed with the recent advances in Worst-case Execution Time (WCET)analysis techniques. In this paper we perform WCET analysis on sequential C code and exploit the structure of the code generated from Esterel specifications to obtain tight WCET estimates. Such estimates can validate Esterel-level assumptions on the instantaneous processing of signals or events that occur together. More importantly, they can be used to identify parts of the specification which might pose as timing/performance bottlenecks with respect to the underlying platform. This is done by exploiting traceability links between Esterel specifications and the generated C code, which map the time-critical computations at the C-level back to the Esterel-level. This not only allows a designer to optimize or simplify Esterel specifications, but also choose/configure suitable implementation platforms. We show the results of our WCET analysis on a set of standard Esterel benchmarks and illustrate the utility of our model-code traceability technique using an Esterel specification of a reflex game application.

#*Static analysis of processor stall cycle aggregation.
#@Jongeun Lee,Aviral Shrivastava
#t2008
#cCODES+ISSS
#index106511
#%436519
#%141343
#%132273
#%106299
#%53785
#%833164
#%141487
#%142139
#%132608
#%77608
#!Processor Idle Cycle Aggregation (PICA) is a promising approach for low power execution of processors, in which small memory stalls are aggregated to create a large one, and the processor is switched to low-power mode in it. We extend the previous proposed approach in two dimensions. i) We develop static analysis for the PICA technique and present optimum parameters for five common types of loops based on steady-state analysis. ii) We show that software only control is unable to guarantee its correctness in a varying runtime environment, potentially causing deadlocks. We enhance the robustness of PICA with minimal hardware extension, ensuring correct execution for any loops and parameters, which greatly facilitates exploration based parameter optimization. The combined use of our static analysis and exploration based fine-tuning makes the PICA technique applicable, to any memory-bound loop, with energy reduction. We validate our analytical models against simulation based optimization and also show through our experiments on embedded application benchmarks, that our technique can be applied to a wide range of loops with average 20% energy reductions compared to executions without PICA.

#*Extending open core protocol to support system-level cache coherence.
#@Konstantinos Aisopos,Chien-Chun Chou,Li-Shiuan Peh
#t2008
#cCODES+ISSS
#index106512
#%79326
#%698
#%1098606
#%143096
#%134010
#%1008711
#!Open Core Protocol (OCP) is a standard on-chip core interface specification. The current release is flexible and configurable to support the communication needs of a wide range of Intellectual Property cores, and is now in widespread use. However, it does not support system-level coherence. This paper summarizes an effort within the OCP-IP cache coherence working group on incorporating cache coherence extensions into OCP, which is expected to have strong impact on the MPSoC industry. In this paper, we propose a backward-compatible coherent Open Core Protocol interface and discuss the design challenges and implications introduced. This interface is flexible and can support a range of coherence protocols and schemes: we show how it can specify a snoopy bus-based scheme as well as a directory-based scheme. The correctness of the specification and models was verified using NuSMV, via exploring the entire state space for the two basic coherence schemes.

#*Combination of instruction set simulation and abstract RTOS model execution for fast and accurate target software evaluation.
#@Matthias Krause,Dominik Englert,Oliver Bringmann,Wolfgang Rosenstiel
#t2008
#cCODES+ISSS
#index106513
#%805783
#%134816
#%142230
#%132647
#%106454
#%143729
#%133297
#%805601
#%141896
#%36085
#%141925
#%106371
#%142552
#%1098587
#%142036
#%646290
#%106366
#%450469
#%132705
#!Instruction set simulation and real time operating system modeling have become important issues for the design of distributed embedded systems. This paper presents a holistic approach to simulate a distributed, embedded system that includes target software, processing units, and abstract RTOS within a virtual prototype environment. The processing unit is modeled by an ISS, which is embedded in a SystemC environment to allow the integration into a platform model. In comparison to existing approaches, the RTOS is not directly running on the ISS but outsourced and replaced by an RTOS model. This step strongly reduces simulation time since the execution on the ISS is much more time consuming in contrast to the execution on the host processor. The results show the theoretical and measured performance gain depending on the RTOS scheduler and task switching.

#*Don't forget memories: a case study redesigning a pattern counting ASIC circuit for FPGAs.
#@David Sheldon,Frank Vahid
#t2008
#cCODES+ISSS
#index106514
#%203380
#%131431
#%203105
#%214267
#%203129
#%214233
#%203236
#%203278
#%133012
#%214578
#%214667
#%214665
#!Modern embedded compute platforms increasingly contain both microprocessors and field-programmable gate arrays (FPGAs). The FPGAs may implement accelerators or other circuits to speedup performance. Many such circuits have been previously designed for acceleration via application-specific integrated circuits (ASICs). Redesigning an ASIC circuit for FPGA implementation involves several challenges. We describe a case study that highlights a common challenge related to memories. The study involves converting a pattern counting circuit architecture, based on a pipelined binary tree and originally designed for ASIC implementation, into a circuit suitable for FPGAs. The original ASIC-oriented circuit, when mapped to a Spartan 3e FPGA, could process 10 million patterns per second and handle up to 4,096 patterns. The redesigned circuit could instead process 100 million patterns per second and handle up to 32,768 patterns, representing a 10x performance improvement and a 4x utilization improvement. The redesign involved partitioning large memories into smaller ones at the expense of redundant control logic. Through this and other case studies, design patterns may emerge that aid designers in redesigning ASIC circuits for FPGAs as well as in building new high-performance and efficient circuits for FPGAs.

#*Static analysis for fast and accurate design space exploration of caches.
#@Yun Liang,Tulika Mitra
#t2008
#cCODES+ISSS
#index106515
#%132927
#%106056
#%805601
#%1123204
#%446223
#%141928
#%1079630
#%143434
#%134909
#%1117615
#%597633
#!Application-specific system-on-chip platforms create the opportunity to customize the cache configuration for optimal performance with minimal chip estate. Simulation, in particular trace-driven simulation, is widely used to estimate cache hit rates. However, simulation is too slow to be deployed in the design space exploration, specially when it involves hundreds of design points and huge traces or long program execution. In this paper, we propose a novel static analysis technique for rapid and accurate design space exploration of instruction caches. Given the program control flow graph (CFG) annotated only with basic block and control flow edge execution counts, our analysis estimates the hit rates for multiple cache configurations in one pass. We achieve this by modeling the cache states at each node of the CFG in probabilistic manner and exploiting the structural similarities among related cache configurations. Experimental results indicate that our analysis is 24--3,855 times faster compared to the fastest known cache simulator while maintaining high accuracy (0.7% average error), in predicting hit rates for popular embedded benchmarks.

#*Power reduction via macroblock prioritization for power aware H.264 video applications.
#@Michael A. Baker,Viswesh Parameswaran,Karam S. Chatha,Baoxin Li
#t2008
#cCODES+ISSS
#index106516
#%132430
#%341578
#%503645
#!As the importance of multimedia applications in hand-held devices increases, the computational strain and corresponding demand for energy in such devices continues to grow. Portable multimedia devices with inherently limited energy supplies face tight energy constraints and require optimization for energy conservation. Power-aware applications give their users flexibility to prioritize and trade between performance and battery-life. This paper introduces a power-aware technique for user selectable power reduction in exchange for controlled reductions in video quality for H.264 video streams. The technique uses an encoder-decoder pair. The encoder characterizes video streams and provides information to the decoder via Flexible Macroblock Ordering (FMO) by generating prioritized slice groups. The decoder selectively ignores low priority slice groups based on user selected preference effectively reducing the decoder workload. With a reduced computational requirement, processor voltage and frequency scaling (DVFS) significantly improve decoder power performance within timing constraints. Our PXA270 system implementation resulted in power savings of as much as 53% with an average PSNR per frame of 24dB compared to the unmodified video.

#*Profiling of lossless-compression algorithms for a novel biomedical-implant architecture.
#@Christos Strydis,Georgi Gaydadjiev
#t2008
#cCODES+ISSS
#index106517
#%418565
#%483610
#%773113
#%457022
#%2373
#%584504
#%85635
#%1082479
#!In view of a booming market for microelectronic implants, our ongoing research work is focusing on the specification and design of a novel biomedical microprocessor core targeting a large subset of existing and future biomedical applications. Towards this end, we have taken steps in identifying various tasks commonly required by such applications and profiling their behavior and requirements. A prominent family of such tasks is lossless data compression. In this work we profile a large collection of compression algorithms on suitably selected biomedical workloads. Compression ratio, average and peak power consumption, total energy budget, compression rate and program-code size metrics have been evaluated. Findings indicate the best-performing algorithms across most metrics to be mlzo (scores high in 5 out of 6 imposed metrics) and fin (present in 4 out of 6 metrics). Further mlzo profiling reveals the dominance of i) address-generation, load, branch and compare instructions, and ii) interdependent logical-logical and logical-compare instructions combinations.

#*Reliable performance analysis of a multicore multithreaded system-on-chip.
#@Simon Schliecker,Mircea Negrean,Gabriela Nicolescu,Pierre G. Paulin,Rolf Ernst
#t2008
#cCODES+ISSS
#index106518
#%106300
#%858394
#%646522
#%174402
#%106413
#%106241
#%50031
#%141631
#%106463
#!Formal performance analysis is now regularly applied in the design of distributed embedded systems such as automotive electronics, where it greatly contributes to an improved predictability and platform robustness of complex networked systems. Even though it might be highly beneficial also in MpSoC design, formal performance analysis could not easily be applied so far, because the classical task communication model does not cover processor-memory traffic, which is an integral part of MpSoC timing. Introducing memory accesses as individual transactions under the classical model has shown to be inefficient, and previous approaches work well only under strict orthogonalization of different traffic streams. Recent research has presented extensions of the classical task model and a corresponding analysis that covers performance implications of shared memory traffic. In this paper we present a multithreaded multiprocessors platform and multimedia application. We conduct performance analysis using the new analysis options and specifically benchmark the quality of the available approach. Our experiments show that corner case coverage can now be supplied with a very high accuracy, allowing to quickly investigate architectural alternatives.

#*Asynchronous transient resilient links for NoC.
#@Simon Ogg,Bashir M. Al-Hashimi,Alexandre Yakovlev
#t2008
#cCODES+ISSS
#index106519
#%55049
#%805785
#%131914
#%143757
#%55268
#%858018
#%406417
#%696647
#!This paper proposes a new link for asynchronous NoC communications that is resilient to transient faults on the wires of the link without impact on the data transfer capability. Resilience to transients is achieved by exploiting the phase relationship between data symbols and a common reference symbol where the symbols are transmitted using additional wires. Detection of transient faults is performed by comparison of the data symbol and the reference symbol. We demonstrate it is possible to achieve a similar number of transitions per bit as existing delay insensitive codes, from a power consumption point of view, but achieving resilience to transient faults. The link has been synthesized and validated using 0.12 ¼m technology and power, area and performance are given. It has been shown that the link area cost is 409 ¼m2 per data bit and energy per bit is 356 fJ/bit. Latency through the link is 0.8 ns and the maximum operating frequency or throughput of the link is 1.056 GHz.

#*Simulation and embedded software development for Anton, a parallel machine with heterogeneous multicore ASICs.
#@John P. Grossman,Cliff Young,Joseph A. Bank,Kenneth M. Mackenzie,Doug Ierardi,John K. Salmon,Ron O. Dror,David E. Shaw
#t2008
#cCODES+ISSS
#index106520
#%133591
#%419632
#%499019
#%1120717
#%77661
#%52279
#%106454
#%282972
#%133297
#%489935
#%597692
#!Anton, a special-purpose parallel machine currently under construction, is the result of a significant hardware-software codesign effort that relied heavily on an architectural simulator. One of this simulator's many important roles is to support the development of embedded software (software that runs on Anton's ASICs), which is challenging for several reasons. First, the Anton ASIC is a heterogeneous multicore system-on-a-chip, with three types of embedded cores tightly coupled to special-purpose hardware units. Second, a standard 512-ASIC configuration contains a total of 6,656 distinct embedded cores, all of which must be explicitly modeled within the simulator. Third, a portion of the embedded software is dynamically generated at simulation time. This paper discusses the various ways in which the Anton simulator addresses these challenges. We use a hardware abstraction layer that allows embedded software source code to be compiled without modification for either the simulation host or the hardware target. We report on the effectiveness of embedding golden-model testbenches within the simulator to verify embedded software as it runs. We also describe our hardware-software cosimulation strategy for dynamically generated embedded software. Finally, we use a methodology that we refer to as concurrent mixed-level simulation to model embedded cores within massively parallel systems. These techniques allow the Anton simulator to serve as an efficient platform for embedded software development.

#*Design and defect tolerance beyond CMOS.
#@Xiaobo Sharon Hu,Alexander Khitun,Konstantin K. Likharev,Michael T. Niemier,Mingqiang Bao,Kang L. Wang
#t2008
#cCODES+ISSS
#index106521
#%282022
#%457706
#%437388
#%153869
#%214694
#!It is well recognized that novel computational models, devices and technologies are needed in order to sustain the remarkable advancement of CMOS-based VLSI circuits and systems. Regardless of the models, devices and technologies, any enhancement/replacement to CMOS must show significant gains in at least one of the key metrics (including speed, power and cost) for at least a subset of application domains currently employing CMOS circuits. In addition, effective defect tolerant techniques are a critical factor for the successful adoption of any new computing device due to the fact that nano-scale structures will have defect rates much higher than today's CMOS chips. The task of identifying application domains that could benefit the most from a new model/device/technology and ensuring that the resultant system meets functional requirements in the presence of defects requires synergistic efforts of physical scientists, and circuit and system design researchers. This paper contains a collection of three contributions-each focusing on one particular emergent technology-presenting a basic introduction on the technologies, some of their unique features in contrast with CMOS, potential application domains for these technologies, and new opportunities that they may bring forward in defect tolerance design. The contributions include both traditional and nontraditional state representations which use either electronic or magnetic interactions.

#*Optimality of Right Leaning Trees.
#@Herman Akdag,Bernadette Bouchon
#t1986
#cCoding Theory and Applications
#index106522

#*Search for Sequences with Zero Autocorrelation.
#@Roger Alexis
#t1986
#cCoding Theory and Applications
#index106523

#*Weighted Decoding as a Means for Reestimating a Probability Distribution (Abstract).
#@Gerard Battail
#t1986
#cCoding Theory and Applications
#index106524

#*Weighted decoding of linear block codes by solving a system of implicit equations.
#@Gerard Battail
#t1988
#cCoding Theory and Applications
#index106525

#*Is minimal distance a good criterion?
#@Gerard Battail
#t1988
#cCoding Theory and Applications
#index106526

#*A Weighted-Output Symbol-by-Symbol Decoding Algorithm of Binary Convolutional Codes.
#@J. C. Belfiore
#t1986
#cCoding Theory and Applications
#index106527

#*Information Theory in Random Fields.
#@Toby Berger
#t1986
#cCoding Theory and Applications
#index106528

#*Optimum '1'-Ended Binary Prefix Codes.
#@Toby Berger,Raymond W. Yeung
#t1986
#cCoding Theory and Applications
#index106529

#*Specification, Synchronisation, Average Length.
#@Anne Bertrand
#t1986
#cCoding Theory and Applications
#index106530

#*On the Density of Best Coverings in Hamming Spaces.
#@M. Beveraggi,Gérard D. Cohen
#t1986
#cCoding Theory and Applications
#index106531

#*A [32, 17, 14] - Geometric Code coming from a Singular Curve.
#@Dominique Le Brigand
#t1986
#cCoding Theory and Applications
#index106532

#*Polynomial factorization using Brill-Noether algorithm.
#@Dominique Le Brigand
#t1988
#cCoding Theory and Applications
#index106533

#*Evaluation of a coding design for a very noisy channel.
#@Paul Camion,Jean-Luc Politano
#t1988
#cCoding Theory and Applications
#index106534

#*A simple description of Kerdock codes.
#@Claude Carlet
#t1988
#cCoding Theory and Applications
#index106535

#*Codes from Artin-Schreier curves.
#@M. Carral,D. Rotillon,J. A. Thiong-Ly
#t1988
#cCoding Theory and Applications
#index106536

#*The Generalized Goppa Codes and Related Discrete Designs from Hermitian Surfaces in PG (3, s).
#@I. M. Chakravarti
#t1986
#cCoding Theory and Applications
#index106537

#*Generating codewords in real space: Application to decoding.
#@Gérard D. Cohen,Philippe Godlewski,Tai-Yang Hwang
#t1988
#cCoding Theory and Applications
#index106538

#*Concatenated coding schemes for HF channels.
#@J. L. Dalmau,J. A. Delgado,Llorenç Huguet i Rotger,Inma Ortuño Ortin,R. Valle
#t1988
#cCoding Theory and Applications
#index106539

#*The future pan european mobile radiotelephone system: a short overview.
#@Jean-Louis Dornstetter
#t1988
#cCoding Theory and Applications
#index106540

#*Amerlioration of the Mc Williams-Sloanes Tables using Geometric Codes from Curves with Genus 1, 2 or 3.
#@Yves Driencourt,Jean-Francis Michon
#t1986
#cCoding Theory and Applications
#index106541

#*On the Inherent Intractability of Soft Decision Decoding of Linear Codes.
#@J. Fang,Gérard D. Cohen,Philippe Godlewski,Gerard Battail
#t1986
#cCoding Theory and Applications
#index106542

#*Linear recurrence relations and an extended subresultant algorithm.
#@Patrick Fitzpatrick,Graham H. Norton
#t1988
#cCoding Theory and Applications
#index106543

#*Coding and Decoding Algorithms of Reed - Solomon Codes Executed on a M 68000 Microprocessor.
#@Francisco J. García-Ugalde
#t1986
#cCoding Theory and Applications
#index106544

#*Covering in Hypercubes.
#@Arif Ghafoor,Patrick Solé
#t1988
#cCoding Theory and Applications
#index106545

#*Adapted Codes for Communication Through Multipath Channel.
#@G. Hakizimana,G. Jourdain,G. Loubet
#t1986
#cCoding Theory and Applications
#index106546

#*A new authentication algorithm.
#@Sami Harari
#t1988
#cCoding Theory and Applications
#index106547

